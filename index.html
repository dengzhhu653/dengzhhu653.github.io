<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Zhihua Deng"><meta name="description" content="衣带渐宽终不悔"><title></title><link rel="icon" href="/favicon.ico"><link rel="canonical" href="https://dengzhhu653.github.io/"><link rel="alternate" href="atom.xml" title="null"><link rel="stylesheet" href="fonts/iconfont/iconfont.css"><link rel="stylesheet" href="css/style.css"><script type="text/javascript">var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'Your Google Analytics ID', 'auto');
ga('send', 'pageview');</script></head><body><div id="main"><header><a href="." class="logo"></a><ul class="nav"><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/about/" target="_self">About</a></li></ul></header><section id="container"><ul class="home"><li class="post-item"><article class="post"><h2 class="post-title"><a href="hive-llap/" class="post-link">Hive Llap尝试（0）</a></h2><span class="post-time">Mar 15, 2017</span><div class="post-content"><h2 id="Hive-llap&#x5C1D;&#x8BD5;"><a href="#Hive-llap&#x5C1D;&#x8BD5;" class="headerlink" title="Hive llap&#x5C1D;&#x8BD5;"></a>Hive llap&#x5C1D;&#x8BD5;</h2><p> &#x5728;Hive2.0&#x7248;&#x672C;&#x4E0A;&#x5F15;&#x8FDB;&#x4E86;<code>Hive llap(Live Long and Process)</code>&#x8FD9;&#x79CD;&#x65B0;&#x7279;&#x6027;&#xFF0C;&#x4E0E;Tez&#x8BA1;&#x7B97;&#x5F15;&#x64CE;&#x7ED3;&#x5408;&#x7D27;&#x5BC6;&#xFF0C;&#x7C7B;&#x4F3C;&#x4E8E;Presto&#x548C;Impala&#xFF0C; &#x5979;&#x9884;&#x5148;&#x542F;&#x52A8;&#x4E00;&#x7EC4;&#x8FDB;&#x7A0B;&#xFF0C;&#x7B49;&#x5F85;&#x6709;&#x89E3;&#x6790;&#x597D;&#x7684;task&#x7684;&#x5230;&#x6765;&#x5E76;&#x6267;&#x884C;&#x3002; &#x5728;&#x8FD9;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#x7684;&#x57FA;&#x7840;&#x4E0A;&#xFF0C;&#x5979;&#x8FD8;&#x5F15;&#x5165;&#x4E00;&#x4E9B;&#x52A0;&#x5FEB;task&#x8BA1;&#x7B97;&#x7684;&#x7279;&#x6027;&#xFF1A;<br> <ol><br>   <li>&#x5F02;&#x6B65;&#x6570;&#x636E;&#x611F;&#x77E5;IO</li><br>   <li>&#x8BA1;&#x7B97;&#x6570;&#x636E;&#x9884;&#x8BFB;&#x53D6;&#x548C;&#x5217;&#x7F13;&#x5B58;</li><br>   <li>&#x826F;&#x597D;&#x5730;&#x5E76;&#x884C;&#x5316;&#x6267;&#x884C;task</li><br> </ol><br>&#x5F97;&#x76CA;&#x4E8E;&#x8FC7;&#x53BB;&#x4E24;&#x5E74;&#x91CC;&#x793E;&#x533A;&#x63D0;&#x4EA4;&#x7684;&#x5404;&#x79CD;&#x7279;&#x6027;&#x548C;&#x6539;&#x8FDB;&#xFF0C;Hive&#x80FD;&#x591F;&#x663E;&#x8457;&#x7684;&#x53D8;&#x5FEB;.<br><br> <ul><br>   <li><a href="https://cwiki.apache.org/confluence/display/Hive/LLAP" target="_blank" rel="external">https://cwiki.apache.org/confluence/display/Hive/LLAP</a></li><br>   <li><a href="http://www.slideshare.net/Hadoop_Summit/llap-longlived-execution-in-hive" target="_blank" rel="external">http://www.slideshare.net/Hadoop_Summit/llap-longlived-execution-in-hive</a></li><br> </ul></p>
<h2 id="&#x90E8;&#x7F72;&#x5B89;&#x88C5;"><a href="#&#x90E8;&#x7F72;&#x5B89;&#x88C5;" class="headerlink" title="&#x90E8;&#x7F72;&#x5B89;&#x88C5;"></a>&#x90E8;&#x7F72;&#x5B89;&#x88C5;</h2> <table><tr><th> &#x8F6F;&#x4EF6; </th><th> &#x7248;&#x672C; </th><th> &#x5B89;&#x88C5;&#x8BF4;&#x660E; </th></tr><tr><td>tez</td><td>0.8.4</td><td><a href="https://tez.apache.org/install.html" target="_blank" rel="external">tez&#x5B89;&#x88C5;</a>&#xFF0C;&#x4FEE;&#x6539;&#x4F9D;&#x8D56;&#x7684;hadoop&#x7248;&#x672C;&#x548C;guava&#x7248;&#x672C;&#xFF0C;&#x91CD;&#x65B0;&#x7F16;&#x8BD1;&#xFF0C;&#x5728;tez-dist&#x76EE;&#x5F55;&#x4E2D;&#xFF0C;&#x627E;&#x5230;tez-0.8.4-minimal.tar.gz&#x6587;&#x4EF6;&#x3002;</td></tr><tr><td>hadoop&#xFF0C;&#x5305;&#x62EC;yarn&#xFF0C;hdfs</td><td>&#x57FA;&#x4E8E;2.7.1</td><td>&#x7565;</td></tr><tr><td>zookeeper</td><td>3.4.6</td><td><a href="https://zookeeper.apache.org/doc/r3.4.8/zookeeperStarted.html#sc_RunningReplicatedZooKeeper" target="_blank" rel="external">zookeeper&#x5B89;&#x88C5;</a></td></tr><tr><td>slider</td><td>slider-0.81.1-incubating</td><td><a href="https://slider.incubator.apache.org/docs/getting_started.html#install" target="_blank" rel="external">slider&#x5B89;&#x88C5;&#x914D;&#x7F6E;</a>&#xFF0C;&#x5B89;&#x88C5;&#x5B8C;&#x6210;&#x540E;&#x5C06;bin&#x76EE;&#x5F55;&#x52A0;&#x5165;&#x5230;$PATH&#x53D8;&#x91CF;&#x4E2D;</td></tr><tr><td>hive</td><td>apache-hive-2.1.1</td><td>&#x4ECE;apache&#x5B98;&#x7F51;&#x540E;&#x4E0B;&#x8F7D;&#x53EF;&#x6267;&#x884C;&#x7684;&#x5305;&#xFF0C;&#x89E3;&#x538B;&#x5230;&#x76F8;&#x5173;&#x7684;&#x76EE;&#x5F55;&#x4E2D;</td></tr></table>

<h2 id="&#x914D;&#x7F6E;"><a href="#&#x914D;&#x7F6E;" class="headerlink" title="&#x914D;&#x7F6E;"></a>&#x914D;&#x7F6E;</h2><table><tr><th>&#x5C5E;&#x6027;</th><th>&#x4F4D;&#x7F6E;</th> <th>&#x8BF4;&#x660E;</th></tr><tr><td>hive.execution.engine</td><td>hive-site.xml</td><td>&#x76EE;&#x524D;llap&#x4EC5;&#x652F;&#x6301;tez&#xFF0C;&#x8BE5;&#x5C5E;&#x6027;&#x503C;&#x987B;&#x4E3A;tez</td></tr><tr><td>hive.llap.execution.mode</td><td>hive-site.xml</td><td>value&#x53EF;&#x4EE5;&#x4E3A;all, auto, map, none. &#x6211;&#x4EEC;&#x914D;&#x7F6E;&#x6210;all<br>&#x8BA9;&#x6240;&#x6709;&#x7684;task&#x90FD;&#x5728;llap&#x8FDB;&#x7A0B;&#x5185;&#x6267;&#x884C;&#x3002;</td></tr><tr><td>hive.execution.mode</td><td>hive-site.xml</td><td>value&#x4E3A;llap</td></tr><tr><td>hive.llap.daemon.service.hosts</td><td>hive-site.xml</td><td>&#x670D;&#x52A1;&#x7684;&#x540D;&#x79F0;&#xFF0C;&#x5982;&#x901A;&#x8FC7;&#x201D;hive &#x2013;service llap &#x2013;name llap_service&#x201D;&#x751F;&#x6210;&#x542F;&#x52A8;&#x811A;&#x672C;&#x65F6;,&#x5C06;&#x8BE5;&#x5C5E;&#x6027;&#x914D;&#x7F6E;&#x6210;@llap_service</td></tr><tr><td>hive.llap.daemon.work.dirs</td><td>hive-site.xml</td><td>&#x7F3A;&#x5C11;&#x8BE5;&#x914D;&#x7F6E;&#x65E0;&#x6CD5;&#x542F;&#x52A8;llap daemon, &#x53EF;&#x80FD;&#x662F;&#x542F;&#x52A8;&#x7528;&#x6237;&#x6CA1;&#x6709;yarn.nodemanager.local-dirs&#x914D;&#x7F6E;&#x4E0A;&#x76EE;&#x5F55;&#x7684;&#x8BFB;&#x5199;&#x6743;&#x9650;&#x3002;</td></tr><tr><td>hive.zookeeper.quorum</td><td>hive-site.xml</td><td>&#x7F3A;&#x5C11;&#x8BE5;&#x914D;&#x7F6E;&#x65E0;&#x6CD5;&#x542F;&#x52A8;llap daemon&#xFF0C;zk&#x8282;&#x70B9;&#x7528;&#x9017;&#x53F7;&#x5206;&#x9694;</td></tr><tr><td>hive.zookeeper.client.port</td><td>hive-site.xml</td><td>2181</td></tr><tr><td>hive.llap.daemon.memory.per.instance.mb</td><td>hive-site.xml</td><td>&#x8FD9;&#x4E2A;&#x5F88;&#x5947;&#x602A;&#xFF0C;&#x5373;&#x4F7F;&#x5728;&#x542F;&#x52A8;&#x547D;&#x4EE4;&#x4E2D;&#x6307;&#x5B9A;daemon&#x5185;&#x5B58;&#x548C;executor&#x7684;&#x6570;&#x91CF;&#xFF0C;&#x542F;&#x52A8;llap&#x670D;&#x52A1;&#x65F6;&#x4E5F;&#x4F1A;&#x5931;&#x8D25;&#xFF0C;&#x5FC5;&#x987B;&#x914D;&#x7F6E;&#x5728;&#x8FD9;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;</td></tr><tr><td>hive.llap.daemon.num.executors</td><td>hive-site.xml</td><td>&#x540C;&#x4E0A;</td></tr><tr><td>tez.tez-ui.history-url.base</td><td>tez-site.xml</td><td>tez ui&#x8DEF;&#x5F84;</td></tr><tr><td>tez.lib.uris</td><td>tez-site.xml</td><td>hdfs&#x4E0A;tez-0.8.4-minimal.tar.gz&#x7684;&#x8DEF;&#x5F84;</td></tr> <tr><td>tez.use.cluster.hadoop-libs</td><td>tez-site.xml</td><td>&#x4F7F;&#x7528;&#x7684;&#x662F;tez-0.8.4-minimal.tar.gz&#xFF0C;&#x987B;&#x5C06;&#x8BE5;&#x914D;&#x7F6E;&#x8BBE;&#x7F6E;&#x6210;true</td></tr><tr><td>hive.server2.enable.doAs</td><td>hive-site.xml</td><td>&#x8FD9;&#x91CC;&#x8BBE;&#x7F6E;&#x6210;false</td></tr><tr><td>hadoop.bin.path</td><td>hive-site.xml</td><td>&#x96C6;&#x7FA4;&#x4E0A;hadoop&#x7684;bin&#x8DEF;&#x5F84;</td></tr></table>


<p>&#x914D;&#x7F6E;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x6267;&#x884C;&#x547D;&#x4EE4;&#xFF1A;</p>
<blockquote>
<p>hive &#x2013;service llap &#x2013;name llap_service &#x2013;instances 16 &#x2013;size 7g &#x2013;loglevel INFO &#x2013;args &#x201C; -XX:MaxMetaspaceSize=128m -verbose:class -XX:+UseParNewGC -Xmn1g -XX:+UseConcMarkSweepGC -XX:-UseBiasedLocking -XX:+PerfDisableSharedMem&#x201D; &#x2013;cache 5g &#x2013;executors 30 &#x2013;iothreads 10 &#x2013;slider-am-container-mb 1024</p>
</blockquote>
<p>&#x5F53;&#x770B;&#x5230;&#x65E5;&#x5FD7;&#x8F93;&#x51FA;&#x884C;&#x91CC;&#x6709;&#xFF1A;</p>
<pre>
  Prepared llap-slider-ddMMyyyy/run.sh for running LLAP on Slider
</pre>
&#x540E;&#x610F;&#x5473;&#x7740;&#x73AF;&#x5883;&#x5E94;&#x8BE5;&#x6CA1;&#x4EC0;&#x4E48;&#x95EE;&#x9898;&#x4E86;&#xFF0C; &#x5728;&#x5F53;&#x524D;&#x7684;&#x76EE;&#x5F55;&#x4E0B;&#xFF0C; &#x53EF;&#x4EE5;&#x627E;&#x5230;llap-slider-ddMMyyyy&#x8FD9;&#x4E2A;&#x76EE;&#x5F55;&#xFF0C;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x6709;&#x56DB;&#x4E2A;&#x6587;&#x4EF6;&#xFF1A;<br>
 <em>appConfig.json  llap-09Mar2017.zip  resources.json  run.sh</em><br>&#x6253;&#x5F00;run.sh&#x8FD9;&#x4E2A;&#x6587;&#x4EF6;&#xFF0C; &#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x542F;&#x52A8;&#x548C;&#x505C;&#x6B62;llap&#x670D;&#x52A1;&#x7684;&#x547D;&#x4EE4;&#xFF1A;
 <pre>
slider stop llap_service
slider destroy llap_service --force || slider destroy llap_service
slider install-package --name LLAP --package  $BASEDIR/llap-09Mar2017.zip --replacepkg
slider create llap_service --resources $BASEDIR/resources.json --template $BASEDIR/appConfig.json
 </pre>

<p>&#x6267;&#x884C;run.sh&#x811A;&#x672C;&#xFF0C;&#x5C31;&#x53EF;&#x4EE5;&#x5728;yarn web&#x7BA1;&#x7406;&#x754C;&#x9762;&#x4E2D;&#xFF0C;&#x770B;&#x5230;Application Type&#x4E3A;org-apache-slider&#xFF0C; Name&#x4E3A;llap_service&#x7684;&#x4E00;&#x4E2A;&#x4F5C;&#x4E1A;&#x4E86;&#x3002;&#x5982;&#x679C;&#x8FD9;&#x4E2A;&#x4F5C;&#x4E1A;&#x80FD;&#x6301;&#x7EED;4&#xFF5E;6&#x5206;&#x949F;&#x8FD0;&#x884C;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x4EE5;&#x542F;&#x52A8;hive cli&#xFF0C; &#x6267;&#x884C;&#x4E00;&#x4E2A;&#x6BD4;&#x8F83;&#x7B80;&#x5355;&#x7684;sql&#x6765;&#x63A2;&#x7D22;llap&#x4E86;(mode&#x4E00;&#x680F;&#x663E;&#x793A;&#x4E3A;llap)&#x3002; </p>
<pre><code>Status: Running (Executing on YARN cluster with App id application_xxxx)
----------------------------------------------------------------------------------------------
    VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED
----------------------------------------------------------------------------------------------
Map 1 ..........      llap     SUCCEEDED     24         24        0        0       0       0
Reducer 2 ......      llap     SUCCEEDED      1          1        0        0       0       0
----------------------------------------------------------------------------------------------
VERTICES: 02/02  [==========================&gt;&gt;] 100%  ELAPSED TIME: 15.01 s
----------------------------------------------------------------------------------------------
</code></pre><p>&#x5982;&#x679C;&#x51FA;&#x73B0;&#x95EE;&#x9898;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x8981;&#x4ED4;&#x7EC6;&#x89C2;&#x5BDF;application&#x4F5C;&#x4E1A;&#x7684;&#x65E5;&#x5FD7;&#x4E86;&#xFF0C; &#x4ECE;&#x4E2D;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x5F53;&#x524D;&#x96C6;&#x7FA4;&#x4E2D;&#x8FD8;&#x6709;&#x54EA;&#x4E9B;&#x6761;&#x4EF6;&#x8FD8;&#x6CA1;&#x88AB;&#x6EE1;&#x8DB3;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;&#x8C03;&#x6574;yarn nodemanager&#x4E2D;&#x7684;&#x53C2;&#x6570;&#xFF1A;</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.delete.debug-delay-sec&lt;/name&gt;
    &lt;value&gt;3600&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>&#x8FDB;&#x5165;daemon&#x542F;&#x52A8;&#x5931;&#x8D25;&#x7684;nodemanager&#x8282;&#x70B9;&#x4E2D;&#xFF0C;&#x901A;&#x8FC7;&#x672C;&#x5730;&#x542F;&#x52A8;&#x547D;&#x4EE4;&#x548C;&#x65E5;&#x5FD7;&#x8F93;&#x51FA;&#xFF0C;&#x67E5;&#x770B;&#x5931;&#x8D25;&#x7684;&#x539F;&#x56E0;&#x3002;</p>
<h2 id="&#x95EE;&#x9898;&#x89E3;&#x51B3;"><a href="#&#x95EE;&#x9898;&#x89E3;&#x51B3;" class="headerlink" title="&#x95EE;&#x9898;&#x89E3;&#x51B3;"></a>&#x95EE;&#x9898;&#x89E3;&#x51B3;</h2><pre><code>1, llap daemon&#x8FDB;&#x7A0B;&#x4E0D;&#x7A33;&#x5B9A;&#xFF0C;&#x670D;&#x52A1;&#x542F;&#x52A8;&#x5931;&#x8D25;&#x3002;
</code></pre><p>&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x4ECE;&#x76EE;&#x524D;&#x603B;&#x7ED3;&#x6765;&#x770B;&#xFF0C;&#x4E3B;&#x8981;&#x5206;&#x4E3A;3&#x7C7B;&#xFF1A;</p>
<ul><br> <li>hive-site.xml&#x4E0A;&#x7F3A;&#x5C11;&#x4E00;&#x4E9B;&#x914D;&#x7F6E;</li><br> <li>hadoop&#x96C6;&#x7FA4;&#x548C;hive&#x4E4B;&#x95F4;&#x7684;&#x7C7B;&#x51B2;&#x7A81;</li><br> <li>&#x627E;&#x4E0D;&#x5230;&#x76F8;&#x5E94;&#x7684;hadoop&#x7C7B;</li><br></ul> 

<pre><code>1.1 &#x7F3A;&#x5C11;&#x914D;&#x7F6E;
</code></pre><p>&#x8FD9;&#x4E2A;&#x53EF;&#x4EE5;&#x7ED3;&#x5408;&#x65E5;&#x5FD7;&#x548C;&#x4EE3;&#x7801;&#xFF0C;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x7F3A;&#x5C11;&#x4EC0;&#x4E48;&#x914D;&#x7F6E;&#xFF0C;&#x5728;hive-site.xml&#x6587;&#x4EF6;&#x52A0;&#x5165;&#x76F8;&#x5173;&#x7684;&#x914D;&#x7F6E;&#x9879;&#x5373;&#x53EF;&#x3002;</p>
<pre><code>1.2 hadoop&#xFF0C; hive&#x4E4B;&#x95F4;&#x7C7B;&#x51B2;&#x7A81;
</code></pre><p>&#x7531;&#x4E8E;&#x6211;&#x4EEC;&#x7ED9;&#x4E88;hadoop&#x4E0A;&#x505A;&#x4E86;&#x4E00;&#x4E9B;&#x6539;&#x8FDB;&#xFF0C;&#x5BFC;&#x81F4;&#x6709;&#x4E00;&#x4E9B;&#x627E;&#x4E0D;&#x5230;&#x7C7B;&#x65B9;&#x6CD5;&#x4EE5;&#x53CA;&#x7C7B;&#x5B9A;&#x4E49;&#x4E0D;&#x5B58;&#x5728;&#x7684;&#x4E00;&#x4E9B;&#x95EE;&#x9898;&#xFF0C;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x662F;&#xFF0C;&#x6309;&#x7167;&#x6307;&#x5B9A;&#x7684;&#x7248;&#x672C;&#x91CD;&#x65B0;&#x7F16;&#x8BD1;tez&#xFF0C;&#x7F16;&#x8BD1;&#x6CA1;&#x51FA;&#x73B0;&#x95EE;&#x9898;&#xFF0C;&#x9009;&#x62E9;minimal&#x538B;&#x7F29;&#x5305;&#x4F5C;&#x4E3A;tez&#x7684;&#x5B89;&#x88C5;&#x8DEF;&#x5F84;&#x5E76;&#x4E0A;&#x4F20;&#x5230;hdfs&#x4E0A;&#x3002;</p>
<pre><code>1.3 &#x627E;&#x4E0D;&#x5230;&#x76F8;&#x5E94;&#x7684;hadoop&#x7C7B;
</code></pre><p>&#x5728;Hadoop&#x73AF;&#x5883;&#x4E2D;&#x627E;&#x4E0D;&#x5230;hadoop&#x7C7B;&#xFF0C;&#x8FD9;&#x786E;&#x5B9E;&#x662F;&#x4E00;&#x4E2A;&#x5F88;&#x8BE1;&#x5F02;&#x7684;&#x95EE;&#x9898;&#x3002;&#x901A;&#x8FC7;&#x8C03;&#x7814;&#x53D1;&#x73B0;&#xFF0C;llap&#x8FDB;&#x7A0B;&#x7684;&#x542F;&#x52A8;&#x662F;&#x901A;&#x8FC7;&#x4E00;&#x4E2A;runLlapDaemon.sh&#x811A;&#x672C;&#x547D;&#x4EE4;&#x542F;&#x52A8;&#x7684;&#xFF0C;&#x800C;&#x8FD9;&#x4E2A;&#x811A;&#x672C;&#x662F;&#x5728;<code>llap-slider-ddMMyyyy/llap-ddMMyyyy.zip</code> &#x8FD9;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x5728;&#x89E3;&#x538B;&#x540E;&#x7684;package/files&#x76EE;&#x5F55;&#x4E2D;&#xFF0C;&#x53EF;&#x4EE5;&#x627E;&#x5230;&#x4E00;&#x4E2A;llap-ddMMyyyy.tar.gz&#x538B;&#x7F29;&#x5305;&#xFF0C;&#x89E3;&#x538B;&#x8FD9;&#x4E2A;tar.gz&#x7684;&#x538B;&#x7F29;&#x5305;&#xFF0C;&#x53D1;&#x73B0;&#x5728;&#x540C;&#x7EA7;&#x7684;&#x76EE;&#x5F55;&#x4E0B;&#x51FA;&#x73B0;bin&#x76EE;&#x5F55;&#xFF0C;&#x8FD9;&#x5C31;&#x662F;<code>runLlapDaemon.sh</code>&#x811A;&#x672C;&#x7684;&#x4F4D;&#x7F6E;&#x3002;<br>&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#xFF0C;&#x5728;&#x8FD9;&#x4E2A;&#x542F;&#x52A8;&#x811A;&#x672C;&#x4E2D;&#x5BF9;&#x4E8E;CLASSPATH&#x7684;&#x5B9A;&#x4E49;&#xFF1A;</p>
<pre><code>CLASSPATH=${LLAP_DAEMON_CONF_DIR}:${LLAP_DAEMON_HOME}/lib/*:${LLAP_DAEMON_HOME}/lib/tez/*:${LLAP_DAEMON_HOME}/lib/udfs/*:.
</code></pre><p>  &#x5728;&#x4E0A;&#x5C42;&#x7684;lib&#x76EE;&#x5F55;&#x4E2D;&#xFF0C;&#x5E76;&#x6CA1;&#x6709;&#x53D1;&#x73B0;&#x76F8;&#x5173;&#x7684;hadoop jar&#x6587;&#x4EF6;&#xFF0C;&#x56E0;&#x6B64;&#x5BFC;&#x81F4;llap daemon&#x65E0;&#x6CD5;&#x627E;&#x5230;&#x76F8;&#x5E94;&#x7684;&#x7C7B;&#xFF0C;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x4E5F;&#x5C31;&#x662F;&#x5728;&#x8FD9;&#x4E2A;CLASSPATH&#x7684;&#x672B;&#x5C3E;&#xFF0C;&#x52A0;&#x4E0A;<code>hadoop classpath</code>:</p>
<pre><code>CLASSPATH=${LLAP_DAEMON_CONF_DIR}:${LLAP_DAEMON_HOME}/lib/*:${LLAP_DAEMON_HOME}/lib/tez/*:${LLAP_DAEMON_HOME}/lib/udfs/*:.:`hadoop classpath`
</code></pre><p>&#x8FD9;&#x4E2A;&#x6700;&#x597D;&#x52A0;&#x5728;&#x540E;&#x9762;&#xFF0C;&#x56E0;&#x4E3A;&#x4E00;&#x4E9B;hive-site.xml&#x7684;&#x914D;&#x7F6E;&#x662F;&#x5728;&#x5B89;&#x88C5;&#x5305;&#x7684;conf&#x76EE;&#x5F55;&#x4E0B;&#xFF0C;&#x5982;&#x679C;&#x52A0;&#x5728;&#x524D;&#x9762;&#xFF0C;&#x5982;&#x679C;hadoop&#x73AF;&#x5883;&#x7684;&#x914D;&#x7F6E;&#x5305;&#x542B;&#x6709;hive-site.xml&#x6587;&#x4EF6;&#xFF0C;&#x90A3;&#x4E48;&#x4F1A;&#x52A0;&#x8F7D;&#x8BE5;&#x6587;&#x4EF6;&#x800C;&#x6452;&#x5F03;&#x4E86;&#x5BA2;&#x6237;&#x7AEF;llap hive-site.xml&#x7684;&#x5B9A;&#x4E49;&#xFF0C;&#x4F1A;&#x5BFC;&#x81F4;&#x51FA;&#x73B0;<code>1.1</code>&#x63CF;&#x8FF0;&#x7684;&#x95EE;&#x9898;&#x3002;<br><br>&#x4FEE;&#x6539;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x91CD;&#x65B0;&#x6253;&#x5305;&#xFF0C;&#x518D;&#x6B21;&#x6267;&#x884C;run.sh&#x811A;&#x672C;&#x5373;&#x53EF;&#x3002;</p>
<p>&#x6309;&#x7167;&#x8FD9;&#x6837;&#x7684;&#x601D;&#x8DEF;&#xFF0C;&#x89E3;&#x51B3;&#x5176;&#x4ED6;&#x95EE;&#x9898;&#x4E5F;&#x5C31;&#x5BB9;&#x6613;&#x5F88;&#x591A;&#x4E86;&#xFF0C;&#x53D1;&#x73B0;&#x67D0;&#x4E2A;udf&#x5F15;&#x5165;&#x4E86;&#x5176;&#x4ED6;&#x7684;jar&#x5305;&#x5BFC;&#x81F4;&#x7C7B;&#x51B2;&#x7A81;&#xFF0C;&#x90A3;&#x4E48;&#x5C06;&#x8FD9;&#x4E2A;jar&#x4ECE;lib/udf&#x76EE;&#x5F55;&#x4E0B;&#x79FB;&#x9664;&#x51FA;&#x53BB;&#xFF0C;&#x8FD8;&#x53EF;&#x4EE5;&#x4FEE;&#x6539;&#x4E00;&#x4E9B;&#x914D;&#x7F6E;&#x7B49;&#x7B49;&#x3002;</p>
<pre><code>2, &#x67E5;&#x8BE2;&#x6548;&#x679C;&#x6CA1;&#x660E;&#x663E;&#x5DEE;&#x5F02;
</code></pre><p>&#x5C06;&#x8868;&#x6570;&#x636E;&#x5B58;&#x50A8;&#x65B9;&#x5F0F;&#x6539;&#x6210;&#x4EE5;&#x5217;&#x5F0F;&#x6765;&#x5B58;&#x50A8;&#x3002; Llap&#x9ED8;&#x8BA4;&#x4F7F;&#x7528;off-heap&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x7F13;&#x5B58;&#x6570;&#x636E;&#xFF0C;&#x5728;&#x4F7F;&#x7528;&#x5982;&#x4E0B;&#x547D;&#x4EE4;&#x751F;&#x6210;&#x811A;&#x672C;&#x65F6;&#xFF0C;<code>hive --service llap --name llap_service --size 4g --loglevel INFO  --cache 4g</code>&#xFF0C; &#x63D0;&#x793A;</p>
<pre><code>java.lang.IllegalArgumentException: Cache size (4.00GB) has to be smaller than the container sizing (4.00GB)
    at com.google.common.base.Preconditions.checkArgument(Preconditions.java:92)
    at org.apache.hadoop.hive.llap.cli.LlapServiceDriver.run(LlapServiceDriver.java:207)
    at org.apache.hadoop.hive.llap.cli.LlapServiceDriver.main(LlapServiceDriver.java:104)
</code></pre><p>&#x4E5F;&#x5C31;&#x662F;&#x5806;&#x5916;&#x7F13;&#x5B58;&#x7684;&#x5927;&#x5C0F;&#x8981;&#x5C0F;&#x4E8E;llap container&#x8BBE;&#x7F6E;&#x7684;&#x5185;&#x5B58;, &#x4E3A;&#x4EC0;&#x4E48;&#x8981;&#x6709;&#x8FD9;&#x4E2A;&#x7EA6;&#x675F;? &#x4ECE;&#x4E0E;&#x793E;&#x533A;&#x7684;&#x4EA4;&#x6D41;&#x6765;&#x770B;&#xFF0C;size&#x8868;&#x793A;&#x7684;&#x542B;&#x4E49;&#x662F;executor&#x5DE5;&#x4F5C;&#x5185;&#x5B58;&#x548C;&#x5806;&#x5916;&#x5185;&#x5B58;&#x4E4B;&#x548C;&#x3002;&#x5728;&#x5B9E;&#x8DF5;&#x4E2D;&#xFF0C;&#x5374;&#x53D1;&#x73B0;size&#x51B3;&#x5B9A;&#x4E00;&#x4E2A;yarn container JVM&#x7684;&#x5B9E;&#x9645;&#x5927;&#x5C0F;&#xFF0C;&#x5E76;&#x672A;&#x6709;&#x6240;&#x6709;&#x5185;&#x5B58;&#x4E4B;&#x548C;&#x7684;&#x542B;&#x4E49;&#x3002;&#x4ECE;&#x4EE3;&#x7801;&#x6CE8;&#x91CA;&#x6765;&#x770B;&#xFF0C;&#x52A0;&#x4E0A;&#x8FD9;&#x4E00;&#x7EA6;&#x675F;&#x662F;&#x4E3A;&#x4E86;&#x66F4;&#x5B89;&#x5168;&#x7684;&#x5806;&#x5916;&#x5185;&#x5B58;&#x5206;&#x914D;&#xFF1F; &#x76EE;&#x524D;&#x91C7;&#x7528;&#x7684;&#x662F;&#x7528;size&#x8868;&#x793A;container&#x7684;&#x5B9E;&#x9645;JVM&#x5185;&#x5B58;&#xFF0C;&#x7528;cache&#x8868;&#x793A;&#x5806;&#x5916;&#x5185;&#x5B58;&#x5927;&#x5C0F;&#x3002;</p>
<p>&#x53E6;&#x5916;&#x4E5F;&#x53EF;&#x4EE5;&#x5C06;&#x7F13;&#x5B58;&#x8BBE;&#x7F6E;&#x6210;on heap&#x7684;&#x65B9;&#x5F0F;&#xFF0C;&#x901A;&#x8FC7;&#x8BBE;&#x7F6E;&#xFF1A;</p>
<pre><code>&lt;property&gt;
     &lt;name&gt;hive.llap.io.allocator.direct&lt;/name&gt;
     &lt;value&gt;false&lt;/value&gt;
 &lt;/property&gt;
</code></pre><p>&#x8FD9;&#x79CD;&#x65B9;&#x5F0F;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;llap&#x4E3A;&#x6BCF;&#x4E2A;executor&#x914D;&#x4E86;&#x4E00;&#x5B9A;&#x7684;&#x5185;&#x5B58;&#x9650;&#x989D;&#xFF1A;</p>
<pre><code>this.memoryPerExecutor = (long)(totalMemoryAvailableBytes * 0.8 / (float) numExecutors);
</code></pre><p>&#x8FD9;&#x8981;&#x6C42;tez task&#x7684;&#x4E34;&#x65F6;&#x5DE5;&#x4F5C;&#x5185;&#x5B58;&#x9700;&#x8981;&#x5C0F;&#x4E8E;&#x8FD9;&#x4E2A;&#x503C;&#xFF0C;&#x5982;&#x4E0B;&#x9762;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;&#xFF1A;</p>
<pre><code> &lt;property&gt;
  &lt;name&gt;tez.runtime.io.sort.mb&lt;/name&gt;
  &lt;defaultValue&gt;100&lt;/defaultValue&gt;
  &lt;type&gt;integer&lt;/type&gt;
&lt;/property&gt;    
</code></pre></div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="storm-core/" class="post-link">storm-core</a></h2><span class="post-time">Oct 21, 2016</span><div class="post-content"><p>&#x8FD9;&#x662F;&#x4E00;&#x6B21;&#x9177;&#x8BAF;&#x516C;&#x53F8;&#x5185;&#x90E8;&#x4E00;&#x6B21;Storm&#x5B66;&#x4E60;&#x5206;&#x4EAB;&#xFF0C;&#x611F;&#x8C22;&#x8001;&#x516C;&#x53F8;&#xFF0C;&#x5728;&#x90A3;&#x91CC;&#x6210;&#x957F;&#x4E86;&#x5F88;&#x591A;&#x3002;<br>

	<div class="row">
	  <iframe src="http://nagland.github.io/viewer/web/viewer.html?val=https://stanford.edu/~rezab/sparkclass/slides/itas_workshop.pdf" style="width:100%; height:550px"></iframe>
	</div>


</p>


	<div class="row">
	  <iframe src="http://nagland.github.io/viewer/web/viewer.html?val=http://7xov2f.com1.z0.glb.clouddn.com/bash_freshman.pdf" style="width:100%; height:550px"></iframe>
	</div>



</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="spark-serializable/" class="post-link">Spark作业提交及序列化</a></h2><span class="post-time">Oct 21, 2016</span><div class="post-content"><p>  &#x5728;&#x5206;&#x6790;Spark&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x4E4B;&#x524D;&#xFF0C;&#x5148;&#x7B80;&#x5355;&#x68B3;&#x7406;&#x4E00;&#x4E0B;&#x6709;&#x5173;Java&#x5E8F;&#x5217;&#x5316;&#x7684;&#x77E5;&#x8BC6;&#x4EE5;&#x53CA;&#x4E00;&#x4E9B;&#x7406;&#x89E3;&#x3002;</p>
<p><strong><em>Java&#x5E8F;&#x5217;&#x5316;</em></strong></p>
<p>  &#x4E00;&#x4E2A;Java&#x5BF9;&#x8C61;&#x5728;&#x5176;&#x751F;&#x547D;&#x5468;&#x671F;&#x5185;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x591A;&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x72B6;&#x6001;&#xFF0C;&#x8FD9;&#x4E9B;&#x72B6;&#x6001;&#x533A;&#x5206;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;&#x7C7B;&#x7684;&#x5176;&#x5B83;&#x5BF9;&#x8C61;&#x3002;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5DE5;&#x4F5C;&#xFF0C;&#x5C31;&#x662F;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x72B6;&#x6001;&#xFF0C;&#x4EE5;&#x4E8C;&#x8FDB;&#x5236;&#x7684;&#x5F62;&#x6001;&#x8F93;&#x51FA;&#x51FA;&#x6765;&#xFF0C;&#x5728;&#x9075;&#x5FAA;&#x8F93;&#x51FA;&#x534F;&#x8BAE;&#x7684;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8FD9;&#x4E9B;&#x5B57;&#x8282;&#x6062;&#x590D;&#x5BF9;&#x8C61;&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#x7684;&#x72B6;&#x6001;(&#x53CD;&#x5E8F;&#x5217;&#x5316;), &#x8FD9;&#x5BF9;&#x4E8E;&#x5FEB;&#x901F;&#x6062;&#x590D;&#x4EE5;&#x53CA;&#x8DE8;JVM&#x4FE1;&#x606F;&#x4EA4;&#x6D41;&#x5E26;&#x6765;&#x5DE8;&#x5927;&#x7684;&#x4FBF;&#x5229;&#x6027;&#x3002;<br>  &#x5BF9;&#x8C61;&#x4E0E;&#x5BF9;&#x8C61;&#x4E4B;&#x95F4;&#x5B58;&#x5728;&#x7740;&#x5F15;&#x7528;&#x4E0E;&#x88AB;&#x5F15;&#x7528;&#x7684;&#x5173;&#x7CFB;&#xFF0C;&#x9488;&#x5BF9;&#x4E8E;&#x5BF9;&#x8C61;&#x672C;&#x8EAB;&#xFF0C;&#x5219;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x8FED;&#x4EE3;&#x7248;&#x672C;&#x3002;&#x5F53;&#x5BF9;&#x8C61;&#x5C1D;&#x8BD5;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x5F15;&#x7528;&#x5173;&#x7CFB;&#x5E8F;&#x5217;&#x5316;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x4FDD;&#x8BC1;&#x5F15;&#x7528;&#x7684;&#x5BF9;&#x8C61;&#x4E5F;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#x3002;&#x5982;&#x4E0B;&#x9762;&#x7684;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;serializable(JavaSerializable) -&gt; sc(Serializable1) -&gt;ns(NonSerializable), &#x7531;&#x4E8E;ns&#x5BF9;&#x8C61;&#x5E76;&#x4E0D;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5BFC;&#x81F4;&#x5728;main&#x65B9;&#x6CD5;&#x4E2D;&#xFF0C;&#x5E8F;&#x5217;&#x5316;serializable&#x64CD;&#x4F5C;&#x5931;&#x8D25;&#x3002;</p>
<p><pre><br>  public class JavaSerializable implements Serializable {<br>  Serializable1 sc;<br>  private JavaSerializable() { }<br>  public JavaSerializable(Serializable1 sc) {<br>    this.sc = sc;<br>  }<br>  public static void main(String[] args) throws IOException {<br>    JavaSerializable serializable = new JavaSerializable(new Serializable1());<br>    ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(&#x201C;/tmp/obj.ser&#x201D;));<br>    //&#x8FD9;&#x91CC;&#x4F1A;&#x629B;&#x51FA;&#x4E00;&#x4E2A; &#x201C;java.io.NotSerializableException: cn.creditease.basic.NonSerializable&#x201D; &#x5F02;&#x5E38;<br>    objectOutputStream.writeObject(serializable);<br>    objectOutputStream.flush();<br>    objectOutputStream.close();<br>  }<br>}<br>class Serializable1 implements Serializable {<br>  NonSerializable ns = new NonSerializable(&#x201C;hello&#x201D;);<br>}</pre></p>
<p>class NonSerializable {<br>    int tf1;<br>    String tf2;<br>    public NonSerializable(String tf2) {<br>      this.tf2 = tf2;<br>    }<br>}<br><br>&#x7136;&#x800C;&#x9700;&#x8981;&#x8BA4;&#x8BC6;&#x5230;&#xFF0C;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5DE5;&#x4F5C;&#x662F;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x72B6;&#x6001;&#x901A;&#x8FC7;&#x4E8B;&#x5148;&#x7EA6;&#x5B9A;&#xFF0C;&#x8F93;&#x51FA;&#x6210;&#x4E8C;&#x8FDB;&#x5236;&#x3002;&#x5BF9;&#x4E8E;&#x67D0;&#x4E00;&#x4E2A;&#x7C7B;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x4F55;&#x5E8F;&#x5217;&#x5316;&#x4EE5;&#x53CA;&#x5E8F;&#x5217;&#x5316;&#x90A3;&#x4E9B;&#x72B6;&#x6001;&#xFF0C;&#x8FD9;&#x4E9B;&#x90FD;&#x662F;&#x5C5E;&#x4E8E;&#x7C7B;&#x7684;&#x884C;&#x4E3A;&#xFF0C;&#x5176;&#x4ED6;&#x7684;&#x7C7B;&#x6CA1;&#x5FC5;&#x8981;&#x77E5;&#x9053;&#x8FD9;&#x4E9B;&#x7EC6;&#x8282;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5F53;&#x8981;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5BF9;&#x8C61;&#x4F9D;&#x8D56;&#x7684;&#x5F15;&#x7528;&#x662F;&#x4E00;&#x4E2A;null&#x65F6;&#xFF0C;&#x8FD9;&#x4E2A;&#x662F;&#x4E0D;&#x4F1A;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E2A;&#x4F9D;&#x8D56;&#x5BF9;&#x8C61;&#x7684;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5728;&#x4E0A;&#x8FF0;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x5F53;serializable&#x5BF9;&#x8C61;&#x4E2D;sc&#x7684;&#x5F15;&#x7528;&#x4E3A;NUll&#x65F6;&#xFF0C;&#x5E8F;&#x5217;&#x5316;serializable&#x5BF9;&#x8C61;&#x662F;&#x6CA1;&#x6709;&#x95EE;&#x9898;&#x7684;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>{</div><div class="line">    <span class="comment">//&#x4E0D;&#x521D;&#x59CB;&#x5316;sc</span></div><div class="line">    JavaSerializable serializable = <span class="keyword">new</span> JavaSerializable();</div><div class="line">    ObjectOutputStream objectOutputStream = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">&quot;/tmp/obj.ser&quot;</span>));</div><div class="line">    <span class="comment">//&#x6210;&#x529F;&#x5E8F;&#x5217;&#x5316;serializable&#x5BF9;&#x8C61;</span></div><div class="line">    objectOutputStream.writeObject(serializable);</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x901A;&#x8FC7;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x6062;&#x590D;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;&#x65F6;&#xFF0C;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x5E76;&#x4E0D;&#x4F1A;&#x8C03;&#x7528;&#x7C7B;&#x7684;&#x6784;&#x9020;&#x51FD;&#x6570;&#x3002;<br>&#x6709;&#x5173;&#x66F4;&#x8FC7;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#xFF1A;<br>  <a href="http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html" target="_blank" rel="external">http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html</a></p>
<p>&#x968F;&#x7740;&#x5206;&#x5E03;&#x5F0F;&#x7CFB;&#x7EDF;&#x7684;&#x53D1;&#x5C55;&#x548C;&#x6D41;&#x884C;&#xFF0C;&#x5F88;&#x591A;&#x6846;&#x67B6;&#x91C7;&#x7528;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x673A;&#x5236;&#x6765;&#x5B9E;&#x73B0;&#x8FDB;&#x7A0B;&#x4E4B;&#x95F4;&#x901A;&#x4FE1;&#xFF0C;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x4FDD;&#x5B58;&#x4EE5;&#x53CA;&#x8FDB;&#x7A0B;&#x4E2D;&#x4E00;&#x4E9B;&#x72B6;&#x6001;&#x7684;&#x6301;&#x4E45;&#x5316;&#x3002;&#x5982;<a href="http://storm.apache.org/" target="_blank" rel="external">storm</a>&#x4E2D;&#x7684;worker&#x4F1A;&#x5468;&#x671F;&#x6027;&#x7684;&#x5C06;&#x4E00;&#x4E9B;&#x72B6;&#x6001;&#x4FE1;&#x606F;&#x5199;&#x5165;&#x5230;&#x6307;&#x5B9A;&#x7684;&#x76EE;&#x5F55;&#x4E2D;&#xFF0C;Supervisor&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E9B;&#x4FE1;&#x606F;&#xFF0C;&#x5F97;&#x5230;worker&#x7684;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#xFF1B;hadoop MapReduce&#x4F1A;&#x5C06;Mapper&#x8F93;&#x51FA;&#x7684;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x5E8F;&#x5217;&#x5316;&#x6210;&#x4E8C;&#x8FDB;&#x5236;&#x6587;&#x4EF6;&#xFF1B;thrift&#x4F1A;&#x5C06;&#x5BA2;&#x6237;&#x7AEF;&#x7684;&#x8C03;&#x7528;&#x5E8F;&#x5217;&#x5316;(&#x5305;&#x62EC;&#x65B9;&#x6CD5;&#x540D;&#xFF0C;&#x4EE5;&#x53CA;&#x65B9;&#x6CD5;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x53C2;&#x6570;&#x4FE1;&#x606F;)&#xFF0C;&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x540E;&#x4E8C;&#x8FDB;&#x5236;&#x6D41;&#x4EA4;&#x7ED9;&#x670D;&#x52A1;&#x7AEF;&#x6765;&#x89E3;&#x6790;&#xFF0C;&#x5B9E;&#x73B0;&#x8FDC;&#x7A0B;&#x8C03;&#x7528;&#x7B49;&#x7B49;&#x3002;&#x9488;&#x5BF9;Java&#x5E8F;&#x5217;&#x5316;&#x6539;&#x8FDB;&#x7684;&#x5E8F;&#x5217;&#x5316;&#x6846;&#x67B6;&#x4E5F;&#x5F00;&#x59CB;&#x53D8;&#x5F97;&#x591A;&#x8D77;&#x6765;,&#x5982;<a href="https://github.com/eishay/jvm-serializers/wiki" target="_blank" rel="external">&#x4E00;&#x4E9B;&#x5E8F;&#x5217;&#x5316;&#x5BF9;&#x6BD4;&#x548C;&#x6D4B;&#x8BD5;</a>&#x3002;</p>
<p><strong><em>Spark&#x4E0E;&#x5E8F;&#x5217;&#x5316;</em></strong></p>
<p>   &#x5BF9;&#x4E8E;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#x6765;&#x8BF4;&#xFF0C;&#x4ECE;&#x8BA1;&#x7B97;&#x4EA7;&#x751F;&#x7684;&#x539F;&#x56E0;&#x7684;&#x89D2;&#x5EA6;&#x4E0A;&#x770B;&#xFF0C;&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x4E24;&#x7C7B;&#xFF1A;&#x4E00;&#x79CD;&#x662F;&#x57FA;&#x4E8E;&#x4E8B;&#x4EF6;&#x9A71;&#x52A8;&#x7684;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#xFF0C;&#x5982;storm&#xFF1B;&#x53E6;&#x4E00;&#x79CD;&#x662F;&#x57FA;&#x4E8E;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#xFF0C;&#x5982;MapReduce&#x3002;&#x4EE5;&#x8FD9;&#x4E24;&#x79CD;&#x7C7B;&#x578B;&#x6765;&#x5206;&#x7C7B;&#x7684;&#x8BDD;&#xFF0C; Spark&#x662F;&#x5C5E;&#x4E8E;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5FC5;&#x987B;&#x5148;&#x6709;&#x6570;&#x636E;&#xFF0C;&#x800C;&#x540E;&#x624D;&#x80FD;&#x8FDB;&#x884C;&#x4E00;&#x4E9B;&#x6570;&#x636E;&#x64CD;&#x4F5C;&#xFF0C;&#x6570;&#x636E;&#x4E0E;&#x64CD;&#x4F5C;&#x4E4B;&#x95F4;&#x662F;&#x76F8;&#x4E92;&#x5206;&#x79BB;&#x7684;&#x3002;&#x8FD9;&#x4E9B;&#x6570;&#x636E;&#x7531;&#x4E00;&#x6761;&#x6761;&#x8BB0;&#x5F55;&#x6784;&#x6210;(&#x53EF;&#x7C7B;&#x6BD4;&#x6210;&#x4F20;&#x7EDF;&#x5173;&#x7CFB;&#x578B;&#x6570;&#x636E;&#x5E93;&#x4E2D;&#x884C;&#x7684;&#x6982;&#x5FF5;)&#xFF0C;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x4E4B;&#x95F4;&#x5173;&#x7CFB;&#x677E;&#x6563;, &#x6CA1;&#x6709;&#x4E0A;&#x4E0B;&#x6587;(&#x8BED;&#x4E49;)&#x3002;&#x5728;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x62BD;&#x8C61;&#x51FA;&#x67D0;&#x4E9B;&#x884C;&#x4E3A;&#x7279;&#x5F81;&#xFF0C;&#x5C3D;&#x7BA1;&#x5BF9;&#x8BB0;&#x5F55;&#x7684;&#x64CD;&#x4F5C;(&#x7EC6;&#x8282;)&#x4F1A;&#x5343;&#x5DEE;&#x4E07;&#x522B;&#xFF0C;Spark&#x5B9A;&#x4E49;&#x4E86;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x96C6;(RDD), &#x4EE5;&#x53CA;&#x9488;&#x5BF9;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x96C6;&#x7684;&#x4E00;&#x4E9B;&#x64CD;&#x4F5C;(&#x63A5;&#x53E3;)&#xFF0C;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x5219;&#x7531;&#x7528;&#x6237;&#x81EA;&#x5DF1;&#x6765;&#x5B9E;&#x73B0;&#x3002;</p>
<p>   &#x62BD;&#x8C61;&#x662F;Spark&#x4E00;&#x4E2A;&#x5F88;&#x663E;&#x8457;&#x7684;&#x7279;&#x5F81;&#xFF0C;&#x6570;&#x636E;&#x88AB;&#x62BD;&#x8C61;&#x6210;&#x6570;&#x636E;&#x96C6;(RDD)&#xFF0C;&#x5728;&#x6BCF;&#x4E2A;&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x8BB0;&#x5F55;&#x4E86;&#xFF1A;</p>
<ul>
<li>A list of partitions &#x7531;&#x90A3;&#x4E9B;&#x6570;&#x636E;&#x5B50;&#x96C6;&#x6784;&#x6210;</li>
<li>A function for computing each split &#x5B50;&#x96C6;&#x4E2D;&#x6BCF;&#x6761;&#x8BB0;&#x5F55;&#x5982;&#x4F55;&#x8BA1;&#x7B97;(&#x8BA1;&#x7B97;&#x56E0;&#x5B50;&#xFF09;</li>
<li>A list of dependencies on other RDDs &#x4F9D;&#x8D56;&#x4E8E;&#x7684;&#x6570;&#x636E;&#x96C6;(parent RDD&#xFF09;</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned) &#x5982;&#x4F55;&#x5C06;&#x8BE5;&#x6570;&#x636E;&#x96C6;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x5B9A;&#x4F4D;&#x5230;&#x4E0B;&#x4E00;&#x4E2A;RDD&#x4E2D;</li>
<li><p>Optionally, a list of preferred locations to compute each split on (e.g. block locations foran HDFS file) &#x4F4D;&#x7F6E;&#x4FE1;&#x606F;</p>
<p>RDD&#x4E2D;&#x7684;&#x8FD9;&#x4E9B;&#x7279;&#x5F81;&#x5305;&#x542B;&#x4E86;&#xFF1A; 1&#xFF0C; &#x6211;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x4ECE;&#x4F55;&#x800C;&#x6765;&#xFF1B; 2&#xFF0C;&#x6211;&#x8981;&#x600E;&#x6837;&#x8BA1;&#x7B97;&#x6E90;&#x6570;&#x636E;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x5F97;&#x5230;&#x6570;&#x636E;&#x96C6;&#xFF1B; 3&#xFF0C; &#x6211;&#x5982;&#x4F55;&#x5C06;&#x6211;&#x7684;&#x8BA1;&#x7B97;&#x7ED3;&#x679C;&#x8F93;&#x51FA;&#x4EE5;&#x53CA;&#x4E00;&#x4E9B;&#x4F18;&#x5316;&#x63AA;&#x65BD;&#xFF08;&#x8BA1;&#x7B97;&#x4E0E;&#x6570;&#x636E;&#x672C;&#x5730;&#x5316;)&#x3002;&#x8BA1;&#x7B97;&#x6570;&#x636E;&#x672C;&#x8EAB;&#x6CA1;&#x6709;&#x4E0A;&#x4E0B;&#x6587;&#x7684;&#x4F18;&#x52BF;&#xFF0C;&#x9002;&#x7528;&#x5206;&#x6CBB;&#x7B97;&#x6CD5;&#x7684;&#x57FA;&#x672C;&#x601D;&#x8DEF;&#xFF0C;&#x5C06;&#x6570;&#x636E;&#x5207;&#x5272;&#x6210;&#x4E00;&#x4E2A;&#x4E2A;&#x76F8;&#x4E92;&#x72EC;&#x7ACB;&#x7684;&#x788E;&#x7247;&#xFF0C;&#x5229;&#x7528;&#x5E76;&#x884C;&#x4F18;&#x52BF;&#x6765;&#x52A0;&#x901F;&#x8BA1;&#x7B97;&#x3002; &#x8FD9;&#x4E0D;&#x4EC5;&#x53EF;&#x4EE5;&#x7F29;&#x77ED;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#x7684;&#x65F6;&#x95F4;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x9002;&#x7528;&#x4E8E;&#x6D77;&#x91CF;&#x6570;&#x636E;&#x7684;&#x95EE;&#x9898;&#x3002;MapReduce, Spark&#x5C31;&#x662F;&#x8FD9;&#x6837;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002;</p>
<p>&#x7EFC;&#x4E0A;&#x6240;&#x53D9;&#xFF0C;&#x4ECE;&#x5B8F;&#x89C2;&#x4E0A;&#x770B;&#xFF0C;&#x53EF;&#x4EE5;&#x8FD9;&#x6837;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;RDD:</p>
<p>  <em>rdd = f(g(h(&#x2026;rdd0&#x2026;)))</em></p>
<p>f,g,h &#x4E3A;&#x8BA1;&#x7B97;&#x56E0;&#x5B50;&#xFF0C;&#x5982;filter&#xFF0C;map&#xFF0C;groupByKey&#x7B49;&#x3002;</p>
<p>&#x5982;&#x4E0A;&#xFF0C;&#x8FD9;&#x4E9B;f,g,h&#x51FD;&#x6570;&#x7684;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x662F;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x3002;&#x4ECE;&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x6765;&#x770B;&#xFF0C;&#x6211;&#x4EEC;&#x6240;&#x505A;&#x7684;&#x5DE5;&#x4F5C;&#x662F;&#x63D0;&#x4EA4;&#x4E00;&#x4E2A;jar&#x6587;&#x4EF6;&#xFF0C;Spark&#x8981;&#x505A;&#x7684;&#x5C31;&#x662F;&#x5C06;jar&#x4E2D;&#x5B9A;&#x4E49;&#x7684;&#x7C7B;&#x4F3C;&#x4E8E;f&#xFF0C;g&#xFF0C;h&#x8FD9;&#x6837;&#x7684;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x5206;&#x53D1;&#x5230;&#x5206;&#x5E03;&#x5F0F;&#x96C6;&#x7FA4;&#x4E0A;&#xFF0C;&#x5B9E;&#x73B0;&#x5E76;&#x884C;&#x8BA1;&#x7B97;&#xFF0C;&#x5F53;&#x7136;&#x5305;&#x62EC;&#x4E00;&#x4E9B;&#x5BB9;&#x9519;&#x63AA;&#x65BD;&#x3002;<br>&#x8981;&#x5B9E;&#x73B0;&#x8FD9;&#x4E9B;&#x7279;&#x70B9;&#xFF0C;&#x5219;&#x5FC5;&#x987B;&#x56DE;&#x7B54;&#x4EE5;&#x4E0B;&#x4E00;&#x4E9B;&#x95EE;&#x9898;&#xFF1A;<br>1, &#x600E;&#x6837;&#x62C9;&#x53D6;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x3002;<br>2&#xFF0C;&#x5982;&#x4F55;&#x5C06;f&#x51FD;&#x6570;&#x5206;&#x53D1;&#x5230;&#x5408;&#x9002;&#x7684;&#x673A;&#x5668;&#x4E0A;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;<br>3&#xFF0C;&#x5982;&#x4F55;&#x8BA1;&#x7B97;&#x3002;<br>&#x4EE5;&#x4E00;&#x4E2A;WordCount&#x4E3A;&#x4F8B;&#xFF1A;</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"> <span class="keyword">val</span> textFile = sc.textFile(<span class="string">&quot;hdfs:///tmp/spark.text&quot;</span>)</div><div class="line"> <span class="keyword">val</span> counts = textFile.flatMap(line =&gt; line.split(<span class="string">&quot;\\s+&quot;</span>))</div><div class="line">                 .map(word =&gt; (word, <span class="number">1</span>))</div><div class="line">                 .reduceByKey(_ + _)</div><div class="line"> counts.saveAsTextFile(<span class="string">&quot;hdfs:///tmp/result&quot;</span>)</div><div class="line">``` </div><div class="line"></div><div class="line">&#x6267;&#x884C; <span class="keyword">val</span> textFile &#xFF1D; sc.textFile(<span class="string">&quot;hdfs:///tmp/spark.text&quot;</span>) &#x8FD9;&#x6761;&#x8BED;&#x53E5;&#x65F6;&#xFF0C;&#x8FD4;&#x56DE;&#x7684;&#x662F;<span class="type">HadoopRDD</span>&#xFF0C; &#x8FD9;&#x4E2A;<span class="type">HadoopRDD</span>&#x7531;&#xFF0C;</div><div class="line"></div><div class="line">```scala</div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = {</div><div class="line">    <span class="keyword">val</span> jobConf = getJobConf()</div><div class="line">    <span class="comment">// add the credentials here as this can be called before SparkContext initialized</span></div><div class="line">    <span class="type">SparkHadoopUtil</span>.get.addCredentials(jobConf)</div><div class="line">    <span class="keyword">val</span> inputFormat = getInputFormat(jobConf)</div><div class="line">    <span class="keyword">val</span> inputSplits = inputFormat.getSplits(jobConf, minPartitions)</div><div class="line">    <span class="keyword">val</span> array = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Partition</span>](inputSplits.size)</div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until inputSplits.size) {</div><div class="line">      array(i) = <span class="keyword">new</span> <span class="type">HadoopPartition</span>(id, i, inputSplits(i))</div><div class="line">    }</div><div class="line">    array</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x6BCF;&#x4E2A;&#x5177;&#x4F53;&#x7684;RDD&#x5B9E;&#x4F8B;&#x4E0A;&#x63D0;&#x4F9B;&#x4E86;&#x8FED;&#x4EE3;&#x5668;&#x6A21;&#x5F0F;&#x6765;&#x5C01;&#x88C5;RDD&#x5185;&#x90E8;&#x4E00;&#x6761;&#x6761;&#x8BB0;&#x5F55;&#x7684;&#x8BBF;&#x95EE;, &#x5982;HadoopRDD&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> iter = <span class="keyword">new</span> <span class="type">NextIterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] {</div><div class="line">     <span class="keyword">val</span> split = theSplit.asInstanceOf[<span class="type">HadoopPartition</span>]</div><div class="line">     logInfo(<span class="string">&quot;Input split: &quot;</span> + split.inputSplit)</div><div class="line">     <span class="keyword">val</span> jobConf = getJobConf()</div><div class="line">     ...</div><div class="line">     <span class="keyword">var</span> reader: <span class="type">RecordReader</span>[<span class="type">K</span>, <span class="type">V</span>] = <span class="literal">null</span></div><div class="line">     <span class="keyword">val</span> inputFormat = getInputFormat(jobConf)</div><div class="line">     <span class="comment">//&#x5F97;&#x5230;&#x8BE5;RDD&#x5B9E;&#x4F8B;&#x8981;&#x5904;&#x7406;&#x7684;InputSplit&#xFF0C;&#x6839;&#x636E;&#x8FD9;&#x4E2A;InputSplit&#x4EE5;&#x53CA;InputFormat&#x5F97;&#x5230;&#x5C06;&#x5185;&#x5BB9;&#x89E3;&#x6790;&#x6210;&#x4E00;&#x6761;&#x6761;&lt;key value&gt;&#x7684;reader</span></div><div class="line">     reader = inputFormat.getRecordReader(split.inputSplit.value, jobConf, <span class="type">Reporter</span>.<span class="type">NULL</span>)</div><div class="line">    </div><div class="line">     <span class="keyword">val</span> key: <span class="type">K</span> = reader.createKey()</div><div class="line">     <span class="keyword">val</span> value: <span class="type">V</span> = reader.createValue()</div><div class="line"></div><div class="line">     <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getNext</span></span>(): (<span class="type">K</span>, <span class="type">V</span>) = {</div><div class="line">       <span class="keyword">try</span> {</div><div class="line">         finished = !reader.next(key, value)</div><div class="line">       } <span class="keyword">catch</span> {</div><div class="line">         <span class="keyword">case</span> eof: <span class="type">EOFException</span> =&gt;</div><div class="line">           finished = <span class="literal">true</span></div><div class="line">       }</div><div class="line">       <span class="keyword">if</span> (!finished) {</div><div class="line">         inputMetrics.incRecordsRead(<span class="number">1</span>)</div><div class="line">       }</div><div class="line">       (key, value)</div><div class="line">     }</div><div class="line"></div><div class="line"> }</div><div class="line">  <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>[(<span class="type">K</span>, <span class="type">V</span>)](context, iter)</div></pre></td></tr></table></figure>
<p> <em>val textFile &#xFF1D; sc.textFile(&#x201C;hdfs:///tmp/spark.text&#x201D;)</em> &#x8FD9;&#x4E00;&#x6B65;&#x8FD4;&#x56DE;&#x4E86;HadoopRDD&#x7684;&#x5B9A;&#x4E49;(&#x5176;&#x5B9E;&#x8FD4;&#x56DE;&#x7684;&#x662F;MapPartitionsRDD&#xFF0C;HadoopRDD&#x8FD4;&#x56DE;&#x7684;<long, text="">&#x952E;&#x503C;&#x5BF9;&#x66F4;&#x6539;&#x6210;value.toString, &#x4E3A;&#x4E86;&#x63CF;&#x8FF0;&#x7B80;&#x4FBF;&#xFF0C;&#x7701;&#x7565;&#x4E86;&#x8FD9;&#x4E00;&#x6B65;&#xFF0C;&#x5177;&#x4F53;&#x8FC7;&#x7A0B;&#x53EF;&#x67E5;&#x770B;SparkContext.textFile&#x6E90;&#x7801;)&#xFF0C;&#x5305;&#x62EC;HadoopRDD&#x5305;&#x542B;&#x54EA;&#x4E9B;partition&#xFF0C;&#x4EE5;&#x53CA;HadoopRDD&#x5B9E;&#x4F8B;&#x662F;&#x600E;&#x6837;&#x83B7;&#x5F97;&#x6570;&#x636E;(compute).<br>&#x5F53;&#x6267;&#x884C;&#x5230;&#x8FD9;&#x4E00;&#x8BED;&#x53E5;&#x65F6;&#xFF0C;<br>  textFile.flatMap(line =&gt; line.split(&#x201C;\s+&#x201D;))&#xFF0C; &#x8FD4;&#x56DE;&#x4E00;&#x4E2A;MapPartitionsRDD&#xFF0C;</long,></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> *  Return a new RDD by first applying a function to all elements of this</div><div class="line"> *  RDD, and then flattening the results.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>] = withScope {</div><div class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</div><div class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.flatMap(cleanF))</div><div class="line">}</div></pre></td></tr></table></figure>
<p>&#x6211;&#x4EEC;&#x81EA;&#x5B9A;&#x4E49;flatMap&#x7684;&#x903B;&#x8F91;f: line =&gt; line.split(&#x201C;\s+&#x201D;)&#xFF0C;&#x7ECF;&#x8FC7;<em>val cleanF = sc.clean(f)</em>&#x6E05;&#x6D17;&#x52A0;&#x5DE5;(&#x53BB;&#x9664;&#x539F;f&#x4E2D;&#x4E00;&#x4E9B;&#x65E0;&#x6548;&#x7684;&#x53D8;&#x91CF;&#x6216;&#x903B;&#x8F91;&#xFF1F;&#xFF09;&#xFF0C;&#x5F53;&#x8BA1;&#x7B97;&#x8BE5;MapPartitionsRDD&#x5B9E;&#x4F8B;&#x4E2D;&#x7684;&#x8BB0;&#x5F55;&#x65F6;&#xFF0C;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">MapPartitionsRDD</span>[<span class="type">U</span>: <span class="type">ClassTag</span>, <span class="type">T</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></div><div class="line">    var prev: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">    f: (<span class="type">TaskContext</span>, <span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) <span class="title">=&gt;</span> <span class="title">Iterator</span>[<span class="type">U</span>],  <span class="title">//</span> (<span class="params"><span class="type">TaskContext</span>, partition index, iterator</span>)</div><div class="line">    preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>)</div><div class="line">  <span class="keyword">extends</span> <span class="type">RDD</span>[<span class="type">U</span>](prev) {</div><div class="line">  <span class="comment">//&#x5728;&#x8BE5;&#x5B9E;&#x4F8B;&#x4E2D;&#xFF1A; firstParent -&gt; HadoopRDD</span></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">U</span>] = {</div><div class="line">    <span class="keyword">val</span> iter = firstParent[<span class="type">T</span>].iterator(split, context);</div><div class="line">    <span class="keyword">val</span> index = split.index</div><div class="line">    f(context, index, iter)</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x5F53;MapPartitionsRDD&#x5B9E;&#x4F8B;&#x8C03;&#x7528;compute&#x65B9;&#x6CD5;&#xFF0C;&#x751F;&#x6210;&#x8BE5;RDD&#x4E0A;&#x7684;&#x8FED;&#x4EE3;&#x5668;&#x65F6;&#x3002;&#x9996;&#x5148;&#x67E5;&#x770B;&#x5B83;&#x4F9D;&#x8D56;&#x7684;RDD(firstParent)&#x8981;&#x4E00;&#x4E2A;&#x5BF9;&#x5E94;split&#x7684;&#x8FED;&#x4EE3;&#x5668;&#xFF0C;spark&#x9996;&#x5148;&#x67E5;&#x770B;&#x8BE5;rdd split&#x662F;&#x5426;&#x88AB;&#x7F13;&#x5B58;&#xFF0C;&#x5982;&#x679C;&#x88AB;&#x7F13;&#x5B58;&#x5219;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#xFF0C;&#x5219;&#x8C03;&#x7528;parent rdd&#x7684;compute&#x65B9;&#x6CD5;&#x8BA1;&#x7B97;&#x51FA;&#x6765;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x9012;&#x5F52;&#x8BA1;&#x7B97;&#x7684;&#x8FC7;&#x7A0B;&#x3002;MapPartitionsRDD&#x5728;&#x8C03;&#x7528;compute&#x65F6;&#xFF0C;&#x6709;&#x4E2A;<em>f(context, index, iter)</em>, &#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x8C03;&#x7528;&#x7B49;&#x4EF7;&#x4E8E;&#xFF1A;<em>iter(HadoopRDD&#x8FED;&#x4EE3;&#x5668;).flatMap(line =&gt; line.split(&#x201C;\s+&#x201D;)</em> </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">B</span>](f: <span class="type">A</span> =&gt; <span class="type">GenTraversableOnce</span>[<span class="type">B</span>]): <span class="type">Iterator</span>[<span class="type">B</span>] = <span class="keyword">new</span> <span class="type">AbstractIterator</span>[<span class="type">B</span>] {</div><div class="line">   <span class="keyword">private</span> <span class="keyword">var</span> cur: <span class="type">Iterator</span>[<span class="type">B</span>] = empty</div><div class="line">   <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> =</div><div class="line">     cur.hasNext || self.hasNext &amp;&amp; { cur = f(self.next).toIterator; hasNext }</div><div class="line">   <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">B</span> = (<span class="keyword">if</span> (hasNext) cur <span class="keyword">else</span> empty).next()</div><div class="line"> }</div></pre></td></tr></table></figure>
<p>&#x53EF;&#x89C1;&#xFF0C;&#x6211;&#x4EEC;&#x5177;&#x4F53;&#x7684;&#x4E1A;&#x52A1;&#x903B;&#x8F91;(line =&gt; line.split(&#x201C;\s+&#x201D;))&#x662F;&#x5728;<em>f(self.next)</em>&#x8FD9;&#x8C03;&#x7528;&#x7684;&#xFF0C; &#x800C;self.next&#x83B7;&#x5F97;&#x7684;&#x662F;HadoopRDD&#x8FED;&#x4EE3;&#x5668;&#x4E2D;&#x4E0B;&#x4E00;&#x6761;&#x8BB0;&#x5F55;&#x3002;</p>
<p>&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x5F53;Spark driver&#x6267;&#x884C;&#x5230;&#x8FD9;&#x4E00;&#x6B65;&#x65F6;&#xFF0C;&#x5C5E;&#x4E8E;&#x8FD9;&#x4E2A;Application&#x7684;&#x8FDB;&#x7A0B;&#x96C6;&#x5408;&#x5E76;&#x6CA1;&#x6709;task&#x5728;&#x8FD0;&#x884C;&#xFF0C;&#x56E0;&#x4E3A;RDD&#x5B9E;&#x4F8B;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x4E2A;iterator&#x63A5;&#x53E3;&#xFF0C;&#x5176;&#x5185;&#x90E8;&#x6570;&#x636E;&#x5982;&#x4F55;&#x8BA1;&#x7B97;&#x4EE5;&#x53CA;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x600E;&#x6837;&#x88AB;&#x83B7;&#x53D6;&#xFF0C;&#x8FD9;&#x5BF9;&#x4E8E;&#x5176;&#x5B83;&#x7684;RDD&#x6765;&#x8BF4;&#x662F;&#x4E0D;&#x53EF;&#x89C1;&#x7684;&#xFF0C;&#x4E5F;&#x6CA1;&#x5FC5;&#x8981;&#x77E5;&#x9053;&#x3002; &#x8981;&#x60F3;&#x771F;&#x6B63;&#x8BA9;&#x6570;&#x636E;&#x52A8;&#x8D77;&#x6765;(rdd.action)&#xFF0C;&#x5219;&#x9700;&#x8981;&#x8FD9;&#x6837;&#xFF1A;</p>
<p><pre><br>  while (iter.hasNext) {<br>     func(iter.next)<br>  }<br> iter.hasNext -&gt; iter1.hasNext -&gt; iter2.hasNext -&gt; &#x2026;.. -&gt; itern.hasNext<br> iter.next -&gt; iter1.next -&gt; &#x2026;&#x2026;. -&gt; itern.next<br> </pre><br> &#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;&#xFF0C;&#x5219;&#x662F;&#x5728;&#x8C03;&#x7528;&#x8FD9;&#x4E9B;iter1.hasNext&#x6216;&#x8005;iter.next&#x7684;&#x65F6;&#x5019;&#x88AB;&#x6267;&#x884C;(rdd&#x6709;&#x4E2A;mapPartitions&#x65B9;&#x6CD5;&#x548C;&#x8FD9;&#x91CC;&#x8BF4;&#x7684;&#x4E0D;&#x4E00;&#x81F4;&#xFF09;<br> &#x5982;rdd.reduce:</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(f: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span> = withScope {</div><div class="line">   <span class="keyword">val</span> cleanF = sc.clean(f)</div><div class="line">   <span class="comment">//reducePartition&#x88AB;&#x5E8F;&#x5217;&#x5316;&#x5230;executors&#x4E2D;&#x6267;&#x884C;</span></div><div class="line">   <span class="keyword">val</span> reducePartition: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Option</span>[<span class="type">T</span>] = iter =&gt; {</div><div class="line">     <span class="keyword">if</span> (iter.hasNext) {</div><div class="line">       <span class="type">Some</span>(iter.reduceLeft(cleanF))</div><div class="line">     } <span class="keyword">else</span> {</div><div class="line">       <span class="type">None</span></div><div class="line">     }</div><div class="line">   }</div><div class="line">   ...</div><div class="line"> }</div></pre></td></tr></table></figure>
<p>&#x56DE;&#x5230;&#x6700;&#x521D;&#x7684;&#x95EE;&#x9898;&#xFF0C;Spark&#x4E0E;&#x5E8F;&#x5217;&#x5316;&#x6709;&#x4F55;&#x5173;&#x7CFB;&#xFF1F;<br>&#x7531;&#x4E0A;&#x6587;&#x7684;&#x5206;&#x6790;&#x53EF;&#x77E5;&#xFF0C;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;&#x88AB;&#x5185;&#x5D4C;&#x5230;RDD&#x7684;&#x5B9A;&#x4E49;&#x4E2D;(&#x901A;&#x8FC7;&#x6784;&#x9020;&#x51FD;&#x6570;), &#x8FD9;&#x4E9B;&#x903B;&#x8F91;&#x968F;RDD&#x4E00;&#x8D77;&#x88AB;&#x5206;&#x53D1;&#x5230;application&#x53EF;&#x7528;&#x7684;&#x8FDB;&#x7A0B;&#x4E0A;&#x53BB;&#x6267;&#x884C;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x903B;&#x8F91;&#x662F;RDD&#x4E2D;&#x4E00;&#x4E2A;&#x6709;&#x72B6;&#x6001;&#x7684;&#x6210;&#x5458;&#x53D8;&#x91CF;&#xFF0C;Spark driver&#x901A;&#x8FC7;&#x5C06;RDD&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5C06;&#x7ED3;&#x679C;&#x5C01;&#x88C5;&#x5230;&#x76F8;&#x5E94;&#x7684;Task&#x4E2D;&#xFF0C;&#x8FD9;&#x90E8;&#x5206;&#x7EC6;&#x8282;&#x53EF;&#x5728;DAGScheduler.submitMissingTasks&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">    <span class="keyword">try</span> {</div><div class="line">      <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">      <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">      <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> {</div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">          closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">          closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">      }</div><div class="line"></div><div class="line">      taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">    }</div><div class="line">    </div><div class="line">  <span class="comment">//...</span></div><div class="line">     <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">          partitionsToCompute.map { id =&gt;</div><div class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">            <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">              taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">          }</div><div class="line"></div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">          <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">          partitionsToCompute.map { id =&gt;</div><div class="line">            <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">            <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">              taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">     }</div></pre></td></tr></table></figure>
<p>&#x5C06;&#x6211;&#x4EEC;&#x7684;&#x903B;&#x8F91;&#x5E8F;&#x5217;&#x5316;&#x540E;&#xFF0C;&#x901A;&#x8FC7;&#x6784;&#x9020;&#x51FD;&#x6570;&#x4F20;&#x5165;&#x5230;&#x76F8;&#x5E94;&#x7684;Task&#x4E2D;&#xFF0C;TaskSetManager&#x518D;&#x5C06;task&#x5E8F;&#x5217;&#x5316;&#xFF0C;driver&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x7ED3;&#x679C;&#x53D1;&#x9001;&#x5230;executor&#xFF0C; executor&#x5148;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x5F97;&#x5230;task&#x5B9E;&#x4F8B;&#xFF0C;&#x63A5;&#x7740;&#x518D;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x5F97;&#x5230;rdd&#x548C;&#x4F9D;&#x8D56;&#x5173;&#x7CFB;(dependency)&#x3002;<br>&#x5728;<a href="https://issues.apache.org/jira/browse/SPARK-7708" target="_blank" rel="external">SPARK-7708</a>&#x63D0;&#x5230;&#xFF0C;&#x76EE;&#x524D;&#x5E76;&#x4E0D;&#x80FD;&#x652F;&#x6301;kyro&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E9B;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#xFF0C;&#x5728;&#x672A;&#x53EF;&#x66FF;&#x4EE3;&#x7684;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;&#x4F7F;&#x7528;&#x7684;&#x662F;Java&#x672C;&#x8EAB;&#x63D0;&#x4F9B;&#x7684;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x5199;&#x6211;&#x4EEC;&#x7684;&#x903B;&#x8F91;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x9075;&#x5FAA;Java&#x5E8F;&#x5217;&#x5316;&#x63D0;&#x4F9B;&#x7684;&#x89C4;&#x5219;&#x3002;&#x5305;&#x62EC;&#xFF0C;<strong>&#x5728;&#x6211;&#x4EEC;&#x5199;&#x7684;&#x903B;&#x8F91;&#x4E2D;&#x5305;&#x542B;&#x4F9D;&#x8D56;&#x7684;&#x7C7B;&#xFF0C;&#x5982;&#x679C;&#x6709;&#x72B6;&#x6001;&#x7684;&#x5168;&#x5C40;&#x53D8;&#x91CF;(&#x9012;&#x5F52;&#xFF0C;&#x5BF9;&#x8C61;&#x76F8;&#x5173;)&#x4E0D;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5219;&#x4F1A;&#x51FA;&#x73B0;&#x5E8F;&#x5217;&#x5316;&#x95EE;&#x9898;&#x7B49;</strong>&#xFF0C; &#x8FD9;&#x4E2A;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<em>spark.closure.serializer</em>&#x53EF;&#x914D;&#x7F6E;&#x3002; &#x540C;&#x65F6;&#xFF0C;&#x4E86;&#x89E3;&#x5230;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;f&#xFF0C;&#x4F1A;&#x5206;&#x53D1;&#x5728;&#x4E0D;&#x540C;&#x7684;JVM&#x4E0A;&#x6267;&#x884C;&#xFF0C;&#x610F;&#x5473;&#x7740;&#x53EF;&#x80FD;&#x5B58;&#x5728;&#x4E00;&#x4E9B;&#x8FD9;&#x6837;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x8FD9;&#x662F;&#x5206;&#x5E03;&#x5F0F;&#x7F16;&#x7A0B;&#x7279;&#x522B;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x95EE;&#x9898;&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> counter = <span class="number">0</span></div><div class="line"><span class="keyword">var</span> rdd = sc.parallelize(data)</div><div class="line"></div><div class="line"><span class="comment">// Wrong: Don&apos;t do this!!</span></div><div class="line">rdd.foreach(x =&gt; counter += x)</div><div class="line"><span class="comment">//&#x5728;&#x5206;&#x5E03;&#x5F0F;&#x73AF;&#x5883;&#x4E0B;&#xFF0C;&#x53EF;&#x80FD;&#x6BCF;&#x6B21;&#x8FD4;&#x56DE;&#x7684;&#x503C;&#x51FA;&#x73B0;&#x4E0D;&#x4E00;&#x81F4;</span></div><div class="line">println(<span class="string">&quot;Counter value: &quot;</span> + counter)</div></pre></td></tr></table></figure>
<p><a href="http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka" target="_blank" rel="external">Prior to execution, Spark computes the task&#x2019;s closure. The closure is those variables and methods which must be visible for the executor to perform its computations on the RDD (in this case foreach()). This closure is serialized and sent to each executor.<br>The variables within the closure sent to each executor are now copies and thus, when counter is referenced within the foreach function, it&#x2019;s no longer the counter on the driver node. There is still a counter in the memory of the driver node but this is no longer visible to the executors! The executors only see the copy from the serialized closure. Thus, the final value of counter will still be zero since all operations on counter were referencing the value within the serialized closure.</a><br>&#x53E6;&#x5916;&#xFF0C;&#x5728;spark&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;&#x5230;&#x4E86;&#x5E8F;&#x5217;&#x5316;&#x6765;&#x4FDD;&#x5B58;shuffle&#x7684;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;,&#x51CF;&#x5C11;&#x7F51;&#x7EDC;&#x4F20;&#x8F93;;&#x6709;&#x65F6;&#x4E3A;&#x907F;&#x514D;&#x540C;&#x4E00;&#x4E2A;RDD&#x91CD;&#x590D;&#x8BA1;&#x7B97;&#xFF0C;&#x9700;&#x8981;&#x4FDD;&#x5B58;&#x67D0;&#x4E2A;RDD&#x4E0A;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<a href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence" target="_blank" rel="external">RDD Persist API</a>, &#x4F7F;&#x7528;&#x5E8F;&#x5217;&#x5316;&#x6765;&#x51CF;&#x5C11;&#x5185;&#x5B58;&#x4F7F;&#x7528;&#x91CF;(MEMORY_ONLY_SER)&#x6216;&#x8005;disk&#x7684;&#x5360;&#x7528;&#x7A7A;&#x95F4;(MEMORY_AND_DISK_SER)&#x3002;<a href="https://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="external">&#x5BF9;&#x4E8E;&#x5927;&#x591A;&#x6570;&#x5E94;&#x7528;&#x6765;&#x8BF4;&#xFF0C;&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x66F4;&#x6539;&#x6210;kyro&#xFF0C;&#x5C06;&#x6570;&#x636E;&#x4EE5;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5F62;&#x5F0F;&#x6765;&#x4FDD;&#x5B58;&#xFF0C;&#x53EF;&#x4EE5;&#x89E3;&#x51B3;&#x5927;&#x90E8;&#x5206;&#x5E94;&#x7528;&#x7684;&#x6027;&#x80FD;&#x95EE;&#x9898;&#x3002;</a>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//switch to using Kryo by initializing your job with a SparkConf</span></div><div class="line">conf.set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>).</div></pre></td></tr></table></figure>
<p>&#x6765;&#x914D;&#x7F6E;&#x6216;&#x4FEE;&#x6539;&#x8FD9;&#x90E8;&#x5206;Spark&#x7684;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x3002;<br><br>&#x672C;&#x6587;&#x6240;&#x4F5C;&#x7684;&#x5206;&#x6790;&#x4E0D;&#x8FC7;&#x662F;Spark&#x4E2D;&#x7684;&#x51B0;&#x5C71;&#x4E00;&#x89D2;&#xFF0C;&#x6587;&#x4E2D;&#x4E0D;&#x5F53;&#x6216;&#x9519;&#x8BEF;&#x4E4B;&#x5904;&#xFF0C;&#x6B22;&#x8FCE;&#x6279;&#x8BC4;&#x6307;&#x6B63;&#x3002;</p>
<p><strong><em>Useful links: <br></em></strong></p>
<ul><br>  <li><a href="http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/" target="_blank" rel="external">http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/</a></li><br>  <li><a href="https://github.com/JerryLead/SparkInternals" target="_blank" rel="external">https://github.com/JerryLead/SparkInternals</a></li><br>  <li><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/programming-guide.html</a></li><br>  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html" target="_blank" rel="external">https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html</a></li><br>  <li><a href="http://blog.madhukaraphatak.com/kryo-disk-serialization-in-spark/" target="_blank" rel="external">http://blog.madhukaraphatak.com/kryo-disk-serialization-in-spark/</a></li><br>  <li><a href="https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/" target="_blank" rel="external">https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/</a></li><br>  <li><a href="http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka" target="_blank" rel="external">http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka</a></li><br></ul>  

<p>Example:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Spark Pi&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</div><div class="line"><span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"><span class="keyword">var</span> wcount = spark.textFile(<span class="string">&quot;file:///Users/yixin/test&quot;</span>).flatMap(line =&gt; line.split(<span class="string">&quot;\\s+&quot;</span>))</div><div class="line">      .filter(word =&gt; word.startsWith(<span class="string">&quot;f&quot;</span>)).map(word =&gt; (word, <span class="number">1</span>)).cache()</div><div class="line"></div><div class="line"><span class="keyword">var</span> patitions = wcount.mapPartitions(iter =&gt; {</div><div class="line">  <span class="keyword">var</span> buf = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]();</div><div class="line">  <span class="keyword">while</span> (iter.hasNext) {</div><div class="line">    <span class="keyword">var</span> (word, count) = iter.next()</div><div class="line">     buf += (word + <span class="string">&quot;_&quot;</span> + count)</div><div class="line">  }</div><div class="line">  buf.toList.toIterator</div><div class="line">})</div><div class="line"></div><div class="line"><span class="keyword">var</span> iter: <span class="type">Iterator</span>[<span class="type">String</span>] = patitions.compute(<span class="keyword">new</span> <span class="type">Partition</span> {</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">index</span></span>: <span class="type">Int</span> = wcount.partitions.apply(<span class="number">0</span>).index</div><div class="line">},</div><div class="line"> <span class="keyword">new</span> <span class="type">TaskContextImpl</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</div><div class="line">     <span class="keyword">new</span> <span class="type">TaskMemoryManager</span>(<span class="type">SparkEnv</span>.get.memoryManager, <span class="number">0</span>),</div><div class="line">          <span class="type">SparkEnv</span>.get.metricsSystem,</div><div class="line">          internalAccumulators = <span class="type">Seq</span>.empty))</div><div class="line"></div><div class="line"><span class="comment">//How to scan the records in a rdd </span></div><div class="line"><span class="keyword">while</span> (iter.hasNext) {</div><div class="line">    println(<span class="string">&quot;---------&gt;&quot;</span> + iter.next())</div><div class="line">}</div><div class="line">spark.stop()</div></pre></td></tr></table></figure>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="yarn-logaggregator/" class="post-link">另一种支持kerberized yarn对长时间运行的job进行日志归并</a></h2><span class="post-time">Sep 14, 2016</span><div class="post-content"><h3 id="&#x6982;&#x8FF0;"><a href="#&#x6982;&#x8FF0;" class="headerlink" title="&#x6982;&#x8FF0;"></a>&#x6982;&#x8FF0;</h3><p>&#x5728;&#x5DF2;&#x7ECF;&#x89E3;&#x51B3;&#x7684;YARN-2704&#x4E0A;&#xFF0C;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x79CD;&#x89E3;&#x51B3;&#x957F;&#x65F6;&#x4EFB;&#x52A1;(long running job)&#x7531;&#x4E8E;hdfs delegation token&#x5931;&#x6548;(token lifetime&gt;7 day)&#x800C;&#x5BFC;&#x81F4;NodeManager&#x5F52;&#x6863;Application&#x65E5;&#x5FD7;&#x5931;&#x8D25;&#x7684;&#x4E00;&#x79CD;&#x601D;&#x8DEF;&#x3002;<br><img src="/yarn-logaggregator/archi-design.png" alt="archi-design.png" title=""><br>&#x5F53;&#x7528;&#x6237;&#x63D0;&#x4EA4;&#x957F;&#x65F6;&#x4F5C;&#x4E1A;&#x540E;&#xFF0C; &#x7531;ResourceManager&#x6765;&#x7EF4;&#x62A4;&#x8BE5;&#x4F5C;&#x4E1A;&#x7684;hdfs delegation token&#xFF0C; &#x5F53;ResourceManager&#x68C0;&#x6D4B;&#x5230;&#x6709;&#x5982;&#x4E0B;&#x4EFB;&#x4E00;&#x6761;&#x4EF6;&#x53D1;&#x751F;&#x65F6;&#xFF1A;<br>  &#xA0;&#xA0;1, &#x7528;&#x6237;&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x65F6;&#xFF0C;&#x5E76;&#x6CA1;&#x6709;&#x63D0;&#x4F9B;dt(delegation token, &#x4E13;&#x6307;hdfs&#xFF0C;&#x4E0B;&#x540C;)&#x4FE1;&#x606F;&#x3002;<br>  &#xA0;&#xA0;2, dt&#x5373;&#x5C06;&#x5728;10&#x5C0F;&#x65F6;&#x4E4B;&#x540E;&#x8FC7;&#x671F;&#x3002;<br>ResourceManager&#x9700;&#x8981;&#x4EE5;&#x4E00;&#x4E2A;&#x53D7;&#x4FE1;&#x4EFB;&#x7684;&#x4EE3;&#x7406;&#x4EBA;&#x8EAB;&#x4EFD;&#x81EA;&#x52A8;&#x5411;NameNode&#x7533;&#x8BF7;&#x4F5C;&#x4E1A;&#x63D0;&#x4EA4;&#x8005;&#x7684;dt&#x4FE1;&#x606F;&#x3002; &#x83B7;&#x53D6;&#x5230;&#x65B0;&#x7684;dt&#x540E;&#xFF0C;&#x901A;&#x8FC7;&#x4E0E;NodeManager&#x7684;&#x5FC3;&#x8DF3;&#x673A;&#x5236;&#xFF0C;&#x5C06;&#x65B0;&#x83B7;&#x53D6;&#x7684;token&#x544A;&#x77E5;NodeManager&#x3002;&#x7531;&#x6B64;NodeManager&#x53EF;&#x4EE5;&#x89C4;&#x5F8B;&#x6027;&#x7684;&#x66F4;&#x65B0;&#x5173;&#x4E8E;&#x4F5C;&#x4E1A;&#x7684;dt&#x4FE1;&#x606F;&#x3002;&#x5F53;&#x4F5C;&#x4E1A;&#x9000;&#x51FA;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x8BE5;dt&#x83B7;&#x5F97;NameNode&#x7684;&#x8BA4;&#x8BC1;&#xFF0C;&#x5C06;&#x4F5C;&#x4E1A;&#x76F8;&#x5173;&#x7684;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x5230;hdfs&#x7528;&#x6237;&#x7684;&#x76EE;&#x5F55;&#x4E0B;&#x3002;<br>&#x8BE5;&#x65B0;&#x529F;&#x80FD;&#x5DF2;&#x5728;HADOOP2.6.0&#x7248;&#x672C;&#x4E2D;&#x5F97;&#x5230;&#x89E3;&#x51B3;&#xFF0C;&#x8BE5;patch&#x9700;&#x8981;&#x4FEE;&#x6539;&#x6216;&#x6D89;&#x53CA;&#x7684;&#x670D;&#x52A1;&#x6709;&#xFF1A;<br>&#xA0;&#xA0;1, ResourceManager&#x81EA;&#x52A8;&#x66F4;&#x65B0;/&#x83B7;&#x53D6; &#x8FC7;&#x65F6;/&#x4E0D;&#x5B58;&#x5728; &#x7684;dt&#x3002;<br>&#xA0;&#xA0;2, &#x4FEE;&#x6539;RM&#x4E0E;NM&#x7684;&#x901A;&#x4FE1;&#x534F;&#x8BAE;&#xFF0C;&#x4F7F;&#x65B0;&#x7684;dt&#x80FD;&#x591F;&#x53CA;&#x65F6;&#x7684;&#x53D1;&#x5E03;&#x5728;NM&#x4E2D;&#x3002;<br>&#xA0;&#xA0;3, &#x5C06;RM&#x5728;NameNode&#x6807;&#x8BB0;&#x4E3A;&#x4E00;&#x4E2A;&#x53D7;&#x4FE1;&#x4EFB;&#x7684;&#x4EE3;&#x7406;&#x89D2;&#x8272;&#x3002;<br>&#x6D89;&#x53CA;&#x5230;&#x7684;&#x670D;&#x52A1;&#x6709;RM&#x3001;NM&#x4EE5;&#x53CA;NameNode&#xFF0C; &#x66F4;&#x6539;&#x540E;&#x9700;&#x8981;&#x91CD;&#x65B0;&#x542F;&#x52A8;&#x8FD9;&#x4E9B;&#x670D;&#x52A1;&#x3002;</p>
<p>&#x7531;&#x4E8E;&#x7EBF;&#x4E0A;hadoop&#x7248;&#x672C;&#x57FA;&#x4E8E;2.4.1&#xFF0C; &#x4E0D;&#x80FD;&#x76F4;&#x63A5;&#x4F7F;&#x7528;&#x8BE5;patch(YARN-2704)&#xFF0C; &#x8FD9;&#x7ED9;&#x5347;&#x7EA7;&#x8BE5;&#x529F;&#x80FD;&#x5E26;&#x6765;&#x4E00;&#x4E9B;&#x56F0;&#x96BE;&#x3002;&#x76EE;&#x524D;&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;&#x7684;&#x957F;&#x65F6;&#x4EFB;&#x52A1;&#x4E3B;&#x8981;&#x4E3A;Spark Streaming&#x3002;&#x5728;SPARK-5342&#x4E2D;&#xFF0C;&#x4E3A;&#x4E86;&#x89E3;&#x51B3;spark streaming dt&#x8FC7;&#x671F;&#x7684;&#x95EE;&#x9898;&#xFF0C;spark AppMaster&#x901A;&#x8FC7;&#x7528;&#x6237;&#x4E0A;&#x4F20;&#x7684;keytab&#x6587;&#x4EF6;&#x5468;&#x671F;&#x6027;&#x7684;&#x5237;&#x65B0;dt&#xFF0C;&#x5E76;&#x5C06;&#x5237;&#x65B0;&#x540E;&#x7684;dt&#x6301;&#x4E45;&#x5316;&#x5230;&#x5206;&#x5E03;&#x5F0F;&#x7F13;&#x5B58;&#x4E2D;&#xFF0C;&#x5E76;&#x53D1;&#x9001;&#x4E00;&#x4E2A;&#x901A;&#x77E5;&#x7ED9;&#x6267;&#x884C;&#x4EFB;&#x52A1;&#x7684;executors&#xFF0C; executors&#x4ECE;&#x5206;&#x5E03;&#x5F0F;&#x7F13;&#x5B58;&#x4E2D;&#x8BFB;&#x53D6;&#x5230;&#x65B0;&#x7684;dt&#xFF0C; &#x66FF;&#x6362;&#x6389;&#x539F;&#x9648;&#x65E7;&#x7684;dt&#x3002;&#x901A;&#x8FC7;&#x8FD9;&#x6837;&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x6301;&#x7EED;&#x957F;&#x65F6;&#x95F4;&#x7684;&#x6267;&#x884C;&#x4E1A;&#x52A1;&#x903B;&#x8F91;&#x3002;<br><img src="/yarn-logaggregator/spark-token-renew.png" alt="spark-token-renew.png" title=""><br>Spark Streaming&#x7684;&#x8BBE;&#x8BA1;&#x65B9;&#x5F0F;&#xFF0C;&#x53EF;&#x4EE5;&#x5F97;&#x5230;&#x8FD9;&#x4E2A;&#x7ED3;&#x8BBA;&#xFF1A;&#x5F53;Spark Executors&#x6B63;&#x5E38;&#x9000;&#x51FA;&#x65F6;&#xFF0C;&#x5176;&#x7F13;&#x5B58;&#x7684;dt&#x662F;&#x6709;&#x6548;&#x7684;&#xFF0C; &#x53EF;&#x4EE5;&#x7EE7;&#x7EED;&#x7528;&#x4E8E;&#x4E0E;NameNode&#x7684;&#x8BA4;&#x8BC1;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x53EF;&#x4EE5;&#x8BA9;&#x8BE5;executors&#x7684;dt&#x66FF;&#x6362;NM&#x4E0A;&#x5BF9;&#x5E94;&#x7684;&#x5DF2;&#x8FC7;&#x671F;&#x7684;dt&#x6765;&#x652F;&#x6301;NodeManager&#x5BF9;&#x957F;&#x65F6;Spark Streaming&#x4EFB;&#x52A1;&#x7684;container&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x7684;&#x529F;&#x80FD;&#xFF0C; &#x91C7;&#x7528;&#x5982;&#x4E0B;&#x7684;&#x8BBE;&#x8BA1;&#xFF1A;<br><img src="/yarn-logaggregator/mydesign.png" alt="mydesign.png" title=""><br>Executor&#x5C06;&#x672C;&#x5730;&#x7F13;&#x5B58;&#x4E2D;&#x6700;&#x65B0;&#x7684;token&#x5199;&#x5165;&#x5230;&#x672C;&#x5730;&#x78C1;&#x76D8;&#x7684;&#x4E00;&#x4E2A;&#x76EE;&#x5F55;&#x4E2D;&#x3002;&#x5F53;NM&#x7531;&#x4E8E;dt&#x8FC7;&#x671F;&#x539F;&#x56E0;&#x800C;&#x5BFC;&#x81F4;container&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x5931;&#x8D25;&#x65F6;&#xFF0C;&#x4ECE;&#x7EA6;&#x5B9A;&#x7684;&#x76EE;&#x5F55;&#x4E2D;&#x8BFB;&#x53D6;dt A&#xFF0C;&#x66FF;&#x6362;&#x6389;&#x5BF9;&#x5E94;&#x5DF2;&#x8FC7;&#x671F;&#x7684;dt B&#xFF0C; &#x4F7F;&#x7528;dt A&#x6765;&#x5B9E;&#x73B0;&#x4E0E;NameNode&#x7684;&#x8BA4;&#x8BC1;&#x8FC7;&#x7A0B;&#x3002;</p>
<p>&#x6682;&#x4E14;&#x5C06;&#x5B98;&#x65B9;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x79F0;&#x4E4B;&#x4E3A;PA&#xFF0C; &#x53E6;&#x4E00;&#x79CD;&#x66FF;&#x8865;&#x7684;&#x65B9;&#x6848;&#x79F0;&#x4E4B;&#x4E3A;PB&#xFF0C; &#x4E0B;&#x9762;&#x6BD4;&#x8F83;PA&#x548C;PB&#x7684;&#x4F18;&#x7F3A;&#x70B9;&#x3002;</p>
<p>&#xA0;&#xA0;1&#xFF0C;&#x5BF9;&#x4E8E;&#x5F52;&#x6863;&#x5E94;&#x7528;&#x7A0B;&#x5E8F;&#x7684;&#x65E5;&#x5FD7;&#x529F;&#x80FD;&#x6765;&#x8BF4;&#xFF0C;&#x8FD9;&#x5C5E;&#x4E8E;YARN&#x672C;&#x8EAB;&#x7684;&#x804C;&#x8D23;&#x4E4B;&#x4E00;&#x3002; &#x4E5F;&#x5C31;&#x662F;&#x4E0D;&#x7BA1;YARN&#x8C03;&#x7528;&#x4EC0;&#x4E48;&#x6837;&#x7684;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#xFF0C; &#x8BA1;&#x7B97;&#x6846;&#x67B6;&#x4E0D;&#x9700;&#x8981;&#x8003;&#x8651;&#x8FD0;&#x884C;&#x4E8E;&#x5176;&#x4E0A;&#x7684;&#x4E1A;&#x52A1;&#x65E5;&#x5FD7;&#x8BE5;&#x5982;&#x4F55;&#x5904;&#x7406;&#x3002;&#x56E0;&#x6B64;PA&#x5B9E;&#x73B0;&#x66F4;&#x5177;&#x5907;&#x901A;&#x7528;&#x6027;&#xFF0C;&#x800C;PB&#x9700;&#x8981;&#x8003;&#x8651;&#x4E0D;&#x540C;&#x7684;&#x6846;&#x67B6;&#x3002;&#x5982;&#x679C;&#x5C06;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#x66FF;&#x6362;&#x6210;storm&#xFF0C;&#x5219;&#x8FD8;&#x9700;&#x8981;&#x8FDB;&#x884C;&#x989D;&#x5916;&#x7684;&#x4EE3;&#x7801;&#x4FEE;&#x6539;&#x64CD;&#x4F5C;&#x3002;<br>&#xA0;&#xA0;2&#xFF0C;PA&#x5728;&#x5B9E;&#x73B0;&#x4E0A;&#x6BD4;&#x8F83;&#x590D;&#x6742;&#xFF0C;&#x6D89;&#x53CA;&#x5230;&#x7684;&#x670D;&#x52A1;&#x6709;NameNode&#xFF0C;ResourceManager&#xFF0C; NodeManager&#xFF0C;&#x8FD9;&#x4E9B;&#x670D;&#x52A1;&#x9700;&#x8981;&#x91CD;&#x542F;&#x4EE5;&#x652F;&#x6301;&#x8FD9;&#x6837;&#x7684;&#x9700;&#x6C42;&#xFF0C;&#x8FD8;&#x9700;&#x8981;&#x5C06;RM&#x8EAB;&#x4EFD;&#x8BBE;&#x7F6E;&#x4E3A;&#x7C7B;&#x4F3C;&#x4E8E;root&#x7684;&#x89D2;&#x8272;&#xFF0C;&#x5B83;&#x53EF;&#x4EE5;&#x7533;&#x8BF7;&#x4EFB;&#x4F55;&#x7528;&#x6237;&#x7684;dt&#x4FE1;&#x606F;&#x3002;&#x53E6;&#x5916;&#xFF0C;PA &#x65B9;&#x6848;&#x7684;&#x5B9E;&#x73B0;&#x4E5F;&#x4E0D;&#x80FD;&#x76F4;&#x63A5;&#x5E94;&#x7528;&#x4E8E;&#x7EBF;&#x4E0A;&#x7684;hadoop2.4.1&#x7248;&#x672C;&#xFF0C;&#x9700;&#x8981;&#x989D;&#x5916;&#x7684;&#x4FEE;&#x6539;&#x4EE3;&#x7801;&#x5DE5;&#x4F5C;&#x3002;&#x800C;PB&#x5728;&#x5B9E;&#x73B0;&#x4E0A;&#xFF0C;&#x5219;&#x76F8;&#x5BF9;&#x7B80;&#x5355;&#xFF0C;&#x4E14;&#x4FDD;&#x62A4;&#x4E86;&#x89D2;&#x8272;&#x4E4B;&#x95F4;&#x7684;&#x72EC;&#x7ACB;&#x6027;&#x548C;&#x79C1;&#x5BC6;&#x6027;&#x3002;</p>
<p>&#x4E0D;&#x7BA1;yarn&#x4E2D;&#x8FD0;&#x884C;&#x7684;&#x957F;&#x65F6;&#x4EFB;&#x52A1;&#x662F;&#x5982;&#x4F55;&#x4FDD;&#x8BC1;dt&#x6709;&#x6548;(&#x8FD9;&#x53EF;&#x4EE5;&#x662F;&#x57FA;&#x4E8E;RM&#x4EE3;&#x7406;&#x7533;&#x8BF7;&#xFF0C;&#x6216;&#x662F;&#x7C7B;&#x4F3C;&#x4E8E;Spark keytab&#x767B;&#x9646;&#x8BF7;&#x6C42;)&#xFF0C;&#x5728;&#x4E0D;&#x5347;&#x7EA7;yarn&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x53EF;&#x4EE5;&#x8BA4;&#x4E3A;container/executor&#x4E0A;&#x7F13;&#x5B58;&#x7684;dt&#x662F;&#x6709;&#x6548;&#x7684;(&#x8FD9;&#x4E5F;&#x662F;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#x9700;&#x8981;&#x8003;&#x8651;&#x7684;&#x5B89;&#x5168;&#x9700;&#x6C42;)&#xFF0C;&#x56E0;&#x6B64;&#x4E0D;&#x7BA1;&#x4F7F;&#x7528;&#x4F55;&#x79CD;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#xFF0C;PB&#x672C;&#x8EAB;&#x4E5F;&#x5177;&#x5907;&#x4E00;&#x5B9A;&#x7684;&#x901A;&#x7528;&#x6027;&#x3002;<br>&#x57FA;&#x4E8E;&#x6B64;&#xFF0C; &#x91C7;&#x7528;PB&#x65B9;&#x6848;&#x6765;&#x5B9E;&#x73B0;&#x957F;&#x65F6;&#x4EFB;&#x52A1;&#x5F52;&#x6863;app&#x65E5;&#x5FD7;&#x7684;&#x5B89;&#x5168;&#x9700;&#x6C42;&#x3002;</p>
<h3 id="&#x9700;&#x6C42;&#x89C4;&#x8303;"><a href="#&#x9700;&#x6C42;&#x89C4;&#x8303;" class="headerlink" title="&#x9700;&#x6C42;&#x89C4;&#x8303;"></a>&#x9700;&#x6C42;&#x89C4;&#x8303;</h3><p><li> &#x65B0;&#x52A0;&#x5165;&#x7684;&#x529F;&#x80FD;&#x4E0D;&#x80FD;&#x5F71;&#x54CD;&#x5F53;&#x524D;&#x7684;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x903B;&#x8F91;&#xFF0C;&#x5982;dt &lt; 7&#x5929;&#x7684;&#x60C5;&#x51B5;&#xFF0C; &#x5927;&#x90E8;&#x5206;&#x975E;&#x957F;&#x65F6;&#x4EFB;&#x52A1;&#x53EF;&#x4EE5;&#x7EE7;&#x7EED;&#x6CBF;&#x7740;&#x76EE;&#x524D;&#x7684;&#x903B;&#x8F91;&#x6267;&#x884C;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x5DE5;&#x4F5C;&#x3002;</li></p>
<p><li> &#x52A0;&#x5165;&#x7684;&#x4EE3;&#x7801;&#x5C3D;&#x91CF;&#x4E0E;hadoop/spark&#x4EE3;&#x7801;&#x4FDD;&#x6301;&#x9694;&#x79BB;&#xFF0C;&#x51CF;&#x5C11;&#x65B0;&#x589E;&#x4EE3;&#x7801;&#x4E0E;&#x6E90;&#x4EE3;&#x7801;&#x7684;&#x6DF7;&#x6742;&#x5EA6;&#x3002;</li></p>
<p><li> &#x4EE3;&#x7801;&#x89C4;&#x8303;&#x7B26;&#x5408;hadoop&#x5B9A;&#x4E49;&#xFF0C;&#x7F16;&#x5199;&#x57FA;&#x672C;&#x7684;&#x6D4B;&#x8BD5;&#x7528;&#x4F8B;&#x6D4B;&#x8BD5;&#x65B0;&#x589E;&#x7684;&#x4EE3;&#x7801;&#x3002;</li></p>
<h3 id="&#x5B9E;&#x73B0;&#x8981;&#x70B9;"><a href="#&#x5B9E;&#x73B0;&#x8981;&#x70B9;" class="headerlink" title="&#x5B9E;&#x73B0;&#x8981;&#x70B9;"></a>&#x5B9E;&#x73B0;&#x8981;&#x70B9;</h3><p>1, &#x4EC0;&#x4E48;&#x65F6;&#x5019;&#x5C06;executor&#x7F13;&#x5B58;&#x7684;dt&#x5199;&#x5165;&#x672C;&#x5730;&#x78C1;&#x76D8;&#x4E2D;?<br> &#x5F53;executor&#x83B7;&#x53D6;&#x5230;&#x4E00;&#x4E2A;&#x65B0;&#x7684;token&#x65F6;&#xFF0C;&#x5C06;dt&#x5E8F;&#x5217;&#x5316;&#x5230;&#x8BE5;container&#x7684;&#x4E34;&#x65F6;&#x76EE;&#x5F55;&#x4E2D;&#x7684;&#x4E00;&#x4E2A;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x6587;&#x4EF6;&#x53EF;&#x547D;&#x540D;&#x4E3A;container_tokens_update&#x3002;</p>
<p>2, &#x4EC0;&#x4E48;&#x65F6;&#x5019;NM&#x9700;&#x8981;&#x4ECE;&#x672C;&#x5730;&#x78C1;&#x76D8;&#x4E2D;&#x8BFB;&#x53D6;&#x8BE5;dt&#x66FF;&#x6362;&#x5DF2;&#x8FC7;&#x671F;&#x7684;&#x5BF9;&#x5E94;&#x7684;token?<br>&#x5F53;NM&#x5728;&#x505A;app&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x65F6;&#xFF0C;&#x53D1;&#x751F;RemoteException&#xFF0C;&#x4E14;&#x5224;&#x65AD;&#x8BE5;exception&#x662F;&#x7531;dt&#x8FC7;&#x671F;&#x800C;&#x5F15;&#x8D77;&#x7684;&#xFF0C;&#x6B64;&#x65F6;NM&#x4ECE;&#x7EA6;&#x5B9A;&#x7684;&#x6587;&#x4EF6;&#x4E2D;&#x8BFB;&#x53D6;&#x5BF9;&#x5E94;&#x5E94;&#x7528;&#x7684;dt&#x4FE1;&#x606F;&#xFF0C;&#x4F7F;&#x7528;&#x8BE5;dt&#x5B8C;&#x6210;&#x4E0E;NN&#x8BA4;&#x8BC1;&#x8FC7;&#x7A0B;&#x3002;</p>
<p>3, &#x5982;&#x4F55;&#x6E05;&#x9664;executor&#x5199;&#x5165;&#x7684;dt&#x6587;&#x4EF6;&#x4FE1;&#x606F;?<br>&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x4EA4;&#x7ED9;NM&#x6765;&#x505A;, &#x5728;yarn-site.xml&#x6587;&#x4EF6;&#x4E2D;&#x901A;&#x8FC7;&#x914D;&#x7F6E; yarn.nodemanager.delete.debug-delay-sec &#x6765;&#x63A7;&#x5236;Application&#x4E34;&#x65F6;&#x6587;&#x4EF6;&#x4EC0;&#x4E48;&#x65F6;&#x5019;&#x4F1A;&#x88AB;&#x6E05;&#x9664;&#x3002;</p>
<p>4, &#x5982;&#x4F55;&#x4FDD;&#x8BC1;&#x4EE3;&#x7801;&#x7684;&#x5BF9;&#x539F;&#x6846;&#x67B6;&#x7684;&#x4FB5;&#x5165;&#x6027;&#x6700;&#x5C0F;?<br>NM&#x53EF;&#x4EE5;&#x901A;&#x8FC7;yarn.nodemanager.delegationtoken.retry.enabled&#x914D;&#x7F6E;&#x9879;&#x914D;&#x7F6E;&#x662F;&#x5426;&#x652F;&#x6301;&#x8BE5;&#x9879;&#x5C5E;&#x6027;&#xFF0C;&#x8BE5;&#x5C5E;&#x6027;&#x9ED8;&#x8BA4;&#x4E3A;false(&#x5173;&#x95ED;)&#x3002;</p>
<p>5, &#x5BF9;&#x4E8E;spark streaming&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x4F55;&#x4FDD;&#x8BC1;&#x6700;&#x65B0;&#x7684;dt&#x5E8F;&#x5217;&#x5316;&#x5230;&#x78C1;&#x76D8;&#x4E2D;? &#x8BE5;&#x64CD;&#x4F5C;&#x662F;&#x5426;&#x4F1A;&#x5F71;&#x54CD;&#x5230;&#x8282;&#x70B9;&#x7684;IO&#x6027;&#x80FD;?<br>&#x5F53;executor&#x83B7;&#x53D6;&#x5230;&#x4E00;&#x4E2A;&#x65B0;&#x7684;token&#x65F6;&#xFF0C;&#x5373;&#x5C06;&#x8BE5;token&#x5199;&#x5165;&#x5230;&#x78C1;&#x76D8;&#x4E2D;&#xFF0C;&#x6309;&#x7167;spark&#x5B89;&#x5168;&#x8BBE;&#x8BA1;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x79CD;&#x5468;&#x671F;&#x6027;&#x7684;&#x884C;&#x4E3A;&#xFF0C;&#x53EF;&#x4EE5;&#x4FDD;&#x8BC1;&#x5E8F;&#x5217;&#x5316;&#x5230;&#x78C1;&#x76D8;&#x4E2D;&#x7684;token&#x662F;&#x6700;&#x65B0;&#x7684;&#x3002;<br>&#x6309;&#x7167;&#x7EBF;&#x4E0A;&#x96C6;&#x7FA4;&#x7684;&#x914D;&#x7F6E;&#xFF0C; &#x6BCF;&#x4E00;&#x4E2A;Spark Executor&#x6BCF;&#x4E00;&#x5929;&#x90FD;&#x5C06;&#x4F1A;&#x6709;&#x4E00;&#x6B21;&#x5199;&#x78C1;&#x76D8;&#x7684;&#x64CD;&#x4F5C;&#xFF0C;&#x5BF9;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;&#x8282;&#x70B9;&#x6765;&#x8BF4;&#xFF0C; &#x5047;&#x8BBE;&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#x8BE5;&#x53F0;&#x673A;&#x5668;&#x4E0A;&#x8FD0;&#x884C;&#x6709;100&#x4E2A;Spark Executor&#x4F5C;&#x4E1A;&#xFF0C; &#x90A3;&#x4E48;&#x4E00;&#x5929;&#x6700;&#x591A;&#x6709;100&#x6B21;&#x8FD9;&#x6837;&#x7684;&#x5199;&#x78C1;&#x76D8;&#x7684;&#x64CD;&#x4F5C;(&#x5206;&#x522B;&#x5199;&#x4E0D;&#x540C;&#x7684;&#x6587;&#x4EF6;)&#xFF0C;&#x5728;hadoop2.4.1&#x6D4B;&#x8BD5;&#x96C6;&#x7FA4;&#x4E0A;&#xFF0C;&#x5199;&#x5165;&#x7684;&#x6570;&#x636E;&#x91CF;&#x7EA6;&#x5728;200&#x5B57;&#x8282;&#x5DE6;&#x53F3;&#x3002;&#x5F53;Spark App&#x9000;&#x51FA;&#x65F6;&#xFF0C;NM&#x53EA;&#x9700;&#x4E00;&#x6B21;&#x8BFB;&#x64CD;&#x4F5C;(&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x5E94;&#x7528;)&#x3002; &#x8FD9;&#x6837;&#x7684;&#x64CD;&#x4F5C;&#x5BF9;&#x8282;&#x70B9;&#x7684;IO&#x538B;&#x529B;&#x53EF;&#x4EE5;&#x8BF4;&#x5F88;&#x5C0F;&#x3002;</p>
<p>6, NM&#x53EF;&#x80FD;&#x6CA1;&#x6709;&#x6743;&#x9650;&#x8BBF;&#x95EE;&#x8BE5;&#x76EE;&#x5F55;&#xFF0C;&#x5982;&#x4F55;&#x786E;&#x4FDD;NM&#x53EF;&#x4EE5;&#x8BBF;&#x95EE;&#x8BE5;&#x76EE;&#x5F55;?<br>&#x4ECE;NM&#x53EF;&#x4EE5;&#x5220;&#x9664;App&#x7684;&#x76EE;&#x5F55;&#x6765;&#x770B;&#xFF0C;&#x8BBF;&#x95EE;App&#x79C1;&#x6709;&#x7684;&#x76EE;&#x5F55;&#x8FD8;&#x662F;&#x6709;&#x53EF;&#x80FD;&#x7684;&#x3002;<br>executor jvm&#x5B9E;&#x4F8B;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#xFF1A;<br>-Djava.io.tmpdir=/home/hadoop/tmp/hadoop-root/nm-local-dir/usercache/root/appcache/application_1461156446723_0057/container_1461156446723_0057_01_000003/tmp<br>&#x83B7;&#x5F97;&#x672C;&#x5730;&#x79C1;&#x6709;&#x76EE;&#x5F55;&#x3002;</p>
<p>7, &#x66F4;&#x6539;&#x6D89;&#x53CA;&#x5230;&#x4EC0;&#x4E48;&#x670D;&#x52A1;?<br>NodeManager&#x548C;Spark Executor</p>
<p>8, Spark&#x52A8;&#x6001;&#x8D44;&#x6E90;&#x8C03;&#x5EA6;&#x662F;&#x5426;&#x4F1A;&#x5BF9;&#x8BE5;&#x5B9E;&#x73B0;&#x65B9;&#x6848;(PB)&#x4EA7;&#x751F;&#x5F71;&#x54CD;?<br>spark&#x52A8;&#x6001;&#x8D44;&#x6E90;&#x8C03;&#x5EA6;&#x5305;&#x62EC;&#x521B;&#x5EFA;&#x65B0;&#x7684;executor&#x6216;&#x8005;&#x56DE;&#x6536;&#x591A;&#x4F59;&#x7684;executor&#x3002;Yarn&#x5F52;&#x6863;container&#x8FD9;&#x4E2A;&#x64CD;&#x4F5C;&#x662F;&#x5728;&#x6574;&#x4E2A;App&#x9000;&#x51FA;&#x65F6;&#x8FDB;&#x884C;&#x7684;&#xFF0C; &#x53EF;&#x80FD;&#x5B58;&#x5728;&#x67D0;&#x4E9B;container&#x7531;&#x4E8E;&#x9000;&#x51FA;&#x65F6;&#x95F4;&#x65E9;&#x800C;&#x5BFC;&#x81F4;&#x5E8F;&#x5217;&#x5316;&#x5230;&#x672C;&#x5730;&#x7684;dt&#x8FC7;&#x671F;&#xFF0C;&#x8FD9;&#x5BFC;&#x81F4;NM&#x65E0;&#x6CD5;&#x56DE;&#x6536;&#x8FD9;&#x4E9B;container&#x7684;&#x65E5;&#x5FD7;&#x3002;&#x8BE5;&#x65B9;&#x6848;&#x5C3D;&#x6700;&#x5927;&#x7684;&#x52AA;&#x529B;&#x6536;&#x96C6;App&#x9000;&#x51FA;&#x65F6;&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x6216;&#x8005;&#x521A;&#x9000;&#x51FA;&#x4E0D;&#x4E45;&#x7684;&#x5BB9;&#x5668;(Executor)&#x7684;&#x65E5;&#x5FD7;&#xFF0C;&#x8FD9;&#x90E8;&#x5206;&#x65E5;&#x5FD7;&#x53EF;&#x4EE5;&#x8F85;&#x52A9;&#x67E5;&#x660E;App&#x9000;&#x51FA;&#x7684;&#x539F;&#x56E0;&#x3002;</p>
<h3 id="&#x6D4B;&#x8BD5;"><a href="#&#x6D4B;&#x8BD5;" class="headerlink" title="&#x6D4B;&#x8BD5;"></a>&#x6D4B;&#x8BD5;</h3><p>1, &#x6D4B;&#x8BD5;Spark executor&#x662F;&#x5426;&#x5C06;credentials&#x5E8F;&#x5217;&#x5316;&#x5230;&#x78C1;&#x76D8;&#x4E2D;&#x3002;<br>2, &#x975E;&#x5B89;&#x5168;&#x96C6;&#x7FA4;&#x4E0A;&#x7684;&#x6D4B;&#x8BD5;&#x3002;<br>3, &#x5B89;&#x5168;&#x96C6;&#x7FA4;&#x4E0A;&#xFF0C;&#x6B63;&#x5E38;&#x4F5C;&#x4E1A;&#x7ED3;&#x675F;&#x65F6;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x6D4B;&#x8BD5;&#x3002;<br>4, Spark Streaming&#x4E0E;NodeManager&#x96C6;&#x6210;&#x6D4B;&#x8BD5;&#x3002;<br>5, NM&#x5BB9;&#x9519;&#x5904;&#x7406;&#x3002;<br>&#x672C;&#x6587;&#x63CF;&#x8FF0;&#x4E3B;&#x8981;&#x9488;&#x5BF9;NM&#x5BB9;&#x9519;&#x5904;&#x7406;&#xFF0C;&#x8003;&#x8651;&#x53EF;&#x80FD;&#x6709;&#x5982;&#x4E0B;&#x60C5;&#x51B5;&#xFF1A;<br>  &#xA0;&#xA0;&#xA0;&#xA0;a, App Executor&#x91CD;&#x542F;&#x591A;&#x6B21;&#x3002;<br>  &#xA0;&#xA0;&#xA0;&#xA0;b, App AM&#x91CD;&#x542F;&#x591A;&#x6B21;&#x3002;<br>&#xA0;&#xA0;<strong>App Executor&#x91CD;&#x542F;&#x591A;&#x6B21;</strong><br>&#x5047;&#x8BBE;&#x4E00;&#x4E2A;Executor&#x53EF;&#x80FD;&#x88AB;&#x91CD;&#x542F;&#x591A;&#x6B21;&#xFF0C;&#x5148;NM A&#x540E;NM B&#xFF0C; &#x5BF9;&#x4E8E;&#x8FD9;&#x6837;&#x7684;&#x60C5;&#x51B5;&#x5F53;NM A&#x4E2D;dt&#x8FC7;&#x671F;&#x540E;&#xFF08;&#x5305;&#x62EC;&#x5DF2;&#x88AB;&#x6301;&#x4E45;&#x5316;&#x540E;&#x7684;&#x65B0;dt&#xFF09;, &#x5F53;&#x8BE5;App&#x9000;&#x51FA;&#x65F6;&#xFF0C;&#x8BE5;Executor&#x4F4D;&#x4E8E;NM A&#x4E0A;&#x7684;&#x65E5;&#x5FD7;&#x5C06;&#x88AB;&#x4E22;&#x5931;&#x3002;&#x901A;&#x8FC7;&#x8FD9;&#x6837;&#x7684;&#x65B9;&#x6848;&#x6765;&#x5F52;&#x5E76;&#x65E5;&#x5FD7;&#xFF0C;&#x76EE;&#x524D;&#x7684;&#x5B9E;&#x73B0;&#x53EA;&#x80FD;&#x505A;&#x5230;&#x5728;App&#x9000;&#x51FA;&#x7684;&#x90A3;&#x4E00;&#x523B;&#xFF0C;&#x5C06;&#x8BE5;App&#x5728;&#x96C6;&#x7FA4;&#x8303;&#x56F4;&#x5185;&#x6B63;&#x5728;&#x8FD0;&#x884C;(&#x6216;&#x6700;&#x8FD1;&#x9000;&#x51FA;&#xFF0C;&#x6216;&#x8BE5;NM&#x5305;&#x542B;&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x6216;&#x6700;&#x8FD1;&#x9000;&#x51FA;)&#x7684;container&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x3002;&#x8FD9;&#x5BF9;&#x4E8E;&#x957F;&#x65F6;Spark&#x52A8;&#x6001;&#x8C03;&#x5EA6;&#x673A;&#x5236;&#x6765;&#x8BF4;&#xFF0C; &#x53EF;&#x80FD;&#x662F;&#x4E00;&#x4E2A;&#x5E76;&#x4E0D;&#x53CB;&#x597D;&#x7684;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x65B9;&#x6848;&#xFF0C; &#x96C6;&#x7FA4;&#x7528;&#x6237;&#x53EF;&#x80FD;&#x53D1;&#x73B0;&#x67D0;&#x4E9B;Executor&#x51FA;&#x73B0;&#x65E5;&#x5FD7;&#x4E22;&#x5931;&#x7684;&#x60C5;&#x51B5;&#x3002;<br>  &#x5F53;App&#x9000;&#x51FA;&#x65F6;&#xFF0C;&#x76F8;&#x5173;&#x7684;NM&#x624D;&#x4F1A;&#x6267;&#x884C;container&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x7684;&#x903B;&#x8F91;&#xFF0C;&#x5C06;NM&#x4E0A;&#x8FD0;&#x884C;&#x8FC7;&#x7684;container&#x65E5;&#x5FD7;&#x6279;&#x91CF;&#x5199;&#x5165;&#x5230;hdfs&#x4E2D;&#x4E00;&#x4E2A;&#x4E34;&#x65F6;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x5F52;&#x6863;&#x5B8C;&#x6BD5;&#x65F6;&#xFF0C;&#x5C06;&#x8BE5;&#x4E34;&#x65F6;&#x6587;&#x4EF6;&#x91CD;&#x547D;&#x540D;&#x4E3A;&#x6700;&#x7EC8;&#x7684;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x540D;&#x5B57;&#xFF0C; &#x8FD9;&#x8FB9;&#x6D89;&#x53CA;&#x5230;&#x7684;hdfs&#x64CD;&#x4F5C;&#x6709;append&#x4EE5;&#x53CA;rename&#x3002;<br>&#x4E3A;&#x4E86;&#x4E0D;&#x8BA9;App&#x7684;&#x65E5;&#x5FD7;&#x53D1;&#x751F;&#x4E22;&#x5931;&#xFF0C;&#x5F53;NM&#x53D1;&#x73B0;&#x4E00;&#x4E2A;container&#x7ED3;&#x675F;&#x65F6;&#xFF0C;&#x5373;&#x53EF;&#x5C06;&#x8BE5;container&#x65E5;&#x5FD7;&#x4E0A;&#x4F20;&#xFF0C;&#x7531;&#x4E8E;NM&#x5E76;&#x672A;&#x77E5;&#x9053;&#x8BE5;container&#x662F;&#x5426;&#x662F;App&#x5728;&#x8BE5;&#x96C6;&#x7FA4;&#x4E0A;&#x8FD0;&#x884C;&#x7684;&#x6700;&#x540E;&#x7684;&#x4E00;&#x4E2A;container&#xFF0C;&#x52A0;&#x5165;&#x5C06;&#x8BE5;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;append&#x5230;&#x4E00;&#x4E2A;&#x4E34;&#x65F6;&#x6587;&#x4EF6;&#xFF0C;&#x90A3;&#x4E48;&#x53EF;&#x80FD;NM&#x5728;&#x6267;&#x884C;rename&#x64CD;&#x4F5C;&#x65F6;&#xFF0C;&#x629B;&#x51FA;&#x540C;&#x6837;&#x7684;TokenInvalid(Token not found in cache)&#x5F02;&#x5E38;&#x3002;<br>&#xA0;&#xA0;<strong>App AM&#x91CD;&#x542F;&#x591A;&#x6B21;</strong><br>&#x5F53;AM&#x91CD;&#x542F;&#x65F6;&#xFF0C;&#x53EF;&#x80FD;&#x56E0;&#x4E3A;&#x4F7F;&#x7528;&#x65E7;&#x6709;&#x7684;token&#x800C;&#x5BFC;&#x81F4;&#x91CD;&#x542F;&#x5931;&#x8D25;(yarn&#x95EE;&#x9898;)&#x3002;&#x5728;&#x6D4B;&#x8BD5;&#x65F6;&#xFF0C;&#x53D1;&#x73B0;&#x5728;Spark1.4.1&#x7684;&#x7248;&#x672C;&#x4E0A;&#xFF0C;&#x7F13;&#x5B58;&#x7684;FileSystem&#x5B9E;&#x4F8B;&#x4F7F;&#x7528;&#x7684;&#x662F;&#x9648;&#x65E7;&#x7684;dt&#xFF0C;&#x8FD9;&#x5728;token&#x7684;&#x6709;&#x6548;&#x671F;&#x6BD4;&#x8F83;&#x77ED;&#x7684;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x9020;&#x6210;Executor&#x5C06;&#x6C38;&#x4E45;&#x4E0D;&#x80FD;&#x83B7;&#x5F97;AM&#x7684;&#x65B0;&#x7684;token&#x3002;&#x5F15;&#x5165;&#x793E;&#x533A;&#x7684;patch&#x6765;&#x89E3;&#x51B3;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;(SPARK-8688)&#x3002;&#x5728;SPARK1.5.2&#x7248;&#x672C;&#x4E0A;&#xFF0C;&#x89E3;&#x51B3;&#x4E86;&#x8BE5;&#x95EE;&#x9898;&#x3002;</p>
<h3 id="More"><a href="#More" class="headerlink" title="More"></a>More</h3><p>&#xA0;&#xA0;<strong>&#x9648;&#x65E7;Executor&#x7684;&#x65E5;&#x5FD7;&#x5B58;&#x5728;&#x7531;&#x4E8E;token&#x8FC7;&#x671F;&#x800C;&#x5BFC;&#x81F4;&#x5F52;&#x6863;&#x5931;&#x8D25;&#x7684;&#x53EF;&#x80FD;</strong><br>&#x5BF9;&#x4E8E;&#x96C6;&#x7FA4;&#x4E0A;&#x5927;&#x90E8;&#x5206;&#x5E94;&#x7528;(95%&#x4EE5;&#x4E0A;)&#x6765;&#x8BF4;&#xFF0C; &#x5728;token&#x5931;&#x6548;&#x4E4B;&#x524D;(&gt;7d)&#x53EF;&#x4EE5;&#x6267;&#x884C;&#x5B8C;&#x6BD5;&#xFF0C;NM&#x53EF;&#x4EE5;&#x5728;dt&#x7684;&#x6709;&#x6548;&#x671F;&#x5185;&#x5C06;&#x5E94;&#x7528;&#x7684;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x5230;hdfs&#x4E0A;&#x3002;&#x5BF9;&#x4E8E;&#x957F;&#x65F6;&#x4EFB;&#x52A1;(&gt;7d)&#xFF0C;&#x5C24;&#x5176;&#x662F;&#x5F53;&#x4EFB;&#x52A1;&#x5F00;&#x542F;Spark&#x52A8;&#x6001;&#x8D44;&#x6E90;&#x8C03;&#x5EA6;&#x7684;&#x60C5;&#x5F62;&#x4E0B;&#xFF0C;&#x90A3;&#x4E48;&#x65E5;&#x5FD7;&#x4E22;&#x5931;&#x7684;&#x60C5;&#x51B5;&#x5C06;&#x6781;&#x6709;&#x53EF;&#x80FD;&#x4F1A;&#x666E;&#x904D;&#x5B58;&#x5728;&#x3002;<br>Executor&#x4E0A;&#x7684;&#x65E5;&#x5FD7;&#x4E3B;&#x8981;&#x7528;&#x4E8E;&#x5B9A;&#x4F4D;&#x4E1A;&#x52A1;&#x95EE;&#x9898;&#x6240;&#x7528;&#xFF0C; &#x6709;&#x5982;&#x4E0B;&#x573A;&#x666F;&#xFF1A;<br>&#xA0;&#xA0;1, Executor&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x65F6;&#xFF0C;&#x4E1A;&#x52A1;&#x51FA;&#x73B0;&#x95EE;&#x9898;&#x6216;&#x8005;&#x8FD0;&#x884C;&#x72B6;&#x51B5;&#x8868;&#x73B0;&#x4E0D;&#x6B63;&#x5E38;&#xFF0C;&#x9700;&#x8981;&#x5B9A;&#x4F4D;&#x8FD0;&#x884C;&#x65F6;&#x5B58;&#x5728;&#x7684;&#x95EE;&#x9898;&#x3002;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#xFF0C;&#x53EF;&#x4EE5;&#x5229;&#x7528;&#x73B0;&#x6709;&#x7684;&#x6280;&#x672F;&#x624B;&#x6BB5;&#x6765;&#x5206;&#x6790;&#xFF0C;&#x53EF;&#x4EE5;&#x4E0D;&#x9700;&#x8981;NM&#x8FDB;&#x884C;&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x540E;&#x5728;&#x6765;&#x5206;&#x6790;&#x3002;<br>&#xA0;&#xA0;2, Executor&#x5F02;&#x5E38;&#x9000;&#x51FA;&#xFF0C;&#x9700;&#x8981;&#x67E5;&#x660E;&#x5BFC;&#x81F4;&#x5176;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#x7684;&#x539F;&#x56E0;&#x3002;&#x5BFC;&#x81F4;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#x7684;&#x539F;&#x56E0;&#x53EF;&#x4EE5;&#x5F52;&#x7EB3;&#x4E3A;&#x91CD;&#x590D;&#x6027;&#x7684;(&#x5982;&#x4EE3;&#x7801;bug&#xFF0C;&#x8FD0;&#x884C;&#x6240;&#x9700;&#x73AF;&#x5883;&#x5B58;&#x5728;&#x95EE;&#x9898;)&#x4EE5;&#x53CA;&#x5076;&#x7136;&#x6027;&#x7684;(&#x7F51;&#x7EDC;&#x95EE;&#x9898;&#xFF0C;GC&#x95EE;&#x9898;&#x7B49;)&#x3002;&#x5BF9;&#x4E8E;&#x8FD9;&#x4E9B;&#x573A;&#x666F;&#xFF0C;NM&#x65E5;&#x5FD7;&#x5F52;&#x6863;&#x8FD9;&#x90E8;&#x5206;&#x529F;&#x80FD;&#x5E76;&#x4E0D;&#x4F1A;&#x5F71;&#x54CD;&#x5F02;&#x5E38;&#x539F;&#x56E0;&#x63A2;&#x67E5;&#x4EE5;&#x53CA;&#x4E1A;&#x52A1;&#x8FD0;&#x884C;&#xFF0C; &#x8FD9;&#x4E9B;&#x65E5;&#x5FD7;&#x8FD8;&#x5B58;&#x5728;&#x4E8E;&#x8FD0;&#x884C;&#x7684;&#x5404;&#x4E2A;&#x8282;&#x70B9;&#x4E4B;&#x4E0A;&#x3002;<br>&#xA0;&#xA0;3, App&#x5F02;&#x5E38;&#x9000;&#x51FA;&#xFF0C; &#x9700;&#x8981;&#x67E5;&#x660E;&#x5BFC;&#x81F4;App&#x5F02;&#x5E38;&#x9000;&#x51FA;&#x7684;&#x539F;&#x56E0;&#x3002;&#x8BE5;&#x65B9;&#x6848;&#x5C3D;&#x6700;&#x5927;&#x7684;&#x52AA;&#x529B;&#x6536;&#x96C6;App&#x9000;&#x51FA;&#x65F6;&#x6B63;&#x5728;&#x8FD0;&#x884C;&#x6216;&#x8005;&#x521A;&#x9000;&#x51FA;&#x4E0D;&#x4E45;&#x7684;&#x5BB9;&#x5668;(Executor)&#x7684;&#x65E5;&#x5FD7;&#xFF0C;&#x8FD9;&#x90E8;&#x5206;&#x65E5;&#x5FD7;&#x53EF;&#x4EE5;&#x8F85;&#x52A9;&#x67E5;&#x660E;App&#x9000;&#x51FA;&#x7684;&#x539F;&#x56E0;&#x3002;<br>&#xA0;&#xA0;<strong>&#x5F53;App AM&#x5F02;&#x5E38;&#x9000;&#x51FA;&#x800C;&#x91CD;&#x65B0;&#x542F;&#x52A8;&#x65F6;&#xFF0C;&#x53EF;&#x80FD;&#x5B58;&#x5728;&#x7531;&#x4E8E;token&#x8FC7;&#x671F;&#x800C;&#x5BFC;&#x81F4;AM&#x91CD;&#x542F;&#x5931;&#x8D25;</strong><br>&#x8FD9;&#x548C;&#x8BE5;&#x65B9;&#x6848;&#x5176;&#x5B9E;&#x6CA1;&#x4EC0;&#x4E48;&#x5173;&#x7CFB;&#x3002;&#x5373;&#x4F7F;&#x6CA1;&#x6709;&#x8BE5;&#x65B9;&#x6848;&#xFF0C;&#x5F53;AM&#x91CD;&#x542F;&#x65F6;&#xFF0C;&#x540C;&#x6837;&#x7684;&#x9519;&#x8BEF;&#x8FD8;&#x662F;&#x4F1A;&#x53D1;&#x751F;&#x3002; &#x8FD9;&#x4E5F;&#x662F;&#x8BE5;&#x65B9;&#x6848;&#x7684;&#x4E00;&#x4E2A;&#x5C40;&#x9650;&#xFF0C;&#x8FD9;&#x4E2A;&#x65B9;&#x6848;&#x5176;&#x672C;&#x8D28;&#x5728;&#x4E8E;&#x89E3;&#x51B3;App&#x9000;&#x51FA;&#x65F6;&#xFF0C;NM&#x7531;&#x4E8E;dt&#x5931;&#x6548;&#x800C;&#x5BFC;&#x81F4;&#x5F52;&#x6863;&#x65E5;&#x5FD7;&#x5931;&#x8D25;&#x8FD9;&#x4E00;&#x95EE;&#x9898;&#x57DF;&#x3002;&#x5E76;&#x672A;&#x7275;&#x6D89;&#x5230;&#x66F4;&#x591A;&#x7684;yarn&#x5BB9;&#x9519;&#x7EC6;&#x8282;&#x3002;</p>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="namenode-blockreport-storm/" class="post-link">StandBy NameNode启动失败原因分析</a></h2><span class="post-time">Sep 14, 2016</span><div class="post-content"><h3 id="&#x73B0;&#x8C61;"><a href="#&#x73B0;&#x8C61;" class="headerlink" title="&#x73B0;&#x8C61;"></a>&#x73B0;&#x8C61;</h3><p>&#x5F53;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x91CD;&#x542F;&#x4E00;&#x53F0;&#x5DF2;&#x7ECF;&#x9000;&#x51FA;&#x7684;NameNode&#xFF0C;&#x53D1;&#x73B0;NameNode&#x957F;&#x65F6;&#x95F4;&#x5904;&#x4E8E;Safemode&#x72B6;&#x6001;&#xFF0C;&#x76F4;&#x5230;NameNode&#x518D;&#x6B21;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#xFF0C;&#x65E0;&#x6CD5;&#x5C06;NameNode&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x6B63;&#x5E38;&#x7684;StandBy NameNode&#x3002;</p>
<h3 id="&#x5206;&#x6790;"><a href="#&#x5206;&#x6790;" class="headerlink" title="&#x5206;&#x6790;"></a>&#x5206;&#x6790;</h3><p>&#x7ECF;&#x8FC7;&#x5206;&#x6790;,&#x8BA4;&#x4E3A;SBN&#x542F;&#x52A8;&#x7F13;&#x6162;&#x95EE;&#x9898;&#x4E3B;&#x8981;&#x6709;&#x4EE5;&#x4E0B;2&#x4E2A;&#x95EE;&#x9898;&#x5BFC;&#x81F4;&#xFF0C;&#x5206;&#x522B;&#x662F;:</p>
<p><li>NN&#x5904;&#x7406;DataNode&#x7684;blockreport&#x903B;&#x8F91;&#x95EE;&#x9898;&#xFF1B;</li></p>
<p><li>&#x542F;&#x52A8;&#x540E;NN&#x7531;&#x4E8E;&#x5927;&#x91CF;&#x7684;DateNode&#x7684;blockReport&#x8BF7;&#x6C42;&#xFF0C;&#x9020;&#x6210;&#x6709;&#x4E9B;&#x4E0D;&#x80FD;&#x53CA;&#x65F6;&#x5904;&#x7406;&#xFF0C;&#x5BFC;&#x81F4;&#x65E0;&#x6CD5;&#x54CD;&#x5E94;&#x7528;&#x6237;&#x548C;DataNode&#x8BF7;&#x6C42;&#x3002;</li></p>
<p><li>&#x5927;&#x91CF;BlockReport&#x65E5;&#x5FD7;&#x5728;&#x5176;&#x72EC;&#x5360;&#x9501;&#x5185;&#x8F93;&#x51FA;&#xFF0C;&#x5F71;&#x54CD;&#x8BE5;&#x9501;&#x91CA;&#x653E;&#x7684;&#x901F;&#x7387;&#xFF0C;&#x8FDF;&#x6EDE;&#x5176;&#x4ED6;BlockReport&#x7684;&#x5904;&#x7406;&#xFF0C;&#x540C;&#x65F6;&#x7701;&#x53BB;&#x5728;standbyNN &#x5904;&#x7406;BlockReport&#x65F6;&#x68C0;&#x6D4B;&#x4E0D;&#x5408;&#x6CD5;&#x5757;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x52A0;&#x5FEB;BlockReport&#x7684;&#x5904;&#x7406;&#x901F;&#x5EA6;&#x3002;</li></p>
<p><li>&#x5185;&#x5B58;&#x5F00;&#x9500;&#x3001;gc&#x9891;&#x7E41;&#x95EE;&#x9898;&#x3002;<br>&#x5176;&#x4E2D;&#xFF0C;&#x5C24;&#x5176;&#x662F;&#x7B2C;&#x4E8C;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x5927;&#x91CF;&#x7684;BlockReport&#x8BF7;&#x6C42;&#x8017;&#x5C3D;&#x4E86;NN server&#x5904;&#x7406;&#x8BF7;&#x6C42;&#x7684;&#x7EBF;&#x7A0B;&#x8D44;&#x6E90;&#x3001;&#x8FD9;&#x5BFC;&#x81F4;NN Server&#x4E0D;&#x80FD;&#x53CA;&#x65F6;&#x5730;&#x5904;&#x7406;DataNode&#x7684;&#x5FC3;&#x8DF3;&#x548C;&#x8BE5;&#x8282;&#x70B9;(&#x6216;&#x5176;&#x4ED6;&#x8282;&#x70B9;)&#x7684;BlockReport&#xFF0C;&#x76F4;&#x63A5;&#x5BFC;&#x81F4;&#x8BE5;&#x8282;&#x70B9;&#x6B63;&#x7B49;&#x5F85;&#x88AB;NN Server&#x5904;&#x7406;&#x7684;BlockReport&#x88AB;Client&#xFF08;&#x5373;&#x8BE5;&#x8282;&#x70B9;&#xFF09;&#x8D85;&#x65F6;&#x5904;&#x7406;&#xFF0C;&#x8BE5;Client&#x5C06;&#x4F1A;&#x91CD;&#x65B0;&#x53D1;&#x9001;&#x4E00;&#x4E2A;&#x65B0;&#x7684;BlockReport&#x8BF7;&#x6C42;&#xFF0C;&#x8FD9;&#x65E0;&#x7591;&#x66F4;&#x52A0;&#x91CD;&#x4E86;NN Server&#x7684;&#x8D1F;&#x62C5;&#xFF1B;&#x540C;&#x65F6;&#x4E0D;&#x65AD;&#x7684;&#x63A5;&#x6536;BlockReport&#xFF0C;&#x5BFC;&#x81F4;NN &#x5185;&#x5B58;&#x5F00;&#x9500;&#x6301;&#x7EED;&#x589E;&#x957F;&#xFF0C;&#x800C;&#x8FC7;&#x5927;&#x7684;&#x5185;&#x5B58;&#x9700;&#x6C42;(&#x4E00;&#x4E2A;BlockReport long[]&#x5E73;&#x5747;&#x9700;&#x8981;18M&#x7684;&#x8FDE;&#x7EED;&#x5185;&#x5B58;&#x7A7A;&#x95F4;)&#x4EE5;&#x53CA;&#x6570;&#x636E;&#x5904;&#x7406;&#x9020;&#x6210;NN &#x8FDB;&#x7A0B;gc&#x9891;&#x7E41;&#x3002;</li></p>
<h4 id="NN&#x5904;&#x7406;blockreport&#x903B;&#x8F91;&#x95EE;&#x9898;"><a href="#NN&#x5904;&#x7406;blockreport&#x903B;&#x8F91;&#x95EE;&#x9898;" class="headerlink" title="NN&#x5904;&#x7406;blockreport&#x903B;&#x8F91;&#x95EE;&#x9898;"></a>NN&#x5904;&#x7406;blockreport&#x903B;&#x8F91;&#x95EE;&#x9898;</h4><p>&#x8BE5;&#x95EE;&#x9898;&#x5728;<a href="https://issues.apache.org/jira/browse/HDFS-7980&#x4E5F;&#x6709;&#x76F8;&#x5173;&#x7684;&#x63CF;&#x8FF0;&#xFF0C;&#x4ECE;&#x5BA2;&#x6237;&#x7AEF;&#x4E5F;&#x5C31;&#x662F;&#x96C6;&#x7FA4;&#x7684;DataNode&#x6765;&#x8BF4;&#xFF0C;&#x5F53;NN&#x91CD;&#x542F;&#x540E;&#xFF0C;DataNode&#x901A;&#x8FC7;&#x548C;NN&#x7684;&#x5FC3;&#x8DF3;&#x83B7;&#x5F97;&#x4E00;&#x4E2A;&#x5411;NN&#x6CE8;&#x518C;&#x7684;&#x6307;&#x4EE4;&#xFF0C;DataNode&#x6839;&#x636E;&#x8FD9;&#x4E2A;&#x4FE1;&#x606F;&#xFF0C;&#x5237;&#x65B0;&#x672C;&#x5730;&#x7F13;&#x5B58;&#x4E2D;&#x7684;&#x4E0A;&#x6B21;blockReport&#x7684;&#x7684;&#x65F6;&#x95F4;&#x503C;&#xFF0C;" target="_blank" rel="external">https://issues.apache.org/jira/browse/HDFS-7980&#x4E5F;&#x6709;&#x76F8;&#x5173;&#x7684;&#x63CF;&#x8FF0;&#xFF0C;&#x4ECE;&#x5BA2;&#x6237;&#x7AEF;&#x4E5F;&#x5C31;&#x662F;&#x96C6;&#x7FA4;&#x7684;DataNode&#x6765;&#x8BF4;&#xFF0C;&#x5F53;NN&#x91CD;&#x542F;&#x540E;&#xFF0C;DataNode&#x901A;&#x8FC7;&#x548C;NN&#x7684;&#x5FC3;&#x8DF3;&#x83B7;&#x5F97;&#x4E00;&#x4E2A;&#x5411;NN&#x6CE8;&#x518C;&#x7684;&#x6307;&#x4EE4;&#xFF0C;DataNode&#x6839;&#x636E;&#x8FD9;&#x4E2A;&#x4FE1;&#x606F;&#xFF0C;&#x5237;&#x65B0;&#x672C;&#x5730;&#x7F13;&#x5B58;&#x4E2D;&#x7684;&#x4E0A;&#x6B21;blockReport&#x7684;&#x7684;&#x65F6;&#x95F4;&#x503C;&#xFF0C;</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">scheduleBlockReport</span><span class="params">(<span class="keyword">long</span> delay)</span> </span>{</div><div class="line">    <span class="keyword">if</span> (delay &gt; <span class="number">0</span>) { <span class="comment">// send BR after random delay</span></div><div class="line">      lastBlockReport = Time.now()</div><div class="line">      - ( dnConf.blockReportInterval - DFSUtil.getRandom().nextInt((<span class="keyword">int</span>)(delay)));</div><div class="line">    } <span class="keyword">else</span> { <span class="comment">// send at next heartbeat</span></div><div class="line">      lastBlockReport = lastHeartbeat - dnConf.blockReportInterval;</div><div class="line">    }</div><div class="line">    resetBlockReportTime = <span class="keyword">true</span>; <span class="comment">// reset future BRs for randomness</span></div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x8FD9;&#x4E2A;delay&#x4E5F;&#x5C31;&#x662F;&#x914D;&#x7F6E;dfs.blockreport.initialDelay&#x7684;&#x503C;&#xFF0C;&#x9ED8;&#x8BA4;120s&#xFF0C;&#x76F8;&#x5F53;&#x4E8E;&#x96C6;&#x7FA4;&#x8303;&#x56F4;&#x5185;&#x7684;DataNode&#x4ECE;NN&#x542F;&#x52A8;&#x540E;120s&#x4E4B;&#x5185;&#x5411;NN&#x53D1;&#x9001;&#x4E00;&#x4E2A;blockReport.<br>&#x5728;&#x53D1;&#x9001;blockReport&#x65F6;&#xFF0C;DataNode&#x4F1A;&#x9996;&#x5148;&#x53D1;&#x9001;&#x4E00;&#x4E2A;IBR(Incremental Block Report)&#x62A5;&#x544A;&#xFF0C;&#x7136;&#x540E;&#x5728;&#x53D1;&#x9001;&#x4E00;&#x4E2A;blockReport&#xFF0C;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div></pre></td><td class="code"><pre><div class="line"><span class="function">List&lt;DatanodeCommand&gt; <span class="title">blockReport</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>{</div><div class="line">    <span class="comment">// send block report if timer has expired.</span></div><div class="line">    <span class="keyword">final</span> <span class="keyword">long</span> startTime = now();</div><div class="line">    <span class="keyword">if</span> (startTime - lastBlockReport &lt;= dnConf.blockReportInterval) {</div><div class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    }</div><div class="line">    <span class="keyword">final</span> ArrayList&lt;DatanodeCommand&gt; cmds = <span class="keyword">new</span> ArrayList&lt;DatanodeCommand&gt;();</div><div class="line"></div><div class="line">    <span class="comment">// Flush any block information that precedes the block report. Otherwise</span></div><div class="line">    <span class="comment">// we have a chance that we will miss the delHint information</span></div><div class="line">    <span class="comment">// or we will report an RBW replica after the BlockReport already reports</span></div><div class="line">    <span class="comment">// a FINALIZED one.</span></div><div class="line">    reportReceivedDeletedBlocks();</div><div class="line">    lastDeletedReport = startTime;</div><div class="line">    .........</div><div class="line">        <span class="comment">// Send the reports to the NN.</span></div><div class="line">    <span class="keyword">int</span> numReportsSent = <span class="number">0</span>;</div><div class="line">    <span class="keyword">int</span> numRPCs = <span class="number">0</span>;</div><div class="line">    <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</div><div class="line">    <span class="keyword">long</span> brSendStartTime = now();</div><div class="line">    <span class="keyword">try</span> {</div><div class="line">      <span class="keyword">if</span> (totalBlockCount &lt; dnConf.blockReportSplitThreshold) {</div><div class="line">        <span class="comment">// Below split threshold, send all reports in a single message.</span></div><div class="line">        DatanodeCommand cmd = bpNamenode.blockReport(</div><div class="line">            bpRegistration, bpos.getBlockPoolId(), reports);</div></pre></td></tr></table></figure>
<p> &#x5F53;&#x91CD;&#x542F;&#x540E;&#x7684;NN&#x54CD;&#x5E94;&#x7528;&#x6237;&#x7684;blockReport(BlockManager#processReport)&#x65F6;&#xFF0C;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (storageInfo.numBlocks() == <span class="number">0</span>) { </div><div class="line">       <span class="comment">// The first block report can be processed a lot more efficiently than</span></div><div class="line">       <span class="comment">// ordinary block reports.  This shortens restart times.</span></div><div class="line">       processFirstBlockReport(storageInfo, newReport);</div><div class="line">     } <span class="keyword">else</span> {</div><div class="line">       invalidatedBlocks = processReport(storageInfo, newReport);</div><div class="line">     }</div></pre></td></tr></table></figure>
<p>&#x67D0;&#x4E9B;DataNode&#x7684; storageInfo.numBlocks()==0&#x8FD9;&#x4E2A;&#x6761;&#x4EF6;&#x4E0D;&#x5728;&#x6210;&#x7ACB;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;DataNode&#x7684;IBR&#x7684;&#x62A5;&#x544A;&#x4F7F;&#x5F97;NN&#x8BB0;&#x5F55;&#x4E86;&#x76F8;&#x5E94;DataNode&#x7684;storage&#x4FE1;&#x606F;&#xFF0C;&#x4ECE;&#x800C;&#x4F7F;&#x5F97;NN&#x5904;&#x7406;blockReport&#x7684;&#x7A0B;&#x5E8F;&#x903B;&#x8F91;&#x8FDB;&#x5165;&#x5230;else&#x8FD9;&#x4E00;&#x5206;&#x652F;&#x4E0A;&#xFF1A;<br>   <center> invalidatedBlocks = processReport(storageInfo, newReport); </center></p>
<p> processReport&#x548C;processFirstBlockReport&#x5904;&#x7406;&#x6700;&#x5927;&#x7684;&#x4E0D;&#x540C;&#x662F;&#xFF1A; processReport&#x9700;&#x8981;&#x5C06;DataNode&#x6C47;&#x62A5;&#x4E0A;&#x6765;&#x7684;storage&#x5B58;&#x50A8;&#x7684;&#x5757;&#x4FE1;&#x606F;&#x4E0E;NN&#x4E0A;&#x7F13;&#x5B58;&#x7684;&#x8BE5;DataNode&#x7684;&#x5757;&#x4FE1;&#x606F;&#x8FDB;&#x884C;&#x6BD4;&#x5BF9;&#xFF0C;&#x627E;&#x51FA;&#x4E0D;&#x540C;&#x7684;&#x5730;&#x65B9;&#xFF0C;&#x8FD9;&#x91CC;&#x6D89;&#x53CA;&#x5230;&#x5757;&#x7684;&#x589E;&#x5220;&#x6539;&#x7B49;&#x4FE1;&#x606F;&#xFF0C;&#x7136;&#x540E;&#x6839;&#x636E;&#x5177;&#x4F53;&#x7684;&#x60C5;&#x51B5;&#x901A;&#x8FC7;&#x8BE5;blockReport&#x5237;&#x65B0;NN&#x7F13;&#x5B58;&#x7684;DataNode&#x7684;&#x5B58;&#x50A8;&#x7684;&#x5757;&#x4FE1;&#x606F;&#x3002;&#x5BF9;&#x4E8E;&#x91CD;&#x542F;&#x7684;NN&#x6765;&#x8BF4;&#xFF0C;&#x5176;&#x672C;&#x8EAB;&#x5E76;&#x6CA1;&#x6709;&#x7F13;&#x5B58;&#x6709;&#x96C6;&#x7FA4;&#x5185;DataNode&#x7684;&#x5757;&#x8BB0;&#x5F55;&#x60C5;&#x51B5;&#xFF0C;DataNode&#x4E0A;&#x62A5;&#x7684;blockReport&#x5DF2;&#x7ECF;&#x662F;&#x8BE5;DataNode&#x76EE;&#x524D;&#x6700;&#x65B0;&#x7684;&#x72B6;&#x6001;&#xFF0C;&#x56E0;&#x800C;&#x5728;processFirstBlockReport&#x65B9;&#x6CD5;&#x5185;&#x7F3A;&#x5C11;&#x4E86;&#x6BD4;&#x5BF9;&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;NN&#x53EA;&#x662F;&#x6839;&#x636E;&#x8FD9;&#x4E2A;&#x62A5;&#x544A;&#x548C;&#x6709;&#x5173;&#x7684;IBR&#x91CD;&#x5EFA;NN&#x5173;&#x4E8E;&#x8BE5;DataNode&#x7684;&#x6700;&#x65B0;&#x7684;&#x5757;&#x8BB0;&#x5F55;&#x3002;</p>
<p>   &#x7EFC;&#x4E0A;&#x6240;&#x8FF0;&#xFF0C;&#x5728;NN&#x91CD;&#x542F;&#x540E;&#xFF0C;&#x5E94;&#x8BE5;&#x8BA9;NN&#x5904;&#x7406;blockReport&#x7684;&#x903B;&#x8F91;&#x8FDB;&#x5165;&#x5230;if&#x5206;&#x652F;&#x4E0A;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x5C06;&#x5904;&#x7406;&#x903B;&#x8F91;&#x4EA4;&#x7ED9;processFirstBlockReport&#xFF0C;&#x5B9E;&#x73B0;&#x7F29;&#x77ED;NN&#x91CD;&#x542F;&#x65F6;&#x95F4;&#x3002;</p>
<h4 id="NN&#x542F;&#x52A8;&#x540E;IPC&#x8D85;&#x65F6;"><a href="#NN&#x542F;&#x52A8;&#x540E;IPC&#x8D85;&#x65F6;" class="headerlink" title="NN&#x542F;&#x52A8;&#x540E;IPC&#x8D85;&#x65F6;"></a>NN&#x542F;&#x52A8;&#x540E;IPC&#x8D85;&#x65F6;</h4><p>&#x5F53;NN&#x79BB;&#x5F00;safemode&#x4E4B;&#x540E;&#xFF0C;&#x53D1;&#x73B0;NN&#x4ECD;&#x7136;&#x96BE;&#x4EE5;&#x54CD;&#x5E94;&#x7528;&#x6237;&#x8BF7;&#x6C42;&#x548C;&#x8FDB;&#x7A0B;&#x9891;&#x7E41;GC&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x591A;&#x6B21;&#x5BF9;NN&#x8FDB;&#x884C;&#x7684;&#x7EBF;&#x7A0B;&#x8FD0;&#x884C;&#x6808;&#x5206;&#x6790;&#xFF0C;&#x53D1;&#x73B0;NN Server &#x4E2D;&#x7684;rpc handler&#xFF0C;&#x4E5F;&#x5373;NN&#x5904;&#x7406;rpc&#x8BF7;&#x6C42;&#x7684;&#x7EBF;&#x7A0B;&#x90FD;&#x5728;&#x7B49;&#x5F85;&#x83B7;&#x53D6;FSNameSystem#writeLock(),<br>&#x8FD9;&#x6B21;&#x67D0;&#x4E00;&#x6B21;&#x62BD;&#x6837;&#x5BFC;&#x51FA;10&#x6B21;NN&#x8FDB;&#x884C;&#x8FD0;&#x884C;&#x6808;&#x540E;&#x7684;&#x5206;&#x6790;&#x7ED3;&#x679C;&#xFF1A;<br>NameNode rpc handler&#x7684;&#x6570;&#x91CF;&#xFF1A;<br><img src="/namenode-blockreport-storm/rpc-handler.png" alt="rpc-handler.png" title=""></p>
<p>rpc handler&#x4E2D;&#x5904;&#x7406;blockReport&#x7684;&#x6570;&#x91CF;:<br><img src="/namenode-blockreport-storm/blockreport.png" alt="blockreport.png" title=""></p>
<p>rpc handler&#x4E2D;&#x5904;&#x7406;IBR&#x7684;&#x6570;&#x91CF;&#xFF1A;<br><img src="/namenode-blockreport-storm/ibr.png" alt="ibr.png" title=""></p>
<p> &#x901A;&#x8FC7;&#x6BD4;&#x5BF9;&#x53D1;&#x73B0;&#xFF0C;NN&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#x5904;&#x7406;blockReport&#x7684;server handler&#x6709;&#x5F88;&#x591A;&#xFF0C;&#x800C;&#x8FD9;&#x4E9B;&#x5904;&#x7406;&#x9700;&#x8981;&#x83B7;&#x5F97;FSNameSystem&#x7684;&#x4E00;&#x4E2A;&#x9501;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x610F;&#x5473;&#x7740;&#x5FC5;&#x987B;&#x8981;&#x7B49;&#x4E00;&#x4E2A;&#x83B7;&#x53D6;&#x8FD9;&#x4E2A;&#x9501;&#x8D44;&#x6E90;&#x7684;&#x7EBF;&#x7A0B;&#x5904;&#x7406;&#x5B8C;&#x91CA;&#x653E;&#x8FD9;&#x4E2A;&#x9501;&#x65F6;&#xFF0C;&#x5176;&#x4ED6;&#x7EBF;&#x7A0B;&#x624D;&#x53EF;&#x80FD;&#x6709;&#x673A;&#x4F1A;&#x83B7;&#x5F97;&#x6267;&#x884C;&#x7684;&#x673A;&#x4F1A;&#xFF0C;&#x4ECE;&#x8FD9;&#x4E2A;&#x610F;&#x4E49;&#x4E0A;&#x6765;&#x8BF4;&#xFF0C;NN server&#x5E76;&#x6CA1;&#x6709;&#x53D1;&#x6325;&#x5E76;&#x884C;&#x5904;&#x7406;&#x7684;&#x4F18;&#x52BF;&#xFF0C;&#x800C;&#x662F;&#x5927;&#x90E8;&#x5206;&#x7EBF;&#x7A0B;&#x88AB;&#x7B49;&#x5F85;&#xFF0C;&#x800C;NN server&#x5E76;&#x6CA1;&#x6709;&#x5269;&#x4F59;&#x7684;server handler&#x6765;&#x5904;&#x7406;&#x65B0;&#x7684;rpc request&#x3002;<br> &#x901A;&#x8FC7;NN&#x7AEF;&#x65E5;&#x5FD7;&#xFF0C;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;&#x4E00;&#x4E2A;DataNode&#x7684; blockReport&#x7684;&#x5904;&#x7406;&#x65F6;&#x95F4;&#x5927;&#x81F4;&#x5728;12<em>50ms~12</em>60ms&#xFF08;&#x5E73;&#x5747;&#x65F6;&#x95F4;&#x4E3A;59ms&#xFF09;&#x4E4B;&#x95F4;&#xFF0C;(12&#x662F;DataNode storage&#x7684;&#x4E2A;&#x6570;)&#xFF0C;&#x5373;0.6s~0.7s, &#x4E0D;&#x8003;&#x8651;&#x5176;&#x4ED6;&#x56E0;&#x7D20;&#xFF0C;&#x91CD;&#x542F;NN&#x540E;&#x5168;&#x90E8;&#x5904;&#x7406;&#x5B8C;DataNode&#x7684;blockReport&#x7684;&#x65F6;&#x95F4;&#x5927;&#x81F4;&#x5728;355(DataNode)*(0.6~0.7s)&#xFF0C;&#x4E5F;&#x5C31;&#x662F;213~248.5s&#x4E4B;&#x95F4;&#x3002;</p>
<p>&#x7ED3;&#x5408;&#x6808;&#x7684;&#x8FD0;&#x884C;&#x60C5;&#x51B5;&#x8003;&#x8651;&#xFF0C;&#x6392;&#x9664;&#x5176;&#x4ED6;&#x56E0;&#x7D20;&#xFF0C;&#x4EC5;&#x4EC5;&#x8003;&#x8651;processReport&#x7684;&#x6267;&#x884C;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#xFF0C;&#x4F8B;&#x5982;&#x5047;&#x5B9A;Server&#x6709;146&#x4E2A;&#x6B63;&#x5728;&#x5904;&#x7406;processReport&#x7684;&#x60C5;&#x51B5;&#xFF0C;<br>&#x6700;&#x540E;&#x4E00;&#x4E2A;DataNode&#x7684;blockReport&#x88AB;&#x5904;&#x7406;&#x7684;&#x65F6;&#x95F4;&#x6700;&#x65E9;&#x51FA;&#x73B0;&#x5728;&#xFF1A;<br>(146-1)*0.6 = 87.6s &#x4E4B;&#x540E;&#x3002;<br>&#x6211;&#x4EEC;&#x4ECD;&#x4EE5;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x88AB;&#x5904;&#x7406;&#x7684;blockReport&#x4E3A;&#x4F8B;&#xFF0C;&#x8003;&#x8651;&#x8FD9;&#x4E2A;DataNode&#x5728;&#x53D1;&#x9001;blockReport 87.6s&#x4E4B;&#x540E;&#x7684;&#x884C;&#x4E3A;&#x662F;&#x600E;&#x6837;&#x7684;&#x3002;<br>&#x4ECE;DataNode&#x7684;&#x89D2;&#x5EA6;&#x6765;&#x770B;&#xFF0C;&#x5F53;&#x901A;&#x8FC7;TCP/IP&#x53D1;&#x9001;&#x4E00;&#x4E2A;rpc&#x8BF7;&#x6C42;&#x4E4B;&#x540E;&#xFF0C;&#x7B49;&#x5F85;&#x4E00;&#x5B9A;&#x65F6;&#x95F4;&#x4EE5;&#x83B7;&#x5F97;&#x8BF7;&#x6C42;&#x7684;&#x53CD;&#x9988;&#x7ED3;&#x679C;&#xFF0C;&#x82E5;&#x8D85;&#x8FC7;&#x8FD9;&#x4E2A;&#x65F6;&#x95F4;&#x4ECD;&#x7136;&#x65E0;&#x7ED3;&#x679C;&#x8FD4;&#x56DE;&#xFF0C;&#x90A3;&#x4E48;&#x5C06;&#x629B;&#x51FA;&#x4E00;&#x4E2A;&#x5F02;&#x5E38;&#xFF0C;&#x65F6;&#x95F4;&#x53EF;&#x4EE5;&#x5728;Client.java&#x7C7B;&#x4E2D;getTimeout&#x65B9;&#x6CD5;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line">   * The time after which a RPC will timeout.</div><div class="line">   * If ping is not enabled (via ipc.client.ping), then the timeout value is the </div><div class="line">   * same as the pingInterval.</div><div class="line">   * If ping is enabled, then there is no timeout value.</div><div class="line">   * </div><div class="line">   * <span class="doctag">@param</span> conf Configuration</div><div class="line">   * <span class="doctag">@return</span> the timeout period in milliseconds. -1 if no timeout value is set</div><div class="line">   */</div><div class="line">  <span class="function"><span class="keyword">final</span> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getTimeout</span><span class="params">(Configuration conf)</span> </span>{</div><div class="line">    <span class="keyword">if</span> (!conf.getBoolean(CommonConfigurationKeys.IPC_CLIENT_PING_KEY, <span class="keyword">true</span>)) {</div><div class="line">      <span class="keyword">return</span> getPingInterval(conf);</div><div class="line">    }</div><div class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x7ED3;&#x5408;DataNode&#x4E0A;&#x7684;&#x65E5;&#x5FD7;&#xFF0C;&#x53EF;&#x4EE5;&#x53D1;&#x73B0;rpc socket&#x8BF7;&#x6C42;&#x7684;&#x8D85;&#x65F6;&#x65F6;&#x95F4;&#x662F;60s&#xFF0C;</p>
<p>&#x4E5F;&#x5C31;&#x662F;NN 87.6s&#x4E4B;&#x540E;&#x5904;&#x7406;&#x8BE5;DataNode&#x7684;blockReport&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x5C06;&#x8FD9;&#x4E2A;blockReport&#x5B9A;&#x4E49;&#x4E3A;&#x8BF7;&#x6C42;A&#xFF0C;DataNode&#x8BA4;&#x4E3A;&#x8BE5;&#x8BF7;&#x6C42;&#x5DF2;&#x7ECF;timeout&#xFF0C;&#x5229;&#x7528;&#x672C;&#x8EAB;&#x7684;&#x91CD;&#x8BD5;&#x673A;&#x5236;&#x6216;&#x8005;&#x901A;&#x8FC7;&#x5FC3;&#x8DF3;&#x7EBF;&#x7A0B;&#x7EE7;&#x7EED;&#x5411;NN&#x53D1;&#x9001;&#x4E00;&#x4E2A;blockReport&#xFF0C;&#x6211;&#x4EEC;&#x8BBE;&#x4E3A;&#x8BF7;&#x6C42;B&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x8BF7;&#x6C42;A&#x548C;&#x8BF7;&#x6C42;B&#x90FD;&#x662F;&#x6765;&#x6E90;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;DataNode blockReport&#x7684;&#x8BF7;&#x6C42;&#x3002;<br>&#x5F53;&#x8BF7;&#x6C42;A&#x7ECF;&#x8FC7;60s&#x540E;&#xFF0C;&#x6B64;&#x65F6;DataNode&#x8BA4;&#x4E3A;&#x8BF7;&#x6C42;A&#x5DF2;&#x7ECF;&#x5931;&#x6548;&#xFF0C;&#x4F1A;&#x5728;&#x5C06;&#x6765;&#x7684;&#x67D0;&#x4E2A;&#x65F6;&#x523B;&#x7EE7;&#x7EED;&#x53D1;&#x9001;&#x4E00;&#x4E2A;&#x8BF7;&#x6C42;B&#xFF0C;&#x6B64;&#x65F6;&#x8BF7;&#x6C42;A&#x5DF2;&#x7ECF;&#x52A0;&#x5165;&#x5230;NN server handler&#x5904;&#x7406;&#x7EBF;&#x7A0B;&#x4E2D;&#xFF0C;&#x662F;&#x4E0D;&#x4F1A;&#x611F;&#x77E5;DataNode&#x5DF2;&#x7ECF;&#x5C06;&#x8BE5;&#x8BF7;&#x6C42;&#x6807;&#x8BB0;&#x4E3A;&#x5931;&#x6548;&#x7684;&#x8BF7;&#x6C42;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF7;&#x6C42;A&#x5728;87.6s&#x4E4B;&#x540E;&#x4F1A;&#x7EE7;&#x7EED;&#x6267;&#x884C;&#xFF0C;&#x4E5F;&#x5373;&#x610F;&#x5473;&#x7740;&#xFF0C;&#x540C;&#x4E00;&#x4E2A;DataNode&#x7684;blockReport&#x53EF;&#x80FD;&#x4F1A;&#x88AB;&#x6267;&#x884C;&#x591A;&#x6B21;&#xFF0C;&#x9020;&#x6210;blockReport storm&#x73B0;&#x8C61;&#x3002;<br>&#x76F8;&#x5E94;&#x9A8C;&#x8BC1;&#x65E5;&#x5FD7;&#xFF1A;</p>
<pre>
2015-08-27 21:07:50,058 INFO org.apache.hadoop.ipc.Server: IPC Server handler 3 on 8020 caught an exception
java.nio.channels.ClosedChannelException
        at sun.nio.ch.SocketChannelImpl.ensureWriteOpen(SocketChannelImpl.java:265)
       at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:474)
        at org.apache.hadoop.ipc.Server.channelWrite(Server.java:2538)
        at org.apache.hadoop.ipc.Server.access$1900(Server.java:130)
        at org.apache.hadoop.ipc.Server$Responder.processResponse(Server.java:965)
        at org.apache.hadoop.ipc.Server$Responder.doRespond(Server.java:1030)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2068)
</pre>

<p>NN Server&#x5199;&#x56DE;&#x7ED3;&#x679C;&#x65F6;&#xFF0C;SocketChannel&#x5DF2;&#x7ECF;&#x5173;&#x95ED;&#x3002;&#x5BF9;&#x5E94;&#x7684;&#x65E5;&#x5FD7;&#xFF1A;</p>
<pre>
2015-08-27 21:07:50,114 WARN org.apache.hadoop.ipc.Server: IPC Server handler 87 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 10.31.75.88:47215 Call#7732155 Retry#0: output error
2015-08-27 21:07:50,115 INFO org.apache.hadoop.ipc.Server: IPC Server handler 87 on 8020: skipped org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 10.31.75.158:35223 Call#4328162 Retry#0
&#x2026;
015-08-27 21:50:11,269 WARN org.apache.hadoop.ipc.Server: IPC Server handler 67 on 8020, call org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 10.31.74.204:51987 Call#7889446 Retry#0: output error
</pre>

<p>hadoop Server&#x7ED3;&#x6784;(&#x8FD9;&#x662F;&#x4E00;&#x5F20;&#x6765;&#x81EA;javaEye&#x7684;&#x4E00;&#x7BC7;&#x535A;&#x5BA2;&#x603B;&#x7ED3;&#x7684;&#x56FE;&#x7247;&#xFF0C;&#x611F;&#x8C22;&#x539F;&#x4F5C;&#x8005;&#xFF09;:<br><img src="/namenode-blockreport-storm/server.png" alt="server.png" title=""></p>
<p>NN &#x5927;&#x91CF;rpc server handler&#x7531;&#x4E8E;&#x957F;&#x671F;&#x88AB;&#x5360;&#x7528;&#xFF0C;&#x8FD9;&#x5F15;&#x53D1;&#x4E00;&#x7CFB;&#x5217;&#x540E;&#x679C;&#xFF0C;&#x5BFC;&#x81F4;&#x5728;server&#x7B49;&#x5F85;&#x88AB;&#x5904;&#x7406;&#x7684;&#x8BF7;&#x6C42;(&#x8FD9;&#x4E9B;&#x8BF7;&#x6C42;&#x88AB;&#x7F13;&#x5B58;&#x5728;Server&#x7684;&#x961F;&#x5217;&#x4E2D;,&#x5373;&#x4E0A;&#x56FE;&#x7684;call queue)&#x957F;&#x65F6;&#x95F4;&#x65E0;&#x6CD5;&#x5F97;&#x5230;&#x54CD;&#x5E94;&#xFF0C;&#x5F53;&#x7B49;&#x5F85;&#x7684;&#x65F6;&#x95F4;&#x8D85;&#x8FC7;60s&#x540E;&#xFF0C;&#x5F15;&#x8D77;&#x53D1;&#x9001;&#x8BF7;&#x6C42;&#x7684;DataNode&#x8BA4;&#x4E3A;&#x8BF7;&#x6C42;&#x5931;&#x6548;&#xFF0C;&#x5173;&#x95ED;socket&#xFF0C;&#x8FD9;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;NN Server&#x7AEF;&#x7684;&#x65E5;&#x5FD7;&#x53EF;&#x4EE5;&#x9A8C;&#x8BC1;&#xFF1A;</p>
<pre>
2015-08-27 21:45:17,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 136 on 8020: skipped org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 10.31.x.x:59155 Call#7904083 Retry#0
2015-08-27 21:45:17,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 136 on 8020: skipped org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 10.31.x.x:40573 Call#8040659 Retry#0
2015-08-27 21:45:17,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 136 on 8020: skipped org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 10.31.x.x:47194 Call#7929722 Retry#0
2015-08-27 21:45:17,528 INFO org.apache.hadoop.ipc.Server: IPC Server handler 136 on 8020: skipped org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.sendHeartbeat from 10.31.x.x:36714 Call#7835318 Retry#0
</pre>

<p>&#x5BF9;&#x5E94;&#x4E8E;Server&#x7AEF;&#x7684;&#xFF1A;<br><img src="/namenode-blockreport-storm/outputerror.png" alt="outputerror.png" title=""></p>
<p>&#x800C;NN&#x7531;&#x4E8E;&#x65E0;&#x6CD5;&#x53CA;&#x65F6;&#x5904;&#x7406;DataNode&#x7684;&#x5FC3;&#x8DF3;&#xFF0C;&#x5BFC;&#x81F4;NN&#x8BA4;&#x4E3A;DataNode&#x662F;stale&#x7684;&#xFF0C;&#x800C;NN&#x5904;&#x7406;&#x5B8C;&#x6210;&#x8BE5;DataNode&#x7684;blockReport&#x540E;&#xFF0C;&#x53C8;&#x5C06;&#x8BE5;DataNode&#x6807;&#x8BB0;&#x4E3A;&#x975E;stale&#x7684;&#xFF0C;&#x7136;&#x800C;&#x4ECE;&#x603B;&#x4F53;&#x4E0A;&#x770B;&#xFF0C;&#x7531;&#x4E8E;NN server&#x5904;&#x7406;&#x80FD;&#x529B;&#x6709;&#x9650;&#xFF0C;&#x8FD9;&#x4E00;&#x4E2A;&#x6307;&#x6807;&#x4F1A;&#x968F;&#x7740;&#x65F6;&#x95F4;&#x800C;&#x589E;&#x52A0;&#xFF1A;</p>
<img src="/namenode-blockreport-storm/metrics.png" alt="metrics.png" title="">
<p>&#x7EFC;&#x4E0A;&#x6240;&#x8FF0;&#xFF0C;&#x5BFC;&#x81F4;NN server&#x7E41;&#x5FD9;&#x7684;&#x539F;&#x56E0;&#x662F;NN server handler&#x90FD;&#x5728;&#x5904;&#x7406;&#x5927;&#x91CF;&#x7684;DataNode &#x7684;blockReport&#x8BF7;&#x6C42;&#xFF0C;&#x800C;&#x5927;&#x591A;&#x6570;handler&#x7531;&#x4E8E;FSNameSystem&#x9501;&#x7684;&#x539F;&#x56E0;&#x4EE5;&#x53CA;&#x5BA2;&#x6237;&#x7AEF;&#x8BF7;&#x6C42;&#x8D85;&#x65F6;&#x7684;&#x539F;&#x56E0;&#x9677;&#x5165;&#x6BEB;&#x65E0;&#x610F;&#x4E49;&#x7B49;&#x5F85;&#x72B6;&#x6001;&#x4E2D;&#xFF0C;&#x4F7F;&#x5F97;NN server&#x65E0;&#x6CD5;&#x817E;&#x51FA;&#x624B;&#x6765;&#x5904;&#x7406;&#x65B0;request&#x3002;&#x8BA4;&#x4E3A;&#xFF0C;&#x6839;&#x672C;&#x7684;&#x89E3;&#x51B3;&#x529E;&#x6CD5;&#x662F;&#x91CD;&#x542F;DataNode&#xFF0C;&#x5C06;dfs.blockreport.initialDelay&#x7684;&#x503C;&#x8BBE;&#x4E3A;251s(355<em>12</em>59ms)&#x4EE5;&#x4E0A;, &#x540C;&#x65F6;&#x517C;&#x987E;&#x672A;&#x6765;&#x53EF;&#x80FD;&#x53D1;&#x751F;&#x7684;&#x96C6;&#x7FA4;&#x62D3;&#x5C55;&#x9700;&#x6C42;&#x3002;</p>
<h4 id="NameNode&#x5185;&#x5B58;&#x5F00;&#x9500;&#x5206;&#x6790;"><a href="#NameNode&#x5185;&#x5B58;&#x5F00;&#x9500;&#x5206;&#x6790;" class="headerlink" title="NameNode&#x5185;&#x5B58;&#x5F00;&#x9500;&#x5206;&#x6790;"></a>NameNode&#x5185;&#x5B58;&#x5F00;&#x9500;&#x5206;&#x6790;</h4><p> DataNode&#x5411;NN&#x6C47;&#x62A5;&#x4E00;&#x6B21;blockReport&#xFF0C;&#x5E73;&#x5747;&#x6BCF;&#x4E00;&#x4E2A;storage&#x5305;&#x542B;&#x6709;63000&#x4E2A;&#x5757;&#xFF0C;&#x6BCF;&#x4E2A;&#x5757;&#x81F3;&#x5C11;&#x5360;3<em>8 =24&#x4E2A;&#x5B57;&#x8282;(3&#x4E2A;long&#x5B57;&#x8282;&#x8868;&#x793A;&#x4E00;&#x4E2A;&#x5757;)&#xFF0C;&#x6BCF;&#x6B21;blockReport&#x5305;&#x542B;&#x6709;12&#x4E2A;storage&#xFF0C;&#x56E0;&#x6B64;&#xFF0C;&#x6BCF;&#x4E00;&#x6B21;&#x5411;blockReport&#x6C47;&#x62A5;&#x65F6;&#xFF0C;&#x81F3;&#x5C11;&#x8981;&#x7528;&#xFF1A;12</em>24<em>63k =18M&#xFF0C;355&#x53F0;&#x673A;&#x5668;&#x5168;&#x91CF;&#x6C47;&#x62A5;&#x4E00;&#x6B21;&#x81F3;&#x5C11;&#x5360;&#x7528;&#xFF1A;18M</em>355=6.4g&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x81F3;&#x5C11;&#x8981;&#x5360;&#x7528;6.4g&#x7684;&#x5185;&#x5B58;&#x3002;<br> &#x8FD9;&#x662F;&#x4E00;&#x6B21;&#x62BD;&#x6837;jmx NN 8020&#x7AEF;&#x53E3;&#x63A5;&#x6536;&#x5230;&#x7684;&#x6570;&#x636E;&#x7EDF;&#x8BA1;&#xFF0C;&#x6B64;&#x6B21;jmx&#x83B7;&#x53D6;&#x7EA6;&#x5728;NN&#x542F;&#x52A8;&#x540E;2&#x5C0F;&#x65F6;&#x4E4B;&#x5185;.<br> <img src="/namenode-blockreport-storm/8020.png" alt="8020.png" title=""></p>
<p>rpc 8020&#x7AEF;&#x53E3;&#x63A5;&#x6536;&#x5230;&#x7684;&#x6570;&#x636E;&#x8FBE;&#x5230;28g&#xFF0C;<br> <img src="/namenode-blockreport-storm/cnt.png" alt="cnt.png" title=""></p>
<p> &#x5728; &#x201C;modelerType&#x201D; : &#x201C;RpcDetailedActivityForPort8020&#x201D; &#x6307;&#x6807;&#x5185;&#xFF0C; BlockReportNumOps&#x8FBE;&#x5230;2286&#x6B21;&#xFF0C;(&#x6B63;&#x5E38;&#x60C5;&#x51B5;&#x7EA6;&#x4E3A;355&#x6B21;&#x5DE6;&#x53F3;(2&#x5C0F;&#x65F6;&#x4E4B;&#x5185;))&#x3002;<br>&#x5927;&#x91CF;&#x7684;BlockReport&#xFF0C;&#x6309;&#x7167;&#x4E00;&#x6B21;BlockReport&#x5E73;&#x5747;&#x5360;&#x7528;18M&#x8BA1;&#x7B97;&#xFF0C;&#x7EA6;&#x9700;&#x8981;&#x5185;&#x5B58;2286<em>18M, &#x7EA6;&#x4E3A;41g&#x3002;<br> NameNode&#x4FDD;&#x5B58;{file blocksList} &#x4EE5;&#x53CA;{block dataNode}&#x7684;&#x4FE1;&#x606F;&#xFF0C;<br> &#x5176;&#x4E2D; {block &#x2013;&gt;dataNode}(blocksMap), &#x4F7F;&#x7528;3</em>16 byte(3&#x4E2A;Object)&#x5F15;&#x7528;&#x8868;&#x793A;&#x4E00;&#x4E2A;block replica&#xFF0C;&#x76EE;&#x524D;&#x96C6;&#x7FA4;&#x4E0A;&#x7EA6;&#x6709;&#xFF1A;<br>268739622&#x4E2A;&#x5757;&#xFF0C;&#x5360;&#x7528;&#x5185;&#x5B58;&#x7A7A;&#x95F4;&#x7EA6;&#x4E3A;&#xFF1A;268739622<em>48byte =12899501856, &#x7EA6;&#x4E3A;13g&#x3002;<br>&#x4E00;&#x4E2A;Block&#x81F3;&#x5C11;&#x9700;&#x8981;24&#x4E2A;&#x5B57;&#x8282;&#xFF0C;&#x56E0;&#x6B64;&#x8FD9;&#x90E8;&#x5206;&#x603B;&#x5171;&#x9700;&#x8981; 13+13/(2</em>3) = 15g (3&#x4E3A;block replica&#x7684;&#x6570;&#x91CF;)&#x3002;</p>
<p>&#x53E6;&#x5916;{file blocksList} &#x8FD9;&#x4E00;&#x90E8;&#x5206;&#x4FE1;&#x606F;&#xFF0C;&#x5728;NameNode&#x542F;&#x52A8;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;NameNode&#x9996;&#x5148;&#x4F1A;&#x52A0;&#x8F7D;FSImage, &#x8FD9;&#x90E8;&#x5206;&#x4F1A;&#x5360;&#x7528;30g&#x3002;<br>&#x6309;&#x7167;&#x8FD9;&#x6837;&#x7684;&#x8BA1;&#x7B97;&#xFF0C;&#x5185;&#x5B58;&#x5F00;&#x9500;&#x603B;&#x5171;&#x7EA6;&#x8981;&#xFF1A;28g+41g+15g+30g = 114g&#x3002;</p>
<p>&#x4ECE;rpc 8020 &#x63A5;&#x6536;&#x5230;byte&#x6570;&#x636E;&#xFF0C;&#x4ECE;byte&#x6570;&#x636E;&#x4E2D;&#x89E3;&#x6790;&#x51FA;long<a href="blocks"></a>&#xFF0C;&#x56E0;&#x6B64;&#x5185;&#x5B58;&#x6D88;&#x8017;&#x4F1A;&#x53E0;&#x52A0;&#xFF0C;&#x4E5F;&#x5373;28g+41g&#x3002;</p>
<h3 id="&#x89E3;&#x51B3;&#x65B9;&#x6848;"><a href="#&#x89E3;&#x51B3;&#x65B9;&#x6848;" class="headerlink" title="&#x89E3;&#x51B3;&#x65B9;&#x6848;"></a>&#x89E3;&#x51B3;&#x65B9;&#x6848;</h3><p><li>&#x9488;&#x5BF9;NN&#x542F;&#x52A8;&#x6162;&#x7684;&#x539F;&#x56E0;&#xFF0C;&#x53C2;&#x7167;&#x4E86;HDFS-7980&#x7684;&#x5206;&#x6790;&#x5B9E;&#x73B0;&#xFF0C;&#x4FEE;&#x6B63;NN&#x91CD;&#x542F;&#x540E;&#x5904;&#x7406;BlockReport&#x7684;&#x76F8;&#x5173;&#x903B;&#x8F91;&#xFF0C;&#x52A0;&#x901F;NameNode&#x6062;&#x590D;&#x8FC7;&#x7A0B;&#x3002;</li></p>
<p><li>&#x9488;&#x5BF9;NN&#x542F;&#x52A8;&#x540E;FSNameSystem#writeLock()&#x9891;&#x7E41;&#x4F7F;&#x7528;&#x7B49;&#x5F85;&#x7684;&#x539F;&#x56E0;&#xFF0C;&#x53C2;&#x7167;HDFS-7097&#x7684;&#x5206;&#x6790;&#x5B9E;&#x73B0;&#xFF0C;&#x5B9E;&#x73B0;standby checkpoint&#x9501;&#x548C;FSNameSystem&#x7684;&#x9501;&#x5206;&#x79BB;&#xFF0C;&#x51CF;&#x5C11;&#x4E0D;&#x5FC5;&#x8981;&#x7684;&#x9501;&#x7B49;&#x5F85;&#x62E5;&#x5835;&#x3002;</li></p>
<p><li>&#x5982;&#x679C;&#x53EF;&#x4EE5;&#x91CD;&#x542F;datanode&#xFF0C;&#x4EE5;&#x4E0B;&#x53C2;&#x6570;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x4F18;&#x5316;<br>dfs.blockreport.initialDelay: &#x5EFA;&#x8BAE;&#x8BBE;&#x4E3A;251&#x4EE5;&#x4E0A;&#xFF0C;&#x517C;&#x987E;&#x672A;&#x6765;&#x53EF;&#x80FD;&#x53D1;&#x751F;&#x7684;&#x96C6;&#x7FA4;&#x62D3;&#x5C55;&#x6027;&#x9700;&#x6C42;&#x3002;<br>ipc.ping.interval:&#x9ED8;&#x8BA4;&#x662F;60s&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x8BBE;&#x7F6E;&#x5927;&#x4E00;&#x70B9;</li></p>
<p><li><strong>&#x5982;&#x4E0D;&#x80FD;&#x6682;&#x505C;DataNode&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;NameNode&#x7684;rpc server handler&#x7EBF;&#x7A0B;&#x6570;&#x51CF;&#x5C11;&#x81F3;100&#xFF08;60s/0.6=100&#xFF09;&#xFF0C;&#x6216;&#x8005;&#x66F4;&#x4F4E;&#x3002;</strong></li></p>
<p><li>&#x9488;&#x5BF9;&#x65E5;&#x5FD7;&#x95EE;&#x9898;&#xFF0C;&#x5C06;BlockReport&#x8F93;&#x51FA;&#x65E5;&#x5FD7;&#x7684;&#x8FC7;&#x7A0B;&#x79FB;&#x5230;&#x9501;&#x5916;&#x53BB;&#x8F93;&#x51FA;&#x3002;&#x540C;&#x65F6;&#x4E3A;&#x4E86;&#x51CF;&#x5C11;&#x542F;&#x52A8;&#x8FC7;&#x7A0B;&#x7684;&#x8F93;&#x51FA;&#x91CF;&#xFF0C;&#x901A;&#x8FC7;&#x63A5;&#x53E3;&#x6539;&#x53D8;&#x65E5;&#x5FD7;&#x53E5;&#x67C4;(blockStateChangeLog)&#x7684;&#x8F93;&#x51FA;&#x7EA7;&#x522B;&#x3002;<br>&#x4F18;&#x5316;standby NN &#x5904;&#x7406;BlockReport&#x7684;&#x8FC7;&#x7A0B;&#xFF0C;&#x5177;&#x4F53;&#x53C2;&#x8003;&#xFF1A;<br>                   <a href="https://issues.apache.org/jira/browse/HDFS-6424" target="_blank" rel="external">https://issues.apache.org/jira/browse/HDFS-6424</a></li></p>
<h3 id="&#x5176;&#x4ED6;"><a href="#&#x5176;&#x4ED6;" class="headerlink" title="&#x5176;&#x4ED6;"></a>&#x5176;&#x4ED6;</h3><p>  <a href="http://stackoverflow.com/questions/32251192/restarted-namenode-suffer-from-block-report-storm/34288804#34288804" target="_blank" rel="external">http://stackoverflow.com/questions/32251192/restarted-namenode-suffer-from-block-report-storm/34288804#34288804</a>                   </p>
</div></article></li><li class="post-item"><article class="post"><h2 class="post-title"><a href="streaming-pipeline/" class="post-link">RegionServer不断重建Stream Pipeline问题</a></h2><span class="post-time">Sep 13, 2016</span><div class="post-content"><h3 id="&#x73B0;&#x8C61;"><a href="#&#x73B0;&#x8C61;" class="headerlink" title="&#x73B0;&#x8C61;"></a>&#x73B0;&#x8C61;</h3><p>&#x5728;&#x6211;&#x4EEC;&#x7684;Hbase&#x96C6;&#x7FA4;&#x4E2D;&#xFF0C;&#x6709;&#x65F6;&#x5B58;&#x5728;&#x6709;&#x4E9B;<em>RegionServer</em> &#x56E0;&#x4E3A;&#x4E0D;&#x80FD;&#x7EE7;&#x7EED;&#x5F80;<em>HDFS</em> &#x4E2D;&#x5199;&#x5165;<strong>WAL</strong>&#x6570;&#x636E;&#x800C;&#x5BFC;&#x81F4;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#xFF0C;&#x76F8;&#x5E94;&#x7684;&#x5F02;&#x5E38;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre>
2016-08-06 03:45:42,547 FATAL [regionserver/c1-hd-dn18.bdp.idc/10.130.1.37:16020.logRoller] regionserver.HRegionServer: ABORTING region server c1-hd-dn18.bdp.idc,16020,1469772903345: Failed log close in log roller
org.apache.hadoop.hbase.regionserver.wal.FailedLogCloseException: hdfs://ns1/hbase/WALs/c1-hd-dn18.bdp.idc,16020,1469772903345/c1-hd-dn18.bdp.idc%2C16020%2C1469772903345.default.1470426151350, unflushedEntries=61
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.replaceWriter(FSHLog.java:988)
        at org.apache.hadoop.hbase.regionserver.wal.FSHLog.rollWriter(FSHLog.java:721)
        at org.apache.hadoop.hbase.regionserver.LogRoller.run(LogRoller.java:137)
        at java.lang.Thread.run(Thread.java:745)
</pre>
&#x4EA7;&#x751F;&#x8FD9;&#x4E2A;FATAL&#x4E4B;&#x524D;&#xFF0C;&#x5927;&#x91CF;&#x7684; _&quot;java.io.IOException:Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try.&quot;_ &#x8BB0;&#x5F55;&#x5728;&#x5176;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x4E2D;&#x3002; &#x4ECE;&#x8BE5;&#x5F02;&#x5E38;&#x629B;&#x51FA;&#x7684;message&#x6765;&#x5206;&#x6790;&#xFF0C; &#x5219;&#x610F;&#x5473;&#x7740;&#x5728; _RegionServer_ &#x8F93;&#x51FA;&#x8FD9;&#x6837;&#x5F02;&#x5E38;&#x7684;&#x90A3;&#x523B;&#x8D77;&#xFF0C; &#x5728;_HDFS_&#x96C6;&#x7FA4;&#x8303;&#x56F4;&#x5185;&#x627E;&#x4E0D;&#x5230;&#x4E00;&#x4F8B;&#x53EF;&#x7528;&#x7684;DataNode&#x6765;&#x52A0;&#x5165;&#x5230;&#x5F53;&#x524D;&#x7684;_Stream Pipeline_ &#x4E2D;&#x3002; &#x7136;&#x800C;&#x4E8B;&#x5B9E;&#x4E0A;&#xFF0C;&#x6211;&#x4EEC;&#x5F53;&#x65F6;&#x7684;_HDFS_&#x8FD8;&#x5728;&#x6B63;&#x5E38;&#x63D0;&#x4F9B;&#x7740;&#x6570;&#x636E;&#x7684;&#x589E;&#x5220;&#x6539;&#x67E5;&#x529F;&#x80FD;&#xFF0C;&#x5E76;&#x975E;&#x6CA1;&#x6709;&#x6B63;&#x5E38;&#x7684;_DataNode_&#x53EF;&#x7528;&#x3002;

&#x7EE7;&#x7EED;&#x5206;&#x6790;_RegionServer_&#x7684;&#x65E5;&#x5FD7;&#xFF0C;&#x5728;&#x65E0;&#x53EF;&#x7528;_DataNode_&#x4E4B;&#x524D;&#xFF0C;_RegionServer_&#x4F1A;&#x4E0D;&#x65AD;&#x5C1D;&#x8BD5;&#x4E0E;&#x65B0;&#x7684;_DataNode_&#x91CD;&#x5EFA;Stream Pipeline&#xFF0C;&#x6BEB;&#x65E0;&#x4F8B;&#x5916;&#xFF0C; &#x8FD9;&#x6837;&#x7684;&#x5C1D;&#x8BD5;&#x90FD;&#x5931;&#x8D25;&#x4E86;&#xFF1A;
<pre>
2016-08-06 03:44:29,320 INFO  [DataStreamer for file /hbase/WALs/c1-hd-dn18.bdp.idc,16020,1469772903345/c1-hd-dn18.bdp.idc%2C16020%2C1469772903345.default.1470426151350 block BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856] hdfs.DFSClient: Exception in createBlockOutputStream
java.io.IOException: Got error, status message , ack with firstBadLink as 10.130.a.b:50010
        at org.apache.hadoop.hdfs.protocol.datatransfer.DataTransferProtoUtil.checkBlockOpStatus(DataTransferProtoUtil.java:140)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1334)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.(DFSOutputStream.java:1159)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:876)
        at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:402)
2016-08-06 03:44:29,321 WARN  [DataStreamer for file /hbase/WALs/c1-hd-dn18.bdp.idc,16020,1469772903345/c1-hd-dn18.bdp.idc%2C16020%2C1469772903345.default.1470426151350 block BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856] hdfs.DFSClient: Error Recovery for block BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856 in pipeline DatanodeInfoWithStorage[10.130.x.x:50010,DS-b2197bf5-f129-44df-b569-3ba0e51772c4,DISK], DatanodeInfoWithStorage[10.130.x.x:50010,DS-b0dc4a29-30fe-4633-a292-79274279e345,DISK], DatanodeInfoWithStorage[10.130.a.b:50010,DS-abe5559f-f706-4309-983b-08dd30bcdca4,DISK]: bad datanode DatanodeInfoWithStorage[10.130.a.b:50010,DS-abe5559f-f706-4309-983b-08dd30bcdca4,DISK]
</pre>

<h3 id="&#x5206;&#x6790;"><a href="#&#x5206;&#x6790;" class="headerlink" title="&#x5206;&#x6790;"></a>&#x5206;&#x6790;</h3><p><em>RegionServer(DFSClient)</em> &#x5C06;<em>Bad DataNode</em>&#x52A0;&#x5165;&#x5230;&#x4E00;&#x4E2A;&#x4E0D;&#x53EF;&#x7528;&#x7684;&#x961F;&#x5217;<strong>failed</strong>&#x4E2D;&#xFF0C; &#x5728;&#x5411;<em>NameNode</em> &#x8BF7;&#x6C42;&#x4E00;&#x4E2A;&#x65B0;&#x7684;DataNode&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">createBlockOutputStream:</div><div class="line">   <span class="keyword">while</span>(pipeline&#x521B;&#x5EFA;&#x6CA1;&#x6709;&#x6210;&#x529F; &amp;&amp; pipeline&#x6CA1;&#x6709;&#x88AB;&#x5173;&#x95ED; &amp;&amp; dfsclient&#x5728;&#x88AB;&#x4F7F;&#x7528;&#xFF09; &#xFF5B;</div><div class="line">     <span class="comment">//1, &#x5982;&#x679C;&#x6709;DataNode&#x5728;&#x5199;&#x6216;&#x8005;&#x521B;&#x5EFA;pipeline&#x65F6;&#x51FA;&#x73B0;&#x95EE;&#x9898;&#xFF0C;&#x5C06;&#x51FA;&#x9519;&#x7684;DataNode&#x52A0;&#x5165;&#x5230;&#x4E0D;&#x53EF;&#x7528;&#x7684;&#x961F;&#x5217;&#x4E2D;</span></div><div class="line">     failed.add(nodes[errorIndex]);</div><div class="line">     <span class="comment">//2, &#x5C06;&#x6709;&#x95EE;&#x9898;&#x7684;DataNode&#x4ECE;&#x5F53;&#x524D;&#x7684;pipeline&#x4E2D;&#x79FB;&#x9664;</span></div><div class="line">     <span class="comment">//3, &#x662F;&#x5426;&#x9700;&#x8981;&#x5F80;pipeline&#x4E2D;&#x6DFB;&#x52A0;&#x65B0;&#x7684;DataNode&#x8282;&#x70B9;</span></div><div class="line">     <span class="keyword">if</span>(&#x7B26;&#x5408;datanode&#x7684;&#x66FF;&#x6362;&#x7B56;&#x7565;&#xFF09;&#xFF5B;</div><div class="line">        addDatanode2ExistingPipeline</div><div class="line">     &#xFF5D;</div><div class="line">     <span class="comment">//4, &#x751F;&#x6210;&#x65B0;&#x7684;generation stamp&#x7528;&#x4EE5;&#x533A;&#x5206;&#x4E0D;&#x540C;blk&#x7684;&#x4E0D;&#x540C;&#x7248;&#x672C;</span></div><div class="line">     <span class="comment">//5, &#x521B;&#x5EFA;pipeline&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x6D41;</span></div><div class="line">   &#xFF5D;</div><div class="line"> </div><div class="line"> addDatanode2ExistingPipeline:</div><div class="line">    <span class="comment">//get a new datanode</span></div><div class="line">    <span class="keyword">final</span> DatanodeInfo[] original = nodes;</div><div class="line">    <span class="comment">//nodes -&gt; &#x76EE;&#x524D;pipeline&#x4E0A;&#x5305;&#x542B;&#x7684;DataNode&#x8282;&#x70B9;</span></div><div class="line">    <span class="comment">//failed -&gt; &#x7F13;&#x5B58;&#x4E0D;&#x53EF;&#x7528;&#x7684;DataNode&#x7684;&#x5217;&#x8868;</span></div><div class="line">    <span class="comment">//&#x5411;NameNode&#x8BF7;&#x6C42;&#x65B0;&#x7684;DataNode</span></div><div class="line">    <span class="keyword">final</span> LocatedBlock lb = dfsClient.namenode.getAdditionalDatanode(</div><div class="line">        src, fileId, block, nodes, storageIDs,</div><div class="line">        failed.toArray(<span class="keyword">new</span> DatanodeInfo[failed.size()]),</div><div class="line">        <span class="number">1</span>, dfsClient.clientName);</div><div class="line">    setPipeline(lb);</div></pre></td></tr></table></figure>
<p>&#x5728;&#x65B0;pipeline&#x4E2D;&#x6DFB;&#x52A0;&#x7684;DataNode&#x8282;&#x70B9;&#x65E5;&#x5FD7;&#x6587;&#x4EF6;&#x4E2D;&#xFF0C;&#x53D1;&#x73B0;&#x5F53;&#x5199;&#x5165;&#x8FD9;&#x4E2A;&#x5757;&#x65F6;&#xFF0C;&#x7531;&#x4E8E;&#x8BE5;&#x8282;&#x70B9;&#x5E76;&#x6CA1;&#x6709;&#x76F8;&#x5E94;&#x7684;replica&#xFF0C;&#x800C;&#x4E0D;&#x80FD;&#x6267;&#x884C;append&#x7684;&#x64CD;&#x4F5C;&#x3002;&#x8BE5;DataNode&#x88AB;Client&#x6807;&#x8BB0;&#x4E3A;<em>Bad DataNode</em>, &#x4E00;&#x4E2A;&#x65B0;&#x7684;<em>DataNode</em>&#x66FF;&#x6362;&#x8FD9;&#x4E2A;Bad DataNode&#xFF0C;&#x91CD;&#x5EFA;pipeline&#xFF0C;append block&#x64CD;&#x4F5C;&#x5931;&#x8D25;&#xFF0C;&#x91CD;&#x590D;&#x8FD9;&#x6837;&#x7684;&#x64CD;&#x4F5C;, &#x76F4;&#x5230;hdfs&#x96C6;&#x7FA4;&#x8303;&#x56F4;&#x5185;&#x7684; <em>DataNode</em> &#x88AB;&#x8017;&#x5C3D;&#x3002;</p>
<p>DFSClient&#x5728;&#x9009;&#x62E9;&#x65B0;&#x7684;DataNode&#x6062;&#x590D;pipeline&#x4E4B;&#x524D;&#xFF0C;&#x7531;&#x4E8E;&#x8BE5;DataNode&#x4E2D;&#x5E76;&#x6CA1;&#x6709;block&#x76F8;&#x5E94;&#x7684;replica&#xFF0C;&#x9996;&#x5148;&#x4F1A;&#x4ECE;&#x539F;pipeline&#x9009;&#x62E9;&#x4E00;&#x53F0;DataNode&#x4F5C;&#x4E3A;src, &#x5411;src&#x53D1;&#x9001;&#x4E00;&#x4E2A;transfer blk&#x5230;&#x65B0;DataNode&#x7684;&#x4E00;&#x4E2A;RPC&#x8BF7;&#x6C42;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//transfer replica</span></div><div class="line"><span class="keyword">final</span> DatanodeInfo src = d == <span class="number">0</span>? nodes[<span class="number">1</span>]: nodes[d - <span class="number">1</span>];</div><div class="line"><span class="keyword">final</span> DatanodeInfo[] targets = {nodes[d]};</div><div class="line"><span class="keyword">final</span> StorageType[] targetStorageTypes = {storageTypes[d]};</div><div class="line">transfer(src, targets, targetStorageTypes, lb.getBlockToken());</div></pre></td></tr></table></figure>
<p>&#x7531;&#x6B64;&#xFF0C;&#x4FDD;&#x8BC1;pipeline&#x4E0A;&#x6240;&#x6709;&#x7684;datanode&#x90FD;&#x6709;replica&#xFF0C;&#x4FDD;&#x8BC1;append&#x64CD;&#x4F5C;&#x80FD;&#x591F;&#x7EE7;&#x7EED;&#x8FDB;&#x884C;&#x3002;<br>&#x7ED3;&#x5408;&#x65B0;DataNode&#x629B;&#x51FA;&#x7684;&#x5F02;&#x5E38;&#xFF0C;&#x5F88;&#x660E;&#x663E;&#xFF0C; blk&#x5E76;&#x6CA1;&#x6709;&#x88AB;transfer&#x5230;&#x65B0;&#x7684;DataNode&#x8282;&#x70B9;&#x4E0A;&#x3002;</p>
<p>&#x5728;&#x6267;&#x884C;transfer blk&#x64CD;&#x4F5C;&#x7684;src datanode&#x4E0A;&#xFF0C;&#x5BF9;&#x5E94;&#x6709;&#x8FD9;&#x6837;&#x7684;&#x5F02;&#x5E38;&#xFF1A;</p>
<pre>
f8162f70b22;nsid=920937379;c=0):Failed to transfer BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51012555 to 10.130.a.b:50010 got
java.io.IOException: Need 96273147 bytes, but only 96270660 bytes available
        at org.apache.hadoop.hdfs.server.datanode.BlockSender.waitForMinLength(BlockSender.java:475)
        at org.apache.hadoop.hdfs.server.datanode.BlockSender.<init>(BlockSender.java:242)
        at org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer.run(DataNode.java:2116)
        at org.apache.hadoop.hdfs.server.datanode.DataNode.transferReplicaForPipelineRecovery(DataNode.java:2866)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.transferBlock(DataXceiver.java:869)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opTransferBlock(Receiver.java:168)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:86)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)
        at java.lang.Thread.run(Thread.java:745)
</init></pre>

<p>&#x7ED3;&#x5408;&#x4EE3;&#x7801;&#xFF0C;&#x53EF;&#x77E5;&#xFF1A;<strong>blk_1124743217</strong> &#x51FA;&#x73B0;&#x4E86;[ack bytes] &gt; [bytes on disk]&#x7684;&#x73B0;&#x8C61;&#xFF0C;&#x9020;&#x6210;&#x8FD9;&#x53F0;DataNode&#x65E0;&#x6CD5;&#x5411;10.130.a.b&#x590D;&#x5236;replica&#x7684;&#x95EE;&#x9898;&#x3002;</p>
<p>&#x5F53;DFSClient&#x6BCF;&#x4E00;&#x6B21;&#x521B;&#x5EFA;pipeline&#xFF0C;&#x9009;&#x62E9;&#x8FD9;&#x53F0;&#x672C;&#x8EAB;&#x6709;&#x95EE;&#x9898;&#x7684;DataNode&#x4F5C;&#x4E3A;transfer source&#x65F6;&#xFF0C; &#x90A3;&#x4E48;&#x5728;&#x521D;&#x59CB;&#x5316;pipeline&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x6D41;&#x65F6;(DataStreamer.createBlockOutputStream), &#x7531;&#x4E8E;&#x4E4B;&#x524D;&#x7684;&#x590D;&#x5236;(transfer)&#x64CD;&#x4F5C;&#x5931;&#x8D25;&#xFF0C;pipeline&#x4E0A;&#x6709;&#x4E9B;DataNode&#x5E76;&#x6CA1;&#x6709;replica&#xFF0C;&#x56E0;&#x6B64;writeBlock&#x64CD;&#x4F5C;&#x5E76;&#x4E0D;&#x80FD;&#x5728;pipeline&#x6240;&#x6709;&#x7684;DataNode&#x4E0A;&#x987A;&#x5229;&#x6267;&#x884C;&#xFF0C;pipeline&#x521B;&#x5EFA;&#x5931;&#x8D25;&#x3002;&#x8FD9;&#x6837;&#x7684;&#x73B0;&#x8C61;&#x7C7B;&#x4F3C;&#x4E8E;HDFS-6937&#xFF0C;&#x53EA;&#x4E0D;&#x8FC7;&#x56E0;&#x4E0D;&#x540C;&#xFF0C;&#x7ED3;&#x679C;&#x7C7B;&#x4F3C;&#x3002;</p>
<p>&#x73B0;&#x5728;&#x95EE;&#x9898;&#x53D8;&#x6210;&#xFF0C;&#x4E3A;&#x4EC0;&#x4E48;&#x5728;DN2(&#x6682;&#x4E14;&#x79F0;&#x4E4B;&#x4E3A;)&#x4E2D;&#xFF0C; &#x51FA;&#x73B0;<strong>blk_1124743217</strong> &#x51FA;&#x73B0;&#x4E86;[ack bytes] &gt; [bytes on disk]&#x7684;&#x73B0;&#x8C61;&#xFF1F;<br>&#x8BBE;&#x6700;&#x521D;&#x7684;pipeline&#x4E3A;: client -&gt; DN1 -&gt; DN2 -&gt; DN3.</p>
<p>&#x5728;DN2&#x4E2D;&#xFF0C;&#x7531;&#x4E8E;&#x5176;&#x5E76;&#x975E;&#x4E3A;pipeline&#x4E2D;&#x6700;&#x540E;&#x4E00;&#x4E2A;datanode, <em>RegionServer</em>&#x4E2D;&#x9ED8;&#x8BA4;&#x4F7F;&#x7528;&#x4E86;hflush&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x5199;&#x5165;WAL&#xFF0C; &#x6240;&#x4EE5;&#x5F53;DN2&#x63A5;&#x6536;&#x5230;DN1&#x7684;packet(pkt)&#x65F6;,&#x5C31;&#x5C06;&#x8BE5;pkt&#x52A0;&#x5165;&#x5230;&#x7B49;&#x5F85;ack&#x7684;&#x961F;&#x5217;&#x4E2D;&#x3002;</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">BlockReceiver#receivePacket:</div><div class="line"> // put in queue for pending acks, unless sync was requested</div><div class="line"> if (responder != null &amp;&amp; !syncBlock &amp;&amp; !shouldVerifyChecksum()) {</div><div class="line">   ((PacketResponder) responder.getRunnable()).enqueue(seqno,</div><div class="line">       lastPacketInBlock, offsetInBlock, Status.SUCCESS);</div><div class="line"> }</div></pre></td></tr></table></figure>
<p>&#x63A5;&#x7740;&#x5C06;pkt&#x5199;&#x5165;&#x5230;DN3&#x4E2D;&#xFF0C; </p>
<p>&#x6700;&#x540E;&#xFF0C;&#x5C06;pkt(data+checksum)&#x5199;&#x5165;&#x5230;&#x5BF9;&#x5E94;&#x7684;&#x6587;&#x4EF6;&#x4E2D;&#x3002;&#x5E76;&#x66F4;&#x65B0;replica [bytes on disk]&#x7684;&#x6570;&#x636E;&#x6307;&#x6807;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/// flush entire packet, sync if requested</span></div><div class="line"> flushOrSync(syncBlock);</div><div class="line"> </div><div class="line"> replicaInfo.setLastChecksumAndDataLen(offsetInBlock, lastCrc);</div></pre></td></tr></table></figure>
<p>&#x5F53;DN2 PacketResponder&#x63A5;&#x6536;&#x5230;DN3&#x7684;pkt ack&#x6570;&#x636E;&#x65F6;&#xFF0C;&#x66F4;&#x65B0;replica&#x7684;[ack bytes]&#x7684;&#x6570;&#x636E;&#x6307;&#x6807;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">PipelineAck replyAck = <span class="keyword">new</span> PipelineAck(seqno, replies,</div><div class="line">    totalAckTimeNanos);</div><div class="line"><span class="keyword">if</span> (replyAck.isSuccess()</div><div class="line">    &amp;&amp; offsetInBlock &gt; replicaInfo.getBytesAcked()) {</div><div class="line">  replicaInfo.setBytesAcked(offsetInBlock);</div><div class="line">}</div></pre></td></tr></table></figure>
<p>&#x5176;&#x4E2D;&#xFF0C; DN2&#x5C06;pkt&#x5199;&#x5165;&#x5230;&#x5B58;&#x50A8;&#x4ECB;&#x8D28;&#x4E2D;&#x4E0E;DN2&#x63A5;&#x6536;DN3&#x7684;ack&#x6570;&#x636E;&#xFF0C;&#x8FD9;&#x4E24;&#x4E2A;&#x8FC7;&#x7A0B;&#x662F;&#x5F02;&#x6B65;&#x7684;&#x3002; &#x4E5F;&#x5C31;&#x662F;&#xFF0C;&#x53EF;&#x80FD;&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#xFF0C;&#x5728;DN2&#x4E0A;&#xFF0C;&#x51FA;&#x73B0;&#x7C7B;&#x4F3C;&#x4E8E;&#x201C;[ack bytes] &gt; [bytes on disk]&#x201D;&#x7684;&#x73B0;&#x8C61;&#x3002;</p>
<p>&#x5728;DN2&#x65E5;&#x5FD7;&#x4E2D;&#xFF0C;&#x6709;&#x8FD9;&#x6837;&#x7684;&#x4E00;&#x4E2A;&#x5F02;&#x5E38;&#xFF1A;</p>
<pre>
2016-08-06 03:44:26,172 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception for BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856
java.nio.channels.ClosedByInterruptException
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
        at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:268)
        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.adjustCrcChannelPosition(FsDatasetImpl.java:1479)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.adjustCrcFilePosition(BlockReceiver.java:985)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:677)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:849)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:804)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)
        at java.lang.Thread.run(Thread.java:745)
</pre>

<p>&#x4ECE;&#x65E5;&#x5FD7;&#x4E2D;&#xFF0C;DN2&#x5728;&#x5199;&#x5165;blk_1124743217 pkt&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x88AB;&#x65E0;&#x60C5;&#x4E2D;&#x65AD;&#xFF0C;&#x8FD9;&#x76F4;&#x63A5;&#x5BFC;&#x81F4;DN2&#x65E0;&#x6CD5;&#x5C06;packet&#x6570;&#x636E;&#x5199;&#x5165;&#x5230;&#x5B58;&#x50A8;&#x4ECB;&#x8D28;&#x4E2D;,&#x9020;&#x6210;&#x4E86;&#x6570;&#x636E;&#x7684;&#x6C38;&#x4E45;&#x4E22;&#x5931;&#x3002;</p>
<h3 id="More"><a href="#More" class="headerlink" title="More"></a>More</h3><p>DN2&#x53EA;&#x6709;&#x5B8C;&#x6210;&#x4EE5;&#x4E0B;&#x8FD9;&#x4E9B;&#x6B65;&#x9AA4;&#x540E;&#xFF0C;&#x624D;&#x51C6;&#x5907;&#x63A5;&#x6536;&#x4E0B;&#x4E00;&#x4E2A;pkt&#xFF1A;</p>
<li>enqueue pkt ack to waiting queue.</li><br><li>flush pkt to downstream datanode.</li><br><li>flush pkt to disk file.</li>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">while (receivePacket() &gt;= 0) { /* Receive until the last packet */ }</div></pre></td></tr></table></figure>
<p>DN2&#x629B;&#x51FA;<strong>java.nio.channels.ClosedByInterruptException</strong>&#x5F02;&#x5E38;&#x65F6;&#xFF0C; Client&#x4E3A;blk_1124743217&#x5EFA;&#x7ACB;&#x7684;pipeline&#x5931;&#x8D25;&#xFF0C;&#x4ECE;&#x65E5;&#x5FD7;&#x4E0A;&#x5206;&#x6790;&#xFF0C;&#x6B64;&#x540E;DN2&#x4E0A;&#x7684;blk_1124743217&#x4FBF;&#x4E0D;&#x5728;&#x6709;&#x6210;&#x529F;&#x7684;&#x6570;&#x636E;&#x5199;&#x5165;&#x64CD;&#x4F5C;&#x3002;&#x56E0;&#x6B64;&#xFF0C; &#x51FA;&#x73B0;&#x201C;[ack bytes] &gt; [bytes on disk]&#x201D;&#x7684;&#x73B0;&#x8C61;&#x65F6;&#x95F4;&#x53EF;&#x786E;&#x5B9A;&#x4E3A;&#x5728;&#x65E5;&#x5FD7;&#x8BB0;&#x5F55;&#x5F02;&#x5E38;&#x7684;&#x7684;&#x65F6;&#x95F4;&#x201D;2016-08-06 03:44:26&#x201C;&#x4E4B;&#x524D;&#x3002;</p>
<p>&#x5BF9;&#x4E8E;&#x4E0A;&#x8FF0;&#x7684;&#x6848;&#x4F8B;&#x6765;&#x8BF4;&#xFF0C;&#x8BBE;pkt&#x662F;&#x539F;pipeline&#x4E2D;&#x6700;&#x540E;&#x88AB;&#x6210;&#x529F;&#x7684;ack&#x7684;packet&#xFF0C;&#x6309;&#x7167;DFSClient&#x7684;&#x903B;&#x8F91;&#xFF0C;&#x8BE5;pipeline&#x81F3;&#x5C11;&#x6709;&#x53E6;&#x4E00;&#x4E2A;packet&#x6B63;&#x5728;&#x5199;&#x6216;&#x5DF2;&#x5728;pipeline&#x4E0A;&#xFF0C;&#x5C06;&#x5176;&#x6807;&#x8BB0;&#x4E3A;pkt0.(<em>pkt&#x5E76;&#x975E;block&#x6700;&#x540E;&#x4E00;&#x4E2A;packet&#xFF0C;&#x800C;&#x4E14;&#x4E0A;&#x6E38;&#x6301;&#x7EED;&#x6709;&#x6570;&#x636E;&#x5199;&#x5165;.</em>)</p>
<blockquote>
<p>&#x5047;&#x8BBE;DN2&#x4E0A;&#x4E2D;&#x65AD;&#x7684;&#x5F02;&#x5E38;&#x5C5E;&#x4E8E;pkt0&#x3002;   </p>
</blockquote>
<p>pkt0&#x88AB;DN3&#x63A5;&#x6536;&#x4E4B;&#x540E;&#xFF0C;&#x5728;DN3&#x7531;&#x4E8E;SocketTimeOutException&#x5F02;&#x5E38;&#x5173;&#x95ED;Socket&#x4E4B;&#x524D;&#x5C06;pkt0 ack&#x6570;&#x636E;&#x53D1;&#x9001;&#x7ED9;DN2, DN2&#x63A5;&#x6536;&#x5230;&#x8FD9;&#x6837;&#x7684;&#x6570;&#x636E;&#x4E4B;&#x540E;&#xFF0C;&#x66F4;&#x65B0;replica ack bytes&#x6307;&#x6807;&#xFF0C; &#x518D;&#x5C06;DN2&#x548C;DN3&#x7684;ack&#x6570;&#x636E;&#x6253;&#x5305;&#x4E00;&#x8D77;&#x53D1;&#x7ED9;DN1. &#x8981;&#x4F7F;pkt&#x6210;&#x4E3A;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x88AB;&#x6210;&#x529F;ack&#x7684;packet&#xFF0C;&#x4E14;DN2&#x51FA;&#x73B0; ack bytes &gt; bytes on disk&#x7684;&#x73B0;&#x8C61;&#xFF0C; &#x5219;&#x53EF;&#x80FD;&#x6709;&#x4EE5;&#x4E0B;&#x51E0;&#x79CD;&#x60C5;&#x51B5;&#xFF1A;<br></p>
<li><br>DN2&#x672A;&#x5C06;pkt0 ack&#x6570;&#x636E;&#x53D1;&#x9001;&#x7ED9;DN1&#x3002; &#x90A3;&#x4E48;&#x5B58;&#x5728;&#x8FD9;&#x6837;&#x7684;&#x5173;&#x7CFB;&#xFF1A; a1 &lt; a2, a1 &#x4E3A;DN1&#x7684;ack bytes&#x6307;&#x6807;&#xFF1B; a2&#x4E3A;DN2&#x7684;ack bytes&#x7684;&#x6307;&#x6807;&#x3002;<br> <strong>&#x5728;&#x540E;&#x6765;&#x7684;DataNode stream recovery&#x64CD;&#x4F5C;&#x4E2D;&#xFF0C; &#x663E;&#x793A;a1=a2, &#x8FD9;&#x6837;&#x7684;&#x60C5;&#x51B5;&#x88AB;&#x6392;&#x9664;&#x3002;</strong><br></li><br><li><br>  DN1&#x672A;&#x5C06;pkt0 ack&#x6570;&#x636E;&#x53D1;&#x9001;&#x7ED9;Client&#x3002;&#x90A3;&#x4E48;DN1&#x5C06;&#x4F1A;&#x88AB;Client&#x6807;&#x8BB0;&#x6210;&#x8981;&#x66FF;&#x6362;&#x7684;DataNode,&#x800C;&#x5E76;&#x975E;DN3&#x4E86;&#xFF0C;&#x800C;&#x4E14;Client&#x91CD;&#x5EFA;pipeline&#x7684;&#x539F;&#x56E0;&#x4E5F;&#x662F;&#x56E0;&#x4E3A;DN3&#x7684;SocketTimeoutException&#xFF0C;&#x8BE5;&#x4FE1;&#x606F;&#x6CBF;ack&#x4F20;&#x9012;&#x8DEF;&#x5F84;&#x7ECF;DN2 -&gt; DN1&#x4F20;&#x9012;&#x7ED9;Client&#xFF0C;Client&#x624D;&#x77E5;&#x9053;DN3&#x51FA;&#x4E86;&#x95EE;&#x9898;&#x3002;<br></li>   

<blockquote>
<p>&#x56E0;&#x6B64;&#xFF0C;&#x53EF;&#x4EE5;&#x4E0B;&#x4E00;&#x4E2A;&#x8FD9;&#x6837;&#x7684;&#x7ED3;&#x8BBA;&#xFF1A;<strong>&#x5728;DN2&#x4E0A;&#x4E2D;&#x65AD;&#x7684;pkt&#x4E00;&#x5B9A;&#x662F;&#x539F;pipeline&#x4E2D;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x88AB;&#x6210;&#x529F;ack&#x7684;packet&#x3002;</strong></p>
</blockquote>
<p>&#x8FD9;&#x4E2A;&#x7ED3;&#x8BBA;&#x5F88;&#x91CD;&#x8981;&#xFF0C;&#x53EF;&#x4EE5;&#x5927;&#x81F4;&#x5F97;&#x5230;pipeline(DN1-&gt;DN2-&gt;DN3)&#x51FA;&#x73B0;&#x95EE;&#x9898;&#x90A3;&#x4E00;&#x523B;DN2&#x5904;&#x7406;pkt&#x65F6;&#x7EBF;&#x7A0B;&#x6808;&#x7684;&#x60C5;&#x51B5;&#xFF0C;&#x5728;BlockReceiver&#xFF03;receivePacket&#x65B9;&#x6CD5;&#x4E2D;&#xFF0C;&#x5F80;DN3&#x5199;&#x5165;pkt&#x4E4B;&#x540E;&#xFF0C;adjustCrcFilePosition()&#x65B9;&#x6CD5;&#x4E4B;&#x524D;&#xFF0C;&#x662F;&#x6CA1;&#x6709;&#x6BD4;&#x8F83;&#x8017;&#x65F6;&#x64CD;&#x4F5C;&#x7684;&#x3002;&#x56E0;&#x6B64;&#xFF0C;DN2&#x5F53;&#x65F6;&#x6808;&#x7684;&#x60C5;&#x51B5;&#x5E94;&#x8BE5;&#x662F;&#xFF1A;</p>
<pre>
        at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
        at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:268)
        at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.adjustCrcChannelPosition(FsDatasetImpl.java:1479)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.adjustCrcFilePosition(BlockReceiver.java:985)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:677)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:849)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:804)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)
        at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)
        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)
        at java.lang.Thread.run(Thread.java:745)
</pre>

<p>&#x7531;&#x4E8E;DN2&#x4E00;&#x76F4;&#x9677;&#x5165;&#x6587;&#x4EF6;&#x5BFB;&#x5740;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;(&#x5904;&#x7406;pkt&#xFF09;&#xFF0C;&#x9020;&#x6210;DN2&#x65E0;&#x6CD5;&#x5904;&#x7406;pkt0&#xFF0C;&#x8FDB;&#x800C;&#x65E0;&#x6CD5;&#x5C06;pkt0&#x5199;&#x5165;&#x5230;DN3&#x4E2D;&#xFF0C;&#x5F53;&#x8D85;&#x8FC7;60s&#x65F6;&#xFF08;rpc timeout&#xFF09;&#xFF0C;DN3&#x7387;&#x5148;&#x629B;&#x51FA;SocketTimeoutException&#x5F02;&#x5E38;&#xFF0C;&#x5C06;pipeline&#x7684;socket&#x8D44;&#x6E90;&#x5173;&#x95ED;&#xFF0C;DN2&#x6355;&#x83B7;&#x5230;&#x8FD9;&#x4E00;&#x4E8B;&#x4EF6;&#x3002;</p>
<p>DN3:</p>
<pre>
2016-08-06 03:44:22,981 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Exception for BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856
java.net.SocketTimeoutException: 60000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/DN3:50010 remote=/DN2:43529]
        at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:164)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
        at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.DataInputStream.read(DataInputStream.java:149)
        at org.apache.hadoop.io.IOUtils.readFully(IOUtils.java:199)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doReadFully(PacketReceiver.java:213)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.doRead(PacketReceiver.java:134)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PacketReceiver.receiveNextPacket(PacketReceiver.java:109)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:472)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:849)
</pre>

<p>DN2:</p>
<pre>
2016-08-06 03:44:22,982 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-360285305-10.130.1.11-1444619256876:blk_1124743217_51010856, type=HAS_DOWNSTREAM_IN_PIPELINE
java.io.EOFException: Premature EOF: no length prefix available
        at org.apache.hadoop.hdfs.protocolPB.PBHelper.vintPrefixed(PBHelper.java:2280)
        at org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:244)
        at org.apache.hadoop.hdfs.server.datanode.BlockReceiver$PacketResponder.run(BlockReceiver.java:1237)
        at java.lang.Thread.run(Thread.java:745)
</pre>

<p>PBHelper.vintPrefixed:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> InputStream <span class="title">vintPrefixed</span><span class="params">(<span class="keyword">final</span> InputStream input)</span></span></div><div class="line">     <span class="keyword">throws</span> IOException {</div><div class="line">  <span class="keyword">final</span> <span class="keyword">int</span> firstByte = input.read();</div><div class="line">  </div><div class="line">  <span class="keyword">if</span> (firstByte == -<span class="number">1</span>) {</div><div class="line">     <span class="keyword">throw</span> <span class="keyword">new</span> EOFException(<span class="string">&quot;Premature EOF: no length prefix available&quot;</span>);</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>DN2&#x7684;PacketResponder&#x6536;&#x5230;DN3&#x7684;&#x5F02;&#x5E38;&#x6D88;&#x606F;&#x4E4B;&#x540E;&#xFF0C;&#x5C06;DN3&#x8FD9;&#x53F0;DataNode&#x6807;&#x8BB0;&#x4E3A;Error&#xFF0C;&#x5E76;reply&#x7ED9;DN1, DN1&#x5C06;&#x9519;&#x8BEF;&#x4FE1;&#x606F;&#x5C01;&#x88C5;&#x540E;&#x4EA4;&#x7ED9;Client:</p>
<pre><code><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> (ack == <span class="keyword">null</span>) {</div><div class="line">   <span class="comment">// A new OOB response is being sent from this node. Regardless of</span></div><div class="line">   <span class="comment">// downstream nodes, reply should contain one reply.</span></div><div class="line">   replies = <span class="keyword">new</span> <span class="keyword">int</span>[] { myHeader };</div><div class="line"> <span class="comment">//&#x8FD9;&#x91CC;mirrorError &#xFF1D; true;</span></div><div class="line"> } <span class="keyword">else</span> <span class="keyword">if</span> (mirrorError) { <span class="comment">// ack read error</span></div><div class="line">   <span class="keyword">int</span> h = PipelineAck.combineHeader(datanode.getECN(), Status.SUCCESS);</div><div class="line">   <span class="keyword">int</span> h1 = PipelineAck.combineHeader(datanode.getECN(), Status.ERROR);</div><div class="line">   replies = <span class="keyword">new</span> <span class="keyword">int</span>[] {h, h1};</div><div class="line"> }</div></pre></td></tr></table></figure>
</code></pre><p>Client&#x89E3;&#x6790;DN1&#x4F20;&#x6765;&#x7684;ack&#x4FE1;&#x606F;(seqno=-2), &#x53D1;&#x73B0;DN3&#x5BF9;&#x5E94;&#x7684;ack&#x72B6;&#x6001;&#x4E3A;Error&#x7684;&#xFF0C;Client&#x5C06;DN3&#x6807;&#x8BB0;&#x4E3A;&#x4E00;&#x4E2A;&#x4E0D;&#x53EF;&#x7528;&#x7684;<em>DataNode</em>, &#x5E76;&#x5C06;&#x5BF9;&#x5E94;&#x7684;ResponseProcessor&#x7EBF;&#x7A0B;&#x5173;&#x95ED;&#xFF0C;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// if the Responder encountered an error, shutdown Responder</span></div><div class="line">    <span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) {</div><div class="line">      <span class="keyword">try</span> {</div><div class="line">        response.close();</div><div class="line">        response.join();</div><div class="line">        response = <span class="keyword">null</span>;</div><div class="line">      } <span class="keyword">catch</span> (InterruptedException  e) {</div><div class="line">        DFSClient.LOG.warn(<span class="string">&quot;Caught exception &quot;</span>, e);</div><div class="line">    }</div></pre></td></tr></table></figure>
<p>&#x5728;DataStreamer&#x4E3B;&#x7EBF;&#x7A0B;&#x4E0A;&#xFF0C;&#x5C06;&#x539F;&#x6765;&#x7684;pipeline&#x5173;&#x95ED;&#xFF0C;&#x5C06;&#x7B49;&#x5F85;ack&#x7684;packet&#x79FB;&#x5230;&#x8981;&#x53D1;&#x9001;&#x7684;&#x961F;&#x5217;&#x961F;&#x9996;&#x4E2D;,&#x91CD;&#x65B0;&#x9009;&#x62E9;DataNode(&#x66FF;&#x6362;DN3)&#x5EFA;&#x7ACB;pipeline. &#x5728;&#x6062;&#x590D;pipeline&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;DN2&#x4F5C;&#x4E3A;transfer source&#xFF0C; &#x800C;&#x539F;&#x6765;DN2&#x4E2D;&#x7684;replica&#x662F;&#x6709;&#x95EE;&#x9898;&#x7684;(&#x6570;&#x636E;&#x4E22;&#x5931;), &#x8FD9;&#x6837;&#x4FBF;&#x9020;&#x6210;&#x65B0;&#x7684;pipeline&#x65E0;&#x6CD5;&#x521B;&#x5EFA;&#x6210;&#x529F;&#x3002;</p>
<h3 id="&#x603B;&#x7ED3;"><a href="#&#x603B;&#x7ED3;" class="headerlink" title="&#x603B;&#x7ED3;"></a>&#x603B;&#x7ED3;</h3><p>1&#xFF0C; Client flushes pkt to pipeline and gets succuss acks from DN1. <br><br>    (Stage -&gt; BlockConstructionStage.DATA_STREAMING)<br><img src="/streaming-pipeline/snap.png" alt="[title]" title="[title]"></p>
<p>2, Client flushes next pkt(pkt0) to pipeline and timeout from DN3. DN2 sends the error ack to DN1.<br><img src="/streaming-pipeline/pkt0.png" alt="[title]" title="[title]"></p>
<p>3, Client close current pipeline and choose DN4 to replace DN3, and transfer blk from DN2 to DN4.<br><br>   (Stage-&gt; BlockConstructionStage.PIPELINE_SETUP_STREAMING_RECOVERY)<br><img src="/streaming-pipeline/transfer.png" alt="transfer.png" title=""></p>
<p>4, Create new pipeline with DN1, DN2 and DN4.<br><br>   (Stage-&gt; BlockConstructionStage.DATA_STREAMING)<br><img src="/streaming-pipeline/pipeline_new.png" alt="pipeline_new.png" title=""></p>
<p>&#x540C;&#x65F6;&#xFF0C;&#x901A;&#x8FC7;&#x5206;&#x6790;&#xFF0C;&#x5728;&#x5F80;pipeline&#x6DFB;&#x52A0;DataNode&#x65F6;&#xFF0C;&#x5C3D;&#x7BA1;DataNode&#x5728;tranfer block&#x8FC7;&#x7A0B;&#x4E2D;&#x53D1;&#x751F;IOException(&#x4F8B;&#x5982;&#x672C;&#x4F8B;&#x7684;&#x4F8B;&#x5B50;), &#x7136;&#x800C;Client&#x662F;&#x611F;&#x77E5;&#x4E0D;&#x5230;&#x7684;&#xFF0C;&#x4F7F;&#x7528;&#x6709;&#x95EE;&#x9898;&#x7684;DataNode(&#x6570;&#x636E;&#x5DF2;&#x53D1;&#x751F;&#x4E22;&#x5931;)&#x4EE5;&#x53CA;&#x65B0;DataNode(BlockPool&#x4E2D;&#x6CA1;&#x6709;&#x76F8;&#x5E94;&#x7684;replica)&#x91CD;&#x5EFA;pipeline&#xFF0C;&#x5F80;pipeline&#x5199;&#x5165;&#x6570;&#x636E;&#x65F6;(&#x51C6;&#x786E;&#x6765;&#x8BF4;&#xFF0C;&#x662F;&#x53D1;&#x9001;&#x4E00;&#x4E2A;&#x5199;block&#x7533;&#x8BF7;&#xFF0C;&#x83B7;&#x5F97;&#x8BFB;&#x5199;&#x6570;&#x636E;&#x6D41;)&#xFF0C;&#x662F;&#x4E0D;&#x4F1A;&#x6210;&#x529F;&#x7684;&#x3002;&#x5728;&#x7B26;&#x5408;DataNode&#x66FF;&#x6362;&#x7B56;&#x7565;&#x7684;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;Client&#x4F1A;&#x5C1D;&#x8BD5;&#x9009;&#x62E9;&#x4E0E;HDFS&#x96C6;&#x7FA4;&#x8303;&#x56F4;&#x5185;&#x6240;&#x6709;&#x53EF;&#x7528;&#x7684;DataNode&#x5EFA;&#x7ACB;&#x4E00;&#x6761;pipeline&#xFF0C;&#x76F4;&#x5230;&#x65E0;DataNode&#x53EF;&#x7528;&#x4E3A;&#x6B62;&#x3002;<br>&#x6587;&#x4E2D;&#x63CF;&#x8FF0;&#x7684;&#x5F02;&#x5E38;&#x573A;&#x666F;&#x6309;&#x7167;pipeline&#x8BFB;&#x5199;&#x903B;&#x8F91;&#x662F;&#x5F88;&#x96BE;&#x53D1;&#x751F;&#x7684;&#xFF0C;&#x7136;&#x800C;&#x4E0D;&#x540C;&#x7684;&#x8F6F;&#x786C;&#x4EF6;&#x73AF;&#x5883;&#xFF0C;&#x4E0D;&#x540C;&#x7684;&#x8BFB;&#x5199;&#x538B;&#x529B;&#x7B49;&#x7B49;&#xFF0C;&#x8FD9;&#x4E9B;&#x90FD;&#x4E3A;&#x8F6F;&#x4EF6;&#x7684;&#x6D4B;&#x8BD5;&#x548C;&#x7F16;&#x5199;&#x5E26;&#x6765;&#x4E00;&#x5B9A;&#x7684;&#x5C40;&#x9650;&#x6027;&#xFF0C;&#x4E5F;&#x7ED9;&#x7A0B;&#x5E8F;&#x7684;&#x5065;&#x58EE;&#x6027;&#x5E26;&#x6765;&#x4E00;&#x4E9B;&#x6311;&#x6218;&#x3002;&#x4EE5;&#x6587;&#x4E2D;&#x4E3A;&#x4F8B;&#xFF0C;&#x5F53;&#x53D1;&#x73B0;&#x65E0;&#x53EF;&#x7528;&#x7684;DataNode&#x65F6;&#xFF0C;RegionServer&#x5C06;&#x4F1A;&#x5F02;&#x5E38;&#x9000;&#x51FA;&#x3002;&#x5728;&#x5206;&#x5E03;&#x5F0F;&#x73AF;&#x5883;&#x4E0B;&#xFF0C;&#x8C03;&#x8BD5;&#x548C;&#x5B9A;&#x4F4D;&#x95EE;&#x9898;&#x53D8;&#x5F97;&#x590D;&#x6742;&#x548C;&#x4E0D;&#x786E;&#x5B9A;&#xFF0C;&#x968F;&#x7740;&#x6DF1;&#x5165;&#xFF0C;&#x5047;&#x8BBE;&#x4E0D;&#x65AD;&#x7684;&#x88AB;&#x63A8;&#x7FFB;&#x548C;&#x4FEE;&#x6B63;&#xFF0C;&#x8FD9;&#x4E9B;&#x90FD;&#x6709;&#x8D56;&#x4E8E;&#x65E5;&#x5FD7;&#x548C;&#x6E90;&#x7801;&#x7684;&#x5206;&#x6790;&#x3002;</p>
<h3 id="&#x5982;&#x4F55;&#x89E3;&#x51B3;"><a href="#&#x5982;&#x4F55;&#x89E3;&#x51B3;" class="headerlink" title="&#x5982;&#x4F55;&#x89E3;&#x51B3;"></a>&#x5982;&#x4F55;&#x89E3;&#x51B3;</h3><blockquote>
<p>1, &#x63D0;&#x9AD8;hdfs rpc&#x8BFB;&#x5199;&#x7684;&#x8D85;&#x65F6;&#x65F6;&#x95F4;.<br></p>
</blockquote>
<p>&#x5BF9;&#x4E8E;&#x7B2C;&#x4E00;&#x79CD;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x6765;&#x8BF4;&#xFF0C;&#x66F4;&#x6539;&#x6D89;&#x53CA;&#x5230;Client&#x7AEF;(<em>RegionServer</em>), &#x540C;&#x65F6;&#x8FD8;&#x9700;&#x8981;&#x91CD;&#x542F;&#x96C6;&#x7FA4;&#x5185;&#x7684;<em>DataNode</em>&#x670D;&#x52A1;&#x3002;&#x8FD9;&#x79CD;&#x65B9;&#x6848;&#x4FEE;&#x6539;&#x7B80;&#x5355;&#xFF0C;&#x7136;&#x800C;&#x5BF9;&#x4E8E;&#x96C6;&#x7FA4;&#x5BB9;&#x9519;&#x548C;&#x6392;&#x9519;&#x6765;&#x8BF4;&#x5E76;&#x975E;&#x6700;&#x4F73;&#xFF0C;&#x540C;&#x65F6;&#x5C06;&#x8FD9;&#x4E2A;&#x503C;&#x8BBE;&#x7F6E;&#x4E3A;&#x591A;&#x5927;&#x6BD4;&#x8F83;&#x5408;&#x9002;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x66F4;&#x5168;&#x9762;&#x7684;&#x6D4B;&#x8BD5;&#x548C;&#x8BC4;&#x4F30;&#x3002;</p>
<blockquote>
<p>2, &#x4FEE;&#x6539;&#x5BA2;&#x6237;&#x7AEF;&#xFF0C;&#x5728;&#x6062;&#x590D;pipeline&#xFF0C;&#x5C06;replica&#x79FB;&#x52A8;&#x5230;&#x65B0;&#x7684;datanode&#x4E4B;&#x95F4;&#xFF0C;&#x4F7F;&#x7528;&#x539F;pipeline&#x6700;&#x540E;&#x4E00;&#x53F0;<em>DataNode</em>&#x4F5C;&#x4E3A;source&#x3002;</p>
</blockquote>
<p>&#x6839;&#x636E;&#x8BBE;&#x8BA1;:</p>
   <img src="/streaming-pipeline/client.png" alt="client.png" title="">
<p>&#x5728;&#x8FD9;&#x91CC;, BA(i, t)&#x8868;&#x793A;&#x5728;&#x4EFB;&#x610F;&#x65F6;&#x523B;t&#xFF0C;pipeline&#x7B2C;i&#x53F0; <em>DataNode</em> acked bytes&#x7684;&#x6307;&#x6807;,  i&#x7684;&#x5927;&#x5C0F;&#x4EE3;&#x8868;&#x79BB;Client&#x7684;&#x8FDC;&#x8FD1;&#xFF1B;BR(i,t)&#x8868;&#x793A;&#x5728;&#x4EFB;&#x610F;&#x65F6;&#x523B;t&#xFF0C;pipeline&#x7B2C;i&#x53F0; <em>DataNode</em> received bytes&#x7684;&#x6307;&#x6807;, i&#x7684;&#x5927;&#x5C0F;&#x4EE3;&#x8868;&#x79BB;Client&#x7684;&#x8FDC;&#x8FD1;. &#x5047;&#x8BBE;&#x539F;pipeline&#x4E2D;&#x6700;&#x540E;&#x4E00;&#x53F0;<em>DataNode</em>, acked bytes&#x6307;&#x6807;&#x8BB0;&#x4E3A;BAD&#xFF0C; received bytes&#x6307;&#x6807;&#x8BB0;&#x4E3A;BR; &#x5BF9;&#x5E94;&#x7684;Client, acked bytes&#x8BB0;&#x4E3A; BAC, &#x53D1;&#x9001;&#x7684;&#x5B57;&#x8282;&#x6570;&#x8BB0;&#x4E3A;BS&#x3002;&#x5219;,&#x5B58;&#x5728;&#x8FD9;&#x6837;&#x7684;&#x4E0D;&#x7B49;&#x5F0F;&#x5173;&#x7CFB;&#xFF1A;<br><strong>BAC &lt;= BAD &lt;= BR &lt;= BS</strong>&#x3002;<br><br>&#x5728;pipeline&#x6700;&#x540E;&#x4E00;&#x53F0;<em>DataNode</em>&#x4E2D;&#xFF0C;&#x5F53;&#x4E14;&#x4EC5;&#x5F53;DataNode&#x5B8C;&#x6210;packet&#x6570;&#x636E;checksum&#x6821;&#x9A8C;&#x4EE5;&#x53CA;&#x5C06;packet flush&#x5230;&#x78C1;&#x76D8;&#x65F6;&#xFF0C;&#x624D;&#x66F4;&#x6539;BAD&#x7684;&#x6570;&#x636E;&#x6307;&#x6807;&#x3002; &#x7531;&#x6B64;&#xFF0C;replica BAD&#x7684;&#x6570;&#x636E;&#x4E00;&#x5B9A;&#x5177;&#x6709;&#x4EE5;&#x4E0B;&#x4E00;&#x4E9B;&#x6027;&#x8D28;&#xFF1A; 1&#xFF0C; replica data&#x4E0E;checksum&#x5339;&#x914D;&#xFF1B; 2&#xFF0C;replica data acked bytes &lt;= data on disk bytes.</p>
<p>&#x5728;&#x6062;&#x590D;pipeline&#x65F6;&#xFF0C; Client&#x5C06;&#x7B49;&#x5F85;ack&#x7684;&#x6570;&#x636E;&#x91CD;&#x65B0;&#x5F52;&#x7F6E;&#x5230;&#x5F85;&#x53D1;&#x9001;&#x5230;&#x961F;&#x5217;&#x4E2D;&#xFF0C;&#x5373;(BAC, BS], &#x4ECE;&#x539F;pipeline&#x6700;&#x540E;<em>DataNode</em>&#x4E0A;&#x62F7;&#x8D1D;&#x7684;&#x6570;&#x636E;&#x533A;&#x95F4;&#x5728;(0, BAD]&#x6216;&#x8005;<br>(0, BR], &#x65B0;&#x9009;&#x62E9;&#x7684;<em>DataNode</em> replica&#x65E0;&#x8BBA;&#x662F;&#x5728;(0, BAD]&#x6216;(0, BR]&#xFF0C; &#x90FD;&#x80FD;&#x6B63;&#x786E;&#x7684;&#x63A5;&#x6536;&#x6765;&#x81EA;Client&#x4ECE;BAC&#x4F4D;&#x7F6E;&#x5F00;&#x59CB;&#x53D1;&#x9001;&#x8FC7;&#x6765;&#x7684;&#x6570;&#x636E;&#x3002;</p>
<p>&#x5047;&#x8BBE;&#x539F;pipeline&#x6700;&#x540E;&#x7684;&#x4E00;&#x53F0;<em>DataNode</em>&#x4E0D;&#x53EF;&#x7528;&#x600E;&#x4E48;&#x529E;? &#x5982;shutdown, abort, replica&#x88AB;&#x5220;&#x9664;&#x7B49;&#x7B49;&#xFF0C;&#x90A3;&#x4E48;&#x91C7;&#x53D6;&#x7684;&#x7B56;&#x7565;&#x662F;&#x968F;&#x673A;&#x4ECE;pipeline&#x5269;&#x4F59;&#x7684;<em>DataNode</em>&#x4F5C;&#x4E3A;&#x65B0;&#x52A0;&#x5165;<em>DataNode</em>&#x7684;transfer source.</p>
<p>&#x540C;&#x6837;&#xFF0C;&#x8BE5;&#x65B9;&#x6848;&#x4E5F;&#x6709;&#x660E;&#x663E;&#x7684;&#x7F3A;&#x70B9;&#xFF0C;&#x5982;&#x679C;&#x53D1;&#x751F;&#x5728;&#x4E0D;&#x540C;&#x673A;&#x67B6;&#x4E0A;&#x7684;&#x6570;&#x636E;&#x62F7;&#x8D1D;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x6837;&#x7684;&#x65B9;&#x6848;&#x5C06;&#x4F1A;&#x5BF9;pipeline&#x7684;&#x5FEB;&#x901F;&#x6062;&#x590D;&#x6709;&#x4E00;&#x5B9A;&#x7684;&#x6D88;&#x6781;&#x5F71;&#x54CD;&#x3002; &#x4F46;&#x5982;&#x679C;<em>DataNode</em>&#x5728;&#x540C;&#x4E00;rack&#x5185;&#xFF0C;&#x5219;&#x5B8C;&#x5168;&#x6709;&#x7406;&#x7531;&#x8FD9;&#x4E48;&#x505A;&#x3002;&#x4ECE;&#x7406;&#x8BBA;&#x4E0A;&#x6765;&#x8BF4;&#xFF0C;block&#x7684;&#x591A;&#x5907;&#x4EFD;&#x673A;&#x5236;&#x662F;&#x4E3A;&#x4E86;&#x51CF;&#x5C11;&#x5404;&#x79CD;&#x6545;&#x969C;&#x5BFC;&#x81F4;&#x6570;&#x636E;&#x5F02;&#x5E38;&#x800C;&#x91C7;&#x53D6;&#x7684;&#x4E00;&#x79CD;&#x65B9;&#x6848;&#xFF0C;&#x7136;&#x800C;&#xFF0C;&#x8FD9;&#x5E76;&#x4E0D;&#x610F;&#x5473;&#x7740;&#x6570;&#x636E;&#x4F1A;&#x4E00;&#x76F4;&#x6B63;&#x5E38;&#x4E0B;&#x53BB;&#xFF0C;&#x5728;&#x67D0;&#x4E9B;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x91C7;&#x7528;&#x65B9;&#x6848;2&#x4E5F;&#x672A;&#x80FD;&#x9632;&#x6B62;&#x6570;&#x636E;&#x7684;&#x5B8C;&#x6574;&#x6B63;&#x786E;&#x6027;&#xFF0C; &#x4F8B;&#x5982;: &#x6309;&#x7167;&#x63CF;&#x8FF0;&#xFF0C; &#x5F53;DN1&#x548C;DN2&#x540C;&#x65F6;&#x51FA;&#x73B0;data acked bytes &gt; data on disk bytes&#x73B0;&#x8C61;&#xFF0C;&#x800C;&#x6B64;&#x65F6;DN3&#x4E0D;&#x53EF;&#x7528;&#x65F6;&#xFF0C;&#x4E5F;&#x4F1A;&#x51FA;&#x73B0;&#x7C7B;&#x4F3C;&#x4E8E;&#x6587;&#x4E2D;&#x63CF;&#x8FF0;&#x7684;&#x95EE;&#x9898;&#x3002;</p>
<p>&#x6709;&#x65F6;&#x5019;&#x4F1A;&#x6000;&#x7591;&#xFF0C;DataNode&#x662F;&#x5982;&#x4F55;&#x6210;&#x529F;&#x5EFA;&#x7ACB;&#x8D77;pipeline&#x7684;&#xFF1F; &#x5728;DataXceiver&#x8FD9;&#x4E2A;&#x7C7B;&#x4E2D;&#x6C38;&#x8FDC;&#x9009;&#x62E9;&#x7684;&#x662F;targets[0]&#x7684;DataNode&#x4EE3;&#x8868;&#x81EA;&#x5DF1;&#xFF0C;&#x5982;&#x679C;DN2&#x4E5F;&#x9009;&#x62E9;targets[0]&#x4EE3;&#x8868;&#x81EA;&#x5DF1;&#xFF0C;&#x90A3;&#x4E2A;&#x8FD9;&#x4E2A;&#x600E;&#x4E48;&#x4F1A;&#x6210;&#x7ACB;&#x5462;&#xFF1F;&#x8FD9;&#x4E9B;&#x7EC6;&#x8282;&#x4F53;&#x73B0;&#x5728;Sender&#x8FD9;&#x4E2A;&#x7C7B;&#x4E2D;&#xFF0C;&#x5F53;&#x8C03;&#x7528;new Sender(out).writeBlock()&#x7684;&#x65F6;&#x5019;&#xFF0C;&#x8BE5;&#x65B9;&#x6CD5;&#x4ECE;&#x7B2C;&#x4E00;&#x4E2A;&#x4F4D;&#x7F6E;&#x5F00;&#x59CB;&#x5C06;targets&#x4E2D;&#x7684;&#x6570;&#x636E;&#x62F7;&#x8D1D;&#x5230;&#x53E6;&#x4E00;&#x4E2A;&#x6570;&#x7EC4;&#x4E2D;&#xFF0C;&#x5982;&#x679C;&#x8BF4;targets[0]&#x4EE3;&#x8868;&#x81EA;&#x5DF1;&#xFF0C;&#x90A3;&#x4E48;targets[1]&#x5219;&#x4EE3;&#x8868;&#x7684;&#x662F;&#x4E0B;&#x6E38;&#x8282;&#x70B9;&#xFF0C;&#x5C06;&#x4E00;&#x4E9B;&#x6570;&#x636E;&#x62F7;&#x8D1D;&#x5B8C;&#x6210;&#x540E;&#xFF0C;&#x5728;&#x901A;&#x8FC7;&#x534F;&#x8BAE;&#xFF0C;&#x5199;&#x5165;&#x5230;&#x8F93;&#x51FA;&#x6D41;&#x4E2D;&#x3002;</p>
<p>new Sender(out).writeBlock()</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">OpWriteBlockProto.Builder proto = OpWriteBlockProto.newBuilder()</div><div class="line">      .setHeader(header)</div><div class="line">      .setStorageType(PBHelper.convertStorageType(storageType))</div><div class="line">      <span class="comment">//&#x4ECE;targets&#x7B2C;&#x4E00;&#x4E2A;&#x4F4D;&#x7F6E;&#x5F00;&#x59CB;&#xFF0C;&#x62F7;&#x8D1D;DatanodeInfo&#x4FE1;&#x606F;&#x5230;&#x53E6;&#x4E00;&#x4E2A;list&#x4E2D;</span></div><div class="line">      .addAllTargets(PBHelper.convert(targets, <span class="number">1</span>))</div><div class="line">      .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, <span class="number">1</span>))</div></pre></td></tr></table></figure>
<p>PBHelper.convert(targets, 1&#xFF09;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> List&lt;? extends HdfsProtos.DatanodeInfoProto&gt; convert(</div><div class="line">      DatanodeInfo[] dnInfos, <span class="keyword">int</span> startIdx) {</div><div class="line">    <span class="keyword">if</span> (dnInfos == <span class="keyword">null</span>)</div><div class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</div><div class="line">    ArrayList&lt;HdfsProtos.DatanodeInfoProto&gt; protos = Lists</div><div class="line">        .newArrayListWithCapacity(dnInfos.length);</div><div class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = startIdx; i &lt; dnInfos.length; i++) {</div><div class="line">      protos.add(convert(dnInfos[i]));</div><div class="line">    }</div><div class="line">    <span class="keyword">return</span> protos;</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x5047;&#x8BBE;DN2&#x51FA;&#x73B0;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x6309;&#x7167;&#x8FD9;&#x6837;&#x7684;&#x65B9;&#x6848;&#xFF0C;DN3&#x4F1A;&#x5C06;&#x5C06;block&#x590D;&#x5236;&#x5230;DN4&#x4E2D;&#xFF0C;&#x91CD;&#x65B0;&#x5EFA;&#x7ACB;&#x8D77;&#x4E00;&#x6761;&#x65B0;&#x7684;Pipeline(DN1 -&gt; DN2 -&gt; DN4)&#x3002;&#x6309;&#x7167;&#x6587;&#x4E2D;&#x7684;&#x63CF;&#x8FF0;&#xFF0C; &#x5728;DN2&#x4E0A;&#x51FA;&#x73B0;&#x4E86;replica.getVisibleLength() &gt; replica.getBytesOnDisk()&#x7684;&#x73B0;&#x8C61;&#xFF0C; &#x5F53;client&#x5F80;&#x65B0;&#x5EFA;&#x7684;pipeline&#x4E2D;&#x5199;&#x5165;&#x6570;&#x636E;&#x7684;&#x65F6;&#x5019;&#xFF0C;DN2&#x4F1A;&#x5982;&#x4F55;&#x5904;&#x7406;&#x8FD9;&#x79CD;&#x60C5;&#x51B5;&#xFF1F;</p>
<p>DataReceiver#receivePacket():</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The data buffer position where write will begin. If the packet</span></div><div class="line"><span class="comment">// data and on-disk data have no overlap, this will not be at the</span></div><div class="line"><span class="comment">// beginning of the buffer.</span></div><div class="line"><span class="keyword">int</span> startByteToDisk = (<span class="keyword">int</span>)(onDiskLen-firstByteInBlock) </div><div class="line">    + dataBuf.arrayOffset() + dataBuf.position();</div><div class="line"></div><div class="line"><span class="comment">// Actual number of data bytes to write.</span></div><div class="line"><span class="keyword">int</span> numBytesToDisk = (<span class="keyword">int</span>)(offsetInBlock-onDiskLen);</div><div class="line"></div><div class="line"><span class="comment">// Write data to disk.</span></div><div class="line"><span class="keyword">long</span> begin = Time.monotonicNow();</div><div class="line">out.write(dataBuf.array(), startByteToDisk, numBytesToDisk);</div></pre></td></tr></table></figure>
<p>firstByteInBlock&#x662F;&#x8BE5;packet&#x4E2D;&#x7B2C;&#x4E00;&#x4E2A;&#x5B57;&#x8282;&#x7684;offset&#xFF0C; offsetInBlock&#x662F;firstByteInBlock + packet length; &#x6839;&#x636E;&#x8BA1;&#x7B97;&#x7ED3;&#x679C;&#xFF0C;&#x5F53;onDiskLen &lt; firstByteInBlock&#x65F6;&#xFF0C;&#x6B64;&#x65F6;startByteToDisk&#x662F;&#x4E00;&#x4E2A;&#x8D1F;&#x6570;&#xFF0C;&#x8F93;&#x51FA;&#x6D41;&#x5199;&#x6570;&#x636E;&#x65F6;&#xFF0C;&#x4F1A;&#x51FA;&#x73B0;&#x5982;&#x4E0B;&#x5F02;&#x5E38;&#xFF1A;</p>
<pre>
2016-08-24 16:33:09,415 ERROR datanode.DataNode (DataXceiver.java:run(278)) - 127.0.0.1:51033:DataXceiver error processing WRITE_BLOCK operation  src: /127.0.0.1:51047 dst: /127.0.0.1:51033
java.lang.IndexOutOfBoundsException
    at java.io.FileOutputStream.writeBytes(Native Method)
    at java.io.FileOutputStream.write(FileOutputStream.java:326)
    at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:648)
    at org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:849)
    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:804)
    at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)
    at org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)
    at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)
    at java.lang.Thread.run(Thread.java:745)
</pre>

<p>Client&#x6536;&#x5230;DN2&#x7684;ack error, &#x91CD;&#x65B0;&#x5EFA;&#x7ACB;&#x4E00;&#x6761;&#x65B0;&#x7684;pipeline&#xFF0C; &#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x5E76;&#x4E0D;&#x4F1A;&#x4EA7;&#x751F;&#x6570;&#x636E;&#x4E22;&#x5931;&#x7684;&#x60C5;&#x51B5;&#x3002; &#x5F53;&#x7136;&#xFF0C;&#x5728;&#x5B9E;&#x9645;&#x7684;&#x751F;&#x4EA7;&#x73AF;&#x5883;&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x8FD8;&#x53D1;&#x73B0;&#xFF0C;&#x5F53;DN2&#x51FA;&#x73B0;IO&#x74F6;&#x9888;&#x95EE;&#x9898;&#x65F6;&#xFF0C;&#x91CD;&#x65B0;&#x5EFA;&#x7ACB;pipeline&#xFF0C;&#x5199;&#x5165;block&#x65F6;&#xFF0C;&#x5E76;&#x6CA1;&#x6709;&#x5BF9;&#x5E94;&#x7684;java.lang.IndexOutOfBoundsException&#x5F02;&#x5E38;&#x629B;&#x51FA;&#x6765;&#x3002;&#x800C;&#x662F;&#x7EBF;&#x7A0B;&#x88AB;IO&#x963B;&#x585E;&#x4F4F;&#xFF0C;&#x8FD8;&#x6CA1;&#x6709;&#x8D70;&#x5230;&#x4E0A;&#x9762;&#x63CF;&#x8FF0;&#x7684;&#x8FC7;&#x7A0B;&#xFF1A;</p>
<p><pre><br>2016-09-07 09:56:45,521 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Join on writer thread Thread[DataXceiver for client DFSClient<em>NONMAPREDUCE</em>-1754701259_1 at /10.130.1.37:51509 [Receiving block BP-360285305-10.130.1.11-1444619256876:blk_1143909363_70177457],5,dataXceiverServer] timed out<br>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getTmpInputStreams(FsDatasetImpl.java:751)<br>org.apache.hadoop.hdfs.server.datanode.BlockReceiver.computePartialChunkCrc(BlockReceiver.java:1023)<br>org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receivePacket(BlockReceiver.java:634)<br>org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(BlockReceiver.java:849)<br>org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:804)<br>org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.opWriteBlock(Receiver.java:137)<br>org.apache.hadoop.hdfs.protocol.datatransfer.Receiver.processOp(Receiver.java:74)<br>org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:251)<br>java.lang.Thread.run(Thread.java:745)<br></pre><br>&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x4F7F;&#x5F97;hdfs&#x4ECE;&#x9519;&#x8BEF;&#x4E2D;&#x6062;&#x590D;&#x53D8;&#x5F97;&#x7F13;&#x6162;(&#x9700;&#x8981;2&#x4E2A;timeout&#x7684;&#x65F6;&#x95F4;&#xFF09;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x4FEE;&#x6539;receivePacket&#x7684;&#x903B;&#x8F91;&#x6765;&#x5FEB;&#x901F;&#x7684;&#x53D1;&#x73B0;&#x8FD9;&#x6837;&#x7684;&#x60C5;&#x51B5;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Sanity check the header</span></div><div class="line"><span class="comment">// change condition to if (header.getOffsetInBlock() &gt; replicaInfo.getBytesOnDisk()) {</span></div><div class="line"><span class="keyword">if</span> (header.getOffsetInBlock() &gt; replicaInfo.getNumBytes()) {</div><div class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Received an out-of-sequence packet for &quot;</span> + block + </div><div class="line">      <span class="string">&quot;from &quot;</span> + inAddr + <span class="string">&quot; at offset &quot;</span> + header.getOffsetInBlock() +</div><div class="line">      <span class="string">&quot;. Expecting packet starting at &quot;</span> + replicaInfo.getNumBytes());</div><div class="line">}</div></pre></td></tr></table></figure>
<p>&#x8FD9;&#x9700;&#x8981;&#x91CD;&#x542F;&#x6211;&#x4EEC;&#x7684;datanode&#x670D;&#x52A1;&#x624D;&#x80FD;&#x751F;&#x6548;&#x3002;</p>
</div></article></li></ul><div class="paginator"></div></section><footer><div class="social"><a href="mailto:dengzhhu653@163.com" title="email" class="iconfont icon-email"></a><a href="https://github.com/dengzhhu653" title="github" class="iconfont icon-github"></a><a href="/atom.xml" title="rss" class="iconfont icon-rss"></a></div><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2017<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Zhihua Deng</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script></body></html>