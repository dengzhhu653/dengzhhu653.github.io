<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="author" content="Zhihua Deng"><meta name="description" content="Spark&amp;#x4F5C;&amp;#x4E1A;&amp;#x63D0;&amp;#x4EA4;&amp;#x53CA;&amp;#x5E8F;&amp;#x5217;&amp;#x5316;&amp;#x5728;&amp;#x5206;&amp;#x6790;Spark&amp;#x63D0;&amp;#x4EA4;&amp;#x4F5C;&amp;#x4E1A;&amp;#x4E4B"><meta name="keywords" content=""><title> Â· null</title><link rel="icon" href="../favicon.ico"><link rel="canonical" href="https://dengzhhu653.github.io/spark-serializable/"><link rel="alternate" href="../atom.xml" title="null"><link rel="stylesheet" href="../fonts/iconfont/iconfont.css"><link rel="stylesheet" href="../css/style.css"><script type="text/javascript">var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?Your baidu Analytics ID";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script type="text/javascript">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'Your Google Analytics ID', 'auto');
ga('send', 'pageview');</script></head><body><div id="main"><header><a href="../." class="logo"></a><ul class="nav"><li class="nav-link"><a href="/archives/" target="_self">Archives</a></li><li class="nav-link"><a href="/about/" target="_self">About</a></li></ul></header><section id="container"><article class="post"><h1 class="post-title"></h1><span class="post-time">Oct 21, 2016</span><div class="post-content"><p><strong>Spark&#x4F5C;&#x4E1A;&#x63D0;&#x4EA4;&#x53CA;&#x5E8F;&#x5217;&#x5316;</strong></p>
<p>  &#x5728;&#x5206;&#x6790;Spark&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x4E4B;&#x524D;&#xFF0C;&#x5148;&#x7B80;&#x5355;&#x68B3;&#x7406;&#x4E00;&#x4E0B;&#x6709;&#x5173;Java&#x5E8F;&#x5217;&#x5316;&#x7684;&#x77E5;&#x8BC6;&#x4EE5;&#x53CA;&#x4E00;&#x4E9B;&#x7406;&#x89E3;&#x3002;</p>
<p><strong><em>Java&#x5E8F;&#x5217;&#x5316;</em></strong></p>
<p>  &#x4E00;&#x4E2A;Java&#x5BF9;&#x8C61;&#x5728;&#x5176;&#x751F;&#x547D;&#x5468;&#x671F;&#x5185;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x591A;&#x79CD;&#x4E0D;&#x540C;&#x7684;&#x72B6;&#x6001;&#xFF0C;&#x8FD9;&#x4E9B;&#x72B6;&#x6001;&#x533A;&#x5206;&#x4E8E;&#x540C;&#x4E00;&#x4E2A;&#x7C7B;&#x7684;&#x5176;&#x5B83;&#x5BF9;&#x8C61;&#x3002;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5DE5;&#x4F5C;&#xFF0C;&#x5C31;&#x662F;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x72B6;&#x6001;&#xFF0C;&#x4EE5;&#x4E8C;&#x8FDB;&#x5236;&#x7684;&#x5F62;&#x6001;&#x8F93;&#x51FA;&#x51FA;&#x6765;&#xFF0C;&#x5728;&#x9075;&#x5FAA;&#x8F93;&#x51FA;&#x534F;&#x8BAE;&#x7684;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x8FD9;&#x4E9B;&#x5B57;&#x8282;&#x6062;&#x590D;&#x5BF9;&#x8C61;&#x5728;&#x67D0;&#x4E00;&#x65F6;&#x523B;&#x7684;&#x72B6;&#x6001;(&#x53CD;&#x5E8F;&#x5217;&#x5316;), &#x8FD9;&#x5BF9;&#x4E8E;&#x5FEB;&#x901F;&#x6062;&#x590D;&#x4EE5;&#x53CA;&#x8DE8;JVM&#x4FE1;&#x606F;&#x4EA4;&#x6D41;&#x5E26;&#x6765;&#x5DE8;&#x5927;&#x7684;&#x4FBF;&#x5229;&#x6027;&#x3002;<br>  &#x5BF9;&#x8C61;&#x4E0E;&#x5BF9;&#x8C61;&#x4E4B;&#x95F4;&#x5B58;&#x5728;&#x7740;&#x5F15;&#x7528;&#x4E0E;&#x88AB;&#x5F15;&#x7528;&#x7684;&#x5173;&#x7CFB;&#xFF0C;&#x9488;&#x5BF9;&#x4E8E;&#x5BF9;&#x8C61;&#x672C;&#x8EAB;&#xFF0C;&#x5219;&#x53EF;&#x80FD;&#x4F1A;&#x6709;&#x4E0D;&#x540C;&#x7684;&#x8FED;&#x4EE3;&#x7248;&#x672C;&#x3002;&#x5F53;&#x5BF9;&#x8C61;&#x5C1D;&#x8BD5;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x5F15;&#x7528;&#x5173;&#x7CFB;&#x5E8F;&#x5217;&#x5316;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x4FDD;&#x8BC1;&#x5F15;&#x7528;&#x7684;&#x5BF9;&#x8C61;&#x4E5F;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#x3002;&#x5982;&#x4E0B;&#x9762;&#x7684;&#x4E00;&#x4E2A;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;serializable(JavaSerializable) -&gt; sc(Serializable1) -&gt;ns(NonSerializable), &#x7531;&#x4E8E;ns&#x5BF9;&#x8C61;&#x5E76;&#x4E0D;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5BFC;&#x81F4;&#x5728;main&#x65B9;&#x6CD5;&#x4E2D;&#xFF0C;&#x5E8F;&#x5217;&#x5316;serializable&#x64CD;&#x4F5C;&#x5931;&#x8D25;&#x3002;</p>
<p><pre><br>  public class JavaSerializable implements Serializable {<br>  Serializable1 sc;<br>  private JavaSerializable() { }<br>  public JavaSerializable(Serializable1 sc) {<br>    this.sc = sc;<br>  }<br>  public static void main(String[] args) throws IOException {<br>    JavaSerializable serializable = new JavaSerializable(new Serializable1());<br>    ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(&#x201C;/tmp/obj.ser&#x201D;));<br>    //&#x8FD9;&#x91CC;&#x4F1A;&#x629B;&#x51FA;&#x4E00;&#x4E2A; &#x201C;java.io.NotSerializableException: cn.creditease.basic.NonSerializable&#x201D; &#x5F02;&#x5E38;<br>    objectOutputStream.writeObject(serializable);<br>    objectOutputStream.flush();<br>    objectOutputStream.close();<br>  }<br>}<br>class Serializable1 implements Serializable {<br>  NonSerializable ns = new NonSerializable(&#x201C;hello&#x201D;);<br>}</pre></p>
<p>class NonSerializable {<br>    int tf1;<br>    String tf2;<br>    public NonSerializable(String tf2) {<br>      this.tf2 = tf2;<br>    }<br>}<br><br>&#x7136;&#x800C;&#x9700;&#x8981;&#x8BA4;&#x8BC6;&#x5230;&#xFF0C;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5DE5;&#x4F5C;&#x662F;&#x5C06;&#x5BF9;&#x8C61;&#x7684;&#x72B6;&#x6001;&#x901A;&#x8FC7;&#x4E8B;&#x5148;&#x7EA6;&#x5B9A;&#xFF0C;&#x8F93;&#x51FA;&#x6210;&#x4E8C;&#x8FDB;&#x5236;&#x3002;&#x5BF9;&#x4E8E;&#x67D0;&#x4E00;&#x4E2A;&#x7C7B;&#x6765;&#x8BF4;&#xFF0C;&#x5982;&#x4F55;&#x5E8F;&#x5217;&#x5316;&#x4EE5;&#x53CA;&#x5E8F;&#x5217;&#x5316;&#x90A3;&#x4E9B;&#x72B6;&#x6001;&#xFF0C;&#x8FD9;&#x4E9B;&#x90FD;&#x662F;&#x5C5E;&#x4E8E;&#x7C7B;&#x7684;&#x884C;&#x4E3A;&#xFF0C;&#x5176;&#x4ED6;&#x7684;&#x7C7B;&#x6CA1;&#x5FC5;&#x8981;&#x77E5;&#x9053;&#x8FD9;&#x4E9B;&#x7EC6;&#x8282;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x5F53;&#x8981;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5BF9;&#x8C61;&#x4F9D;&#x8D56;&#x7684;&#x5F15;&#x7528;&#x662F;&#x4E00;&#x4E2A;null&#x65F6;&#xFF0C;&#x8FD9;&#x4E2A;&#x662F;&#x4E0D;&#x4F1A;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E2A;&#x4F9D;&#x8D56;&#x5BF9;&#x8C61;&#x7684;&#x3002;&#x4F8B;&#x5982;&#xFF0C;&#x5728;&#x4E0A;&#x8FF0;&#x7684;&#x4F8B;&#x5B50;&#x4E2D;&#xFF0C;&#x5F53;serializable&#x5BF9;&#x8C61;&#x4E2D;sc&#x7684;&#x5F15;&#x7528;&#x4E3A;NUll&#x65F6;&#xFF0C;&#x5E8F;&#x5217;&#x5316;serializable&#x5BF9;&#x8C61;&#x662F;&#x6CA1;&#x6709;&#x95EE;&#x9898;&#x7684;&#xFF1A;</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>{</div><div class="line">    <span class="comment">//&#x4E0D;&#x521D;&#x59CB;&#x5316;sc</span></div><div class="line">    JavaSerializable serializable = <span class="keyword">new</span> JavaSerializable();</div><div class="line">    ObjectOutputStream objectOutputStream = <span class="keyword">new</span> ObjectOutputStream(<span class="keyword">new</span> FileOutputStream(<span class="string">&quot;/tmp/obj.ser&quot;</span>));</div><div class="line">    <span class="comment">//&#x6210;&#x529F;&#x5E8F;&#x5217;&#x5316;serializable&#x5BF9;&#x8C61;</span></div><div class="line">    objectOutputStream.writeObject(serializable);</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x901A;&#x8FC7;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x6062;&#x590D;&#x4E00;&#x4E2A;&#x5BF9;&#x8C61;&#x65F6;&#xFF0C;&#x8FD9;&#x4E2A;&#x8FC7;&#x7A0B;&#x5E76;&#x4E0D;&#x4F1A;&#x8C03;&#x7528;&#x7C7B;&#x7684;&#x6784;&#x9020;&#x51FD;&#x6570;&#x3002;<br>&#x6709;&#x5173;&#x66F4;&#x8FC7;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x77E5;&#x8BC6;&#xFF0C;&#x53EF;&#x4EE5;&#x53C2;&#x8003;&#xFF1A;<br>  <a href="http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html" target="_blank" rel="external">http://docs.oracle.com/javase/7/docs/api/java/io/Serializable.html</a></p>
<p>&#x968F;&#x7740;&#x5206;&#x5E03;&#x5F0F;&#x7CFB;&#x7EDF;&#x7684;&#x53D1;&#x5C55;&#x548C;&#x6D41;&#x884C;&#xFF0C;&#x5F88;&#x591A;&#x6846;&#x67B6;&#x91C7;&#x7528;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x673A;&#x5236;&#x6765;&#x5B9E;&#x73B0;&#x8FDB;&#x7A0B;&#x4E4B;&#x95F4;&#x901A;&#x4FE1;&#xFF0C;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x4FDD;&#x5B58;&#x4EE5;&#x53CA;&#x8FDB;&#x7A0B;&#x4E2D;&#x4E00;&#x4E9B;&#x72B6;&#x6001;&#x7684;&#x6301;&#x4E45;&#x5316;&#x3002;&#x5982;<a href="http://storm.apache.org/" target="_blank" rel="external">storm</a>&#x4E2D;&#x7684;worker&#x4F1A;&#x5468;&#x671F;&#x6027;&#x7684;&#x5C06;&#x4E00;&#x4E9B;&#x72B6;&#x6001;&#x4FE1;&#x606F;&#x5199;&#x5165;&#x5230;&#x6307;&#x5B9A;&#x7684;&#x76EE;&#x5F55;&#x4E2D;&#xFF0C;Supervisor&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E9B;&#x4FE1;&#x606F;&#xFF0C;&#x5F97;&#x5230;worker&#x7684;&#x8FD0;&#x884C;&#x72B6;&#x6001;&#xFF1B;hadoop MapReduce&#x4F1A;&#x5C06;Mapper&#x8F93;&#x51FA;&#x7684;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;&#x5E8F;&#x5217;&#x5316;&#x6210;&#x4E8C;&#x8FDB;&#x5236;&#x6587;&#x4EF6;&#xFF1B;thrift&#x4F1A;&#x5C06;&#x5BA2;&#x6237;&#x7AEF;&#x7684;&#x8C03;&#x7528;&#x5E8F;&#x5217;&#x5316;(&#x5305;&#x62EC;&#x65B9;&#x6CD5;&#x540D;&#xFF0C;&#x4EE5;&#x53CA;&#x65B9;&#x6CD5;&#x4E2D;&#x5305;&#x542B;&#x7684;&#x53C2;&#x6570;&#x4FE1;&#x606F;)&#xFF0C;&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x540E;&#x4E8C;&#x8FDB;&#x5236;&#x6D41;&#x4EA4;&#x7ED9;&#x670D;&#x52A1;&#x7AEF;&#x6765;&#x89E3;&#x6790;&#xFF0C;&#x5B9E;&#x73B0;&#x8FDC;&#x7A0B;&#x8C03;&#x7528;&#x7B49;&#x7B49;&#x3002;&#x9488;&#x5BF9;Java&#x5E8F;&#x5217;&#x5316;&#x6539;&#x8FDB;&#x7684;&#x5E8F;&#x5217;&#x5316;&#x6846;&#x67B6;&#x4E5F;&#x5F00;&#x59CB;&#x53D8;&#x5F97;&#x591A;&#x8D77;&#x6765;,&#x5982;<a href="https://github.com/eishay/jvm-serializers/wiki" target="_blank" rel="external">&#x4E00;&#x4E9B;&#x5E8F;&#x5217;&#x5316;&#x5BF9;&#x6BD4;&#x548C;&#x6D4B;&#x8BD5;</a>&#x3002;</p>
<p><strong><em>Spark&#x4E0E;&#x5E8F;&#x5217;&#x5316;</em></strong></p>
<p>   &#x5BF9;&#x4E8E;&#x8BA1;&#x7B97;&#x6846;&#x67B6;&#x6765;&#x8BF4;&#xFF0C;&#x4ECE;&#x8BA1;&#x7B97;&#x4EA7;&#x751F;&#x7684;&#x539F;&#x56E0;&#x7684;&#x89D2;&#x5EA6;&#x4E0A;&#x770B;&#xFF0C;&#x53EF;&#x4EE5;&#x5206;&#x4E3A;&#x4E24;&#x7C7B;&#xFF1A;&#x4E00;&#x79CD;&#x662F;&#x57FA;&#x4E8E;&#x4E8B;&#x4EF6;&#x9A71;&#x52A8;&#x7684;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#xFF0C;&#x5982;storm&#xFF1B;&#x53E6;&#x4E00;&#x79CD;&#x662F;&#x57FA;&#x4E8E;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#x8BA1;&#x7B97;&#x6A21;&#x578B;&#xFF0C;&#x5982;MapReduce&#x3002;&#x4EE5;&#x8FD9;&#x4E24;&#x79CD;&#x7C7B;&#x578B;&#x6765;&#x5206;&#x7C7B;&#x7684;&#x8BDD;&#xFF0C; Spark&#x662F;&#x5C5E;&#x4E8E;&#x6570;&#x636E;&#x9A71;&#x52A8;&#x7684;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x5FC5;&#x987B;&#x5148;&#x6709;&#x6570;&#x636E;&#xFF0C;&#x800C;&#x540E;&#x624D;&#x80FD;&#x8FDB;&#x884C;&#x4E00;&#x4E9B;&#x6570;&#x636E;&#x64CD;&#x4F5C;&#xFF0C;&#x6570;&#x636E;&#x4E0E;&#x64CD;&#x4F5C;&#x4E4B;&#x95F4;&#x662F;&#x76F8;&#x4E92;&#x5206;&#x79BB;&#x7684;&#x3002;&#x8FD9;&#x4E9B;&#x6570;&#x636E;&#x7531;&#x4E00;&#x6761;&#x6761;&#x8BB0;&#x5F55;&#x6784;&#x6210;(&#x53EF;&#x7C7B;&#x6BD4;&#x6210;&#x4F20;&#x7EDF;&#x5173;&#x7CFB;&#x578B;&#x6570;&#x636E;&#x5E93;&#x4E2D;&#x884C;&#x7684;&#x6982;&#x5FF5;)&#xFF0C;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x4E4B;&#x95F4;&#x5173;&#x7CFB;&#x677E;&#x6563;, &#x6CA1;&#x6709;&#x4E0A;&#x4E0B;&#x6587;(&#x8BED;&#x4E49;)&#x3002;&#x5728;&#x5BF9;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#x65F6;&#xFF0C;&#x53EF;&#x4EE5;&#x62BD;&#x8C61;&#x51FA;&#x67D0;&#x4E9B;&#x884C;&#x4E3A;&#x7279;&#x5F81;&#xFF0C;&#x5C3D;&#x7BA1;&#x5BF9;&#x8BB0;&#x5F55;&#x7684;&#x64CD;&#x4F5C;(&#x7EC6;&#x8282;)&#x4F1A;&#x5343;&#x5DEE;&#x4E07;&#x522B;&#xFF0C;Spark&#x5B9A;&#x4E49;&#x4E86;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x96C6;(RDD), &#x4EE5;&#x53CA;&#x9488;&#x5BF9;&#x8FD9;&#x4E9B;&#x8BB0;&#x5F55;&#x96C6;&#x7684;&#x4E00;&#x4E9B;&#x64CD;&#x4F5C;(&#x63A5;&#x53E3;)&#xFF0C;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x5219;&#x7531;&#x7528;&#x6237;&#x81EA;&#x5DF1;&#x6765;&#x5B9E;&#x73B0;&#x3002;</p>
<p>   &#x62BD;&#x8C61;&#x662F;Spark&#x4E00;&#x4E2A;&#x5F88;&#x663E;&#x8457;&#x7684;&#x7279;&#x5F81;&#xFF0C;&#x6570;&#x636E;&#x88AB;&#x62BD;&#x8C61;&#x6210;&#x6570;&#x636E;&#x96C6;(RDD)&#xFF0C;&#x5728;&#x6BCF;&#x4E2A;&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x8BB0;&#x5F55;&#x4E86;&#xFF1A;</p>
<ul>
<li>A list of partitions &#x7531;&#x90A3;&#x4E9B;&#x6570;&#x636E;&#x5B50;&#x96C6;&#x6784;&#x6210;</li>
<li>A function for computing each split &#x5B50;&#x96C6;&#x4E2D;&#x6BCF;&#x6761;&#x8BB0;&#x5F55;&#x5982;&#x4F55;&#x8BA1;&#x7B97;(&#x8BA1;&#x7B97;&#x56E0;&#x5B50;&#xFF09;</li>
<li>A list of dependencies on other RDDs &#x4F9D;&#x8D56;&#x4E8E;&#x7684;&#x6570;&#x636E;&#x96C6;(parent RDD&#xFF09;</li>
<li>Optionally, a Partitioner for key-value RDDs (e.g. to say that the RDD is hash-partitioned) &#x5982;&#x4F55;&#x5C06;&#x8BE5;&#x6570;&#x636E;&#x96C6;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x5B9A;&#x4F4D;&#x5230;&#x4E0B;&#x4E00;&#x4E2A;RDD&#x4E2D;</li>
<li><p>Optionally, a list of preferred locations to compute each split on (e.g. block locations foran HDFS file) &#x4F4D;&#x7F6E;&#x4FE1;&#x606F;</p>
<p>RDD&#x4E2D;&#x7684;&#x8FD9;&#x4E9B;&#x7279;&#x5F81;&#x5305;&#x542B;&#x4E86;&#xFF1A; 1&#xFF0C; &#x6211;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x4ECE;&#x4F55;&#x800C;&#x6765;&#xFF1B; 2&#xFF0C;&#x6211;&#x8981;&#x600E;&#x6837;&#x8BA1;&#x7B97;&#x6E90;&#x6570;&#x636E;&#xFF0C;&#x4EE5;&#x6B64;&#x6765;&#x5F97;&#x5230;&#x6570;&#x636E;&#x96C6;&#xFF1B; 3&#xFF0C; &#x6211;&#x5982;&#x4F55;&#x5C06;&#x6211;&#x7684;&#x8BA1;&#x7B97;&#x7ED3;&#x679C;&#x8F93;&#x51FA;&#x4EE5;&#x53CA;&#x4E00;&#x4E9B;&#x4F18;&#x5316;&#x63AA;&#x65BD;&#xFF08;&#x8BA1;&#x7B97;&#x4E0E;&#x6570;&#x636E;&#x672C;&#x5730;&#x5316;)&#x3002;&#x8BA1;&#x7B97;&#x6570;&#x636E;&#x672C;&#x8EAB;&#x6CA1;&#x6709;&#x4E0A;&#x4E0B;&#x6587;&#x7684;&#x4F18;&#x52BF;&#xFF0C;&#x9002;&#x7528;&#x5206;&#x6CBB;&#x7B97;&#x6CD5;&#x7684;&#x57FA;&#x672C;&#x601D;&#x8DEF;&#xFF0C;&#x5C06;&#x6570;&#x636E;&#x5207;&#x5272;&#x6210;&#x4E00;&#x4E2A;&#x4E2A;&#x76F8;&#x4E92;&#x72EC;&#x7ACB;&#x7684;&#x788E;&#x7247;&#xFF0C;&#x5229;&#x7528;&#x5E76;&#x884C;&#x4F18;&#x52BF;&#x6765;&#x52A0;&#x901F;&#x8BA1;&#x7B97;&#x3002; &#x8FD9;&#x4E0D;&#x4EC5;&#x53EF;&#x4EE5;&#x7F29;&#x77ED;&#x89E3;&#x51B3;&#x95EE;&#x9898;&#x7684;&#x65F6;&#x95F4;&#xFF0C;&#x540C;&#x65F6;&#x4E5F;&#x9002;&#x7528;&#x4E8E;&#x6D77;&#x91CF;&#x6570;&#x636E;&#x7684;&#x95EE;&#x9898;&#x3002;MapReduce, Spark&#x5C31;&#x662F;&#x8FD9;&#x6837;&#x7684;&#x89E3;&#x51B3;&#x65B9;&#x6848;&#x3002;</p>
<p>&#x7EFC;&#x4E0A;&#x6240;&#x53D9;&#xFF0C;&#x4ECE;&#x5B8F;&#x89C2;&#x4E0A;&#x770B;&#xFF0C;&#x53EF;&#x4EE5;&#x8FD9;&#x6837;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;RDD:</p>
<p>  <em>rdd = f(g(h(&#x2026;rdd0&#x2026;)))</em></p>
<p>f,g,h &#x4E3A;&#x8BA1;&#x7B97;&#x56E0;&#x5B50;&#xFF0C;&#x5982;filter&#xFF0C;map&#xFF0C;groupByKey&#x7B49;&#x3002;</p>
<p>&#x5982;&#x4E0A;&#xFF0C;&#x8FD9;&#x4E9B;f,g,h&#x51FD;&#x6570;&#x7684;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x662F;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x3002;&#x4ECE;&#x63D0;&#x4EA4;&#x4F5C;&#x4E1A;&#x6765;&#x770B;&#xFF0C;&#x6211;&#x4EEC;&#x6240;&#x505A;&#x7684;&#x5DE5;&#x4F5C;&#x662F;&#x63D0;&#x4EA4;&#x4E00;&#x4E2A;jar&#x6587;&#x4EF6;&#xFF0C;Spark&#x8981;&#x505A;&#x7684;&#x5C31;&#x662F;&#x5C06;jar&#x4E2D;&#x5B9A;&#x4E49;&#x7684;&#x7C7B;&#x4F3C;&#x4E8E;f&#xFF0C;g&#xFF0C;h&#x8FD9;&#x6837;&#x7684;&#x5177;&#x4F53;&#x5B9E;&#x73B0;&#x5206;&#x53D1;&#x5230;&#x5206;&#x5E03;&#x5F0F;&#x96C6;&#x7FA4;&#x4E0A;&#xFF0C;&#x5B9E;&#x73B0;&#x5E76;&#x884C;&#x8BA1;&#x7B97;&#xFF0C;&#x5F53;&#x7136;&#x5305;&#x62EC;&#x4E00;&#x4E9B;&#x5BB9;&#x9519;&#x63AA;&#x65BD;&#x3002;<br>&#x8981;&#x5B9E;&#x73B0;&#x8FD9;&#x4E9B;&#x7279;&#x70B9;&#xFF0C;&#x5219;&#x5FC5;&#x987B;&#x56DE;&#x7B54;&#x4EE5;&#x4E0B;&#x4E00;&#x4E9B;&#x95EE;&#x9898;&#xFF1A;<br>1, &#x600E;&#x6837;&#x62C9;&#x53D6;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x3002;<br>2&#xFF0C;&#x5982;&#x4F55;&#x5C06;f&#x51FD;&#x6570;&#x5206;&#x53D1;&#x5230;&#x5408;&#x9002;&#x7684;&#x673A;&#x5668;&#x4E0A;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;<br>3&#xFF0C;&#x5982;&#x4F55;&#x8BA1;&#x7B97;&#x3002;<br>&#x4EE5;&#x4E00;&#x4E2A;WordCount&#x4E3A;&#x4F8B;&#xFF1A;</p>
</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"> <span class="keyword">val</span> textFile = sc.textFile(<span class="string">&quot;hdfs:///tmp/spark.text&quot;</span>)</div><div class="line"> <span class="keyword">val</span> counts = textFile.flatMap(line =&gt; line.split(<span class="string">&quot;\\s+&quot;</span>))</div><div class="line">                 .map(word =&gt; (word, <span class="number">1</span>))</div><div class="line">                 .reduceByKey(_ + _)</div><div class="line"> counts.saveAsTextFile(<span class="string">&quot;hdfs:///tmp/result&quot;</span>)</div><div class="line">``` </div><div class="line"></div><div class="line">&#x6267;&#x884C; <span class="keyword">val</span> textFile &#xFF1D; sc.textFile(<span class="string">&quot;hdfs:///tmp/spark.text&quot;</span>) &#x8FD9;&#x6761;&#x8BED;&#x53E5;&#x65F6;&#xFF0C;&#x8FD4;&#x56DE;&#x7684;&#x662F;<span class="type">HadoopRDD</span>&#xFF0C; &#x8FD9;&#x4E2A;<span class="type">HadoopRDD</span>&#x7531;&#xFF0C;</div><div class="line"></div><div class="line">```scala</div><div class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getPartitions</span></span>: <span class="type">Array</span>[<span class="type">Partition</span>] = {</div><div class="line">    <span class="keyword">val</span> jobConf = getJobConf()</div><div class="line">    <span class="comment">// add the credentials here as this can be called before SparkContext initialized</span></div><div class="line">    <span class="type">SparkHadoopUtil</span>.get.addCredentials(jobConf)</div><div class="line">    <span class="keyword">val</span> inputFormat = getInputFormat(jobConf)</div><div class="line">    <span class="keyword">val</span> inputSplits = inputFormat.getSplits(jobConf, minPartitions)</div><div class="line">    <span class="keyword">val</span> array = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">Partition</span>](inputSplits.size)</div><div class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> until inputSplits.size) {</div><div class="line">      array(i) = <span class="keyword">new</span> <span class="type">HadoopPartition</span>(id, i, inputSplits(i))</div><div class="line">    }</div><div class="line">    array</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x6BCF;&#x4E2A;&#x5177;&#x4F53;&#x7684;RDD&#x5B9E;&#x4F8B;&#x4E0A;&#x63D0;&#x4F9B;&#x4E86;&#x8FED;&#x4EE3;&#x5668;&#x6A21;&#x5F0F;&#x6765;&#x5C01;&#x88C5;RDD&#x5185;&#x90E8;&#x4E00;&#x6761;&#x6761;&#x8BB0;&#x5F55;&#x7684;&#x8BBF;&#x95EE;, &#x5982;HadoopRDD&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> iter = <span class="keyword">new</span> <span class="type">NextIterator</span>[(<span class="type">K</span>, <span class="type">V</span>)] {</div><div class="line">     <span class="keyword">val</span> split = theSplit.asInstanceOf[<span class="type">HadoopPartition</span>]</div><div class="line">     logInfo(<span class="string">&quot;Input split: &quot;</span> + split.inputSplit)</div><div class="line">     <span class="keyword">val</span> jobConf = getJobConf()</div><div class="line">     ...</div><div class="line">     <span class="keyword">var</span> reader: <span class="type">RecordReader</span>[<span class="type">K</span>, <span class="type">V</span>] = <span class="literal">null</span></div><div class="line">     <span class="keyword">val</span> inputFormat = getInputFormat(jobConf)</div><div class="line">     <span class="comment">//&#x5F97;&#x5230;&#x8BE5;RDD&#x5B9E;&#x4F8B;&#x8981;&#x5904;&#x7406;&#x7684;InputSplit&#xFF0C;&#x6839;&#x636E;&#x8FD9;&#x4E2A;InputSplit&#x4EE5;&#x53CA;InputFormat&#x5F97;&#x5230;&#x5C06;&#x5185;&#x5BB9;&#x89E3;&#x6790;&#x6210;&#x4E00;&#x6761;&#x6761;&lt;key value&gt;&#x7684;reader</span></div><div class="line">     reader = inputFormat.getRecordReader(split.inputSplit.value, jobConf, <span class="type">Reporter</span>.<span class="type">NULL</span>)</div><div class="line">    </div><div class="line">     <span class="keyword">val</span> key: <span class="type">K</span> = reader.createKey()</div><div class="line">     <span class="keyword">val</span> value: <span class="type">V</span> = reader.createValue()</div><div class="line"></div><div class="line">     <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">getNext</span></span>(): (<span class="type">K</span>, <span class="type">V</span>) = {</div><div class="line">       <span class="keyword">try</span> {</div><div class="line">         finished = !reader.next(key, value)</div><div class="line">       } <span class="keyword">catch</span> {</div><div class="line">         <span class="keyword">case</span> eof: <span class="type">EOFException</span> =&gt;</div><div class="line">           finished = <span class="literal">true</span></div><div class="line">       }</div><div class="line">       <span class="keyword">if</span> (!finished) {</div><div class="line">         inputMetrics.incRecordsRead(<span class="number">1</span>)</div><div class="line">       }</div><div class="line">       (key, value)</div><div class="line">     }</div><div class="line"></div><div class="line"> }</div><div class="line">  <span class="keyword">new</span> <span class="type">InterruptibleIterator</span>[(<span class="type">K</span>, <span class="type">V</span>)](context, iter)</div></pre></td></tr></table></figure>
<p> <em>val textFile &#xFF1D; sc.textFile(&#x201C;hdfs:///tmp/spark.text&#x201D;)</em> &#x8FD9;&#x4E00;&#x6B65;&#x8FD4;&#x56DE;&#x4E86;HadoopRDD&#x7684;&#x5B9A;&#x4E49;(&#x5176;&#x5B9E;&#x8FD4;&#x56DE;&#x7684;&#x662F;MapPartitionsRDD&#xFF0C;HadoopRDD&#x8FD4;&#x56DE;&#x7684;<long, text="">&#x952E;&#x503C;&#x5BF9;&#x66F4;&#x6539;&#x6210;value.toString, &#x4E3A;&#x4E86;&#x63CF;&#x8FF0;&#x7B80;&#x4FBF;&#xFF0C;&#x7701;&#x7565;&#x4E86;&#x8FD9;&#x4E00;&#x6B65;&#xFF0C;&#x5177;&#x4F53;&#x8FC7;&#x7A0B;&#x53EF;&#x67E5;&#x770B;SparkContext.textFile&#x6E90;&#x7801;)&#xFF0C;&#x5305;&#x62EC;HadoopRDD&#x5305;&#x542B;&#x54EA;&#x4E9B;partition&#xFF0C;&#x4EE5;&#x53CA;HadoopRDD&#x5B9E;&#x4F8B;&#x662F;&#x600E;&#x6837;&#x83B7;&#x5F97;&#x6570;&#x636E;(compute).<br>&#x5F53;&#x6267;&#x884C;&#x5230;&#x8FD9;&#x4E00;&#x8BED;&#x53E5;&#x65F6;&#xFF0C;<br>  textFile.flatMap(line =&gt; line.split(&#x201C;\s+&#x201D;))&#xFF0C; &#x8FD4;&#x56DE;&#x4E00;&#x4E2A;MapPartitionsRDD&#xFF0C;</long,></p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment">/**</span></div><div class="line"> *  Return a new RDD by first applying a function to all elements of this</div><div class="line"> *  RDD, and then flattening the results.</div><div class="line"> */</div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">U</span>: <span class="type">ClassTag</span>](f: <span class="type">T</span> =&gt; <span class="type">TraversableOnce</span>[<span class="type">U</span>]): <span class="type">RDD</span>[<span class="type">U</span>] = withScope {</div><div class="line">  <span class="keyword">val</span> cleanF = sc.clean(f)</div><div class="line">  <span class="keyword">new</span> <span class="type">MapPartitionsRDD</span>[<span class="type">U</span>, <span class="type">T</span>](<span class="keyword">this</span>, (context, pid, iter) =&gt; iter.flatMap(cleanF))</div><div class="line">}</div></pre></td></tr></table></figure>
<p>&#x6211;&#x4EEC;&#x81EA;&#x5B9A;&#x4E49;flatMap&#x7684;&#x903B;&#x8F91;f: line =&gt; line.split(&#x201C;\s+&#x201D;)&#xFF0C;&#x7ECF;&#x8FC7;<em>val cleanF = sc.clean(f)</em>&#x6E05;&#x6D17;&#x52A0;&#x5DE5;(&#x53BB;&#x9664;&#x539F;f&#x4E2D;&#x4E00;&#x4E9B;&#x65E0;&#x6548;&#x7684;&#x53D8;&#x91CF;&#x6216;&#x903B;&#x8F91;&#xFF1F;&#xFF09;&#xFF0C;&#x5F53;&#x8BA1;&#x7B97;&#x8BE5;MapPartitionsRDD&#x5B9E;&#x4F8B;&#x4E2D;&#x7684;&#x8BB0;&#x5F55;&#x65F6;&#xFF0C;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">class</span> <span class="title">MapPartitionsRDD</span>[<span class="type">U</span>: <span class="type">ClassTag</span>, <span class="type">T</span>: <span class="type">ClassTag</span>](<span class="params"></span></span></div><div class="line">    var prev: <span class="type">RDD</span>[<span class="type">T</span>],</div><div class="line">    f: (<span class="type">TaskContext</span>, <span class="type">Int</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) <span class="title">=&gt;</span> <span class="title">Iterator</span>[<span class="type">U</span>],  <span class="title">//</span> (<span class="params"><span class="type">TaskContext</span>, partition index, iterator</span>)</div><div class="line">    preservesPartitioning: <span class="type">Boolean</span> = <span class="literal">false</span>)</div><div class="line">  <span class="keyword">extends</span> <span class="type">RDD</span>[<span class="type">U</span>](prev) {</div><div class="line">  <span class="comment">//&#x5728;&#x8BE5;&#x5B9E;&#x4F8B;&#x4E2D;&#xFF1A; firstParent -&gt; HadoopRDD</span></div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">compute</span></span>(split: <span class="type">Partition</span>, context: <span class="type">TaskContext</span>): <span class="type">Iterator</span>[<span class="type">U</span>] = {</div><div class="line">    <span class="keyword">val</span> iter = firstParent[<span class="type">T</span>].iterator(split, context);</div><div class="line">    <span class="keyword">val</span> index = split.index</div><div class="line">    f(context, index, iter)</div><div class="line">  }</div></pre></td></tr></table></figure>
<p>&#x5F53;MapPartitionsRDD&#x5B9E;&#x4F8B;&#x8C03;&#x7528;compute&#x65B9;&#x6CD5;&#xFF0C;&#x751F;&#x6210;&#x8BE5;RDD&#x4E0A;&#x7684;&#x8FED;&#x4EE3;&#x5668;&#x65F6;&#x3002;&#x9996;&#x5148;&#x67E5;&#x770B;&#x5B83;&#x4F9D;&#x8D56;&#x7684;RDD(firstParent)&#x8981;&#x4E00;&#x4E2A;&#x5BF9;&#x5E94;split&#x7684;&#x8FED;&#x4EE3;&#x5668;&#xFF0C;spark&#x9996;&#x5148;&#x67E5;&#x770B;&#x8BE5;rdd split&#x662F;&#x5426;&#x88AB;&#x7F13;&#x5B58;&#xFF0C;&#x5982;&#x679C;&#x88AB;&#x7F13;&#x5B58;&#x5219;&#x76F4;&#x63A5;&#x8FD4;&#x56DE;&#xFF0C;&#x5982;&#x679C;&#x6CA1;&#x6709;&#xFF0C;&#x5219;&#x8C03;&#x7528;parent rdd&#x7684;compute&#x65B9;&#x6CD5;&#x8BA1;&#x7B97;&#x51FA;&#x6765;&#xFF0C;&#x8FD9;&#x662F;&#x4E00;&#x4E2A;&#x9012;&#x5F52;&#x8BA1;&#x7B97;&#x7684;&#x8FC7;&#x7A0B;&#x3002;MapPartitionsRDD&#x5728;&#x8C03;&#x7528;compute&#x65F6;&#xFF0C;&#x6709;&#x4E2A;<em>f(context, index, iter)</em>, &#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x8C03;&#x7528;&#x7B49;&#x4EF7;&#x4E8E;&#xFF1A;<em>iter(HadoopRDD&#x8FED;&#x4EE3;&#x5668;).flatMap(line =&gt; line.split(&#x201C;\s+&#x201D;)</em> </p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">flatMap</span></span>[<span class="type">B</span>](f: <span class="type">A</span> =&gt; <span class="type">GenTraversableOnce</span>[<span class="type">B</span>]): <span class="type">Iterator</span>[<span class="type">B</span>] = <span class="keyword">new</span> <span class="type">AbstractIterator</span>[<span class="type">B</span>] {</div><div class="line">   <span class="keyword">private</span> <span class="keyword">var</span> cur: <span class="type">Iterator</span>[<span class="type">B</span>] = empty</div><div class="line">   <span class="function"><span class="keyword">def</span> <span class="title">hasNext</span></span>: <span class="type">Boolean</span> =</div><div class="line">     cur.hasNext || self.hasNext &amp;&amp; { cur = f(self.next).toIterator; hasNext }</div><div class="line">   <span class="function"><span class="keyword">def</span> <span class="title">next</span></span>(): <span class="type">B</span> = (<span class="keyword">if</span> (hasNext) cur <span class="keyword">else</span> empty).next()</div><div class="line"> }</div></pre></td></tr></table></figure>
<p>&#x53EF;&#x89C1;&#xFF0C;&#x6211;&#x4EEC;&#x5177;&#x4F53;&#x7684;&#x4E1A;&#x52A1;&#x903B;&#x8F91;(line =&gt; line.split(&#x201C;\s+&#x201D;))&#x662F;&#x5728;<em>f(self.next)</em>&#x8FD9;&#x8C03;&#x7528;&#x7684;&#xFF0C; &#x800C;self.next&#x83B7;&#x5F97;&#x7684;&#x662F;HadoopRDD&#x8FED;&#x4EE3;&#x5668;&#x4E2D;&#x4E0B;&#x4E00;&#x6761;&#x8BB0;&#x5F55;&#x3002;</p>
<p>&#x9700;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x662F;&#xFF0C;&#x5F53;Spark driver&#x6267;&#x884C;&#x5230;&#x8FD9;&#x4E00;&#x6B65;&#x65F6;&#xFF0C;&#x5C5E;&#x4E8E;&#x8FD9;&#x4E2A;Application&#x7684;&#x8FDB;&#x7A0B;&#x96C6;&#x5408;&#x5E76;&#x6CA1;&#x6709;task&#x5728;&#x8FD0;&#x884C;&#xFF0C;&#x56E0;&#x4E3A;RDD&#x5B9E;&#x4F8B;&#x63D0;&#x4F9B;&#x4E86;&#x4E00;&#x4E2A;iterator&#x63A5;&#x53E3;&#xFF0C;&#x5176;&#x5185;&#x90E8;&#x6570;&#x636E;&#x5982;&#x4F55;&#x8BA1;&#x7B97;&#x4EE5;&#x53CA;&#x8981;&#x8BA1;&#x7B97;&#x7684;&#x6570;&#x636E;&#x600E;&#x6837;&#x88AB;&#x83B7;&#x53D6;&#xFF0C;&#x8FD9;&#x5BF9;&#x4E8E;&#x5176;&#x5B83;&#x7684;RDD&#x6765;&#x8BF4;&#x662F;&#x4E0D;&#x53EF;&#x89C1;&#x7684;&#xFF0C;&#x4E5F;&#x6CA1;&#x5FC5;&#x8981;&#x77E5;&#x9053;&#x3002; &#x8981;&#x60F3;&#x771F;&#x6B63;&#x8BA9;&#x6570;&#x636E;&#x52A8;&#x8D77;&#x6765;(rdd.action)&#xFF0C;&#x5219;&#x9700;&#x8981;&#x8FD9;&#x6837;&#xFF1A;</p>
<p><pre><br>  while (iter.hasNext) {<br>     func(iter.next)<br>  }<br> iter.hasNext -&gt; iter1.hasNext -&gt; iter2.hasNext -&gt; &#x2026;.. -&gt; itern.hasNext<br> iter.next -&gt; iter1.next -&gt; &#x2026;&#x2026;. -&gt; itern.next<br> </pre><br> &#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;&#xFF0C;&#x5219;&#x662F;&#x5728;&#x8C03;&#x7528;&#x8FD9;&#x4E9B;iter1.hasNext&#x6216;&#x8005;iter.next&#x7684;&#x65F6;&#x5019;&#x88AB;&#x6267;&#x884C;(rdd&#x6709;&#x4E2A;mapPartitions&#x65B9;&#x6CD5;&#x548C;&#x8FD9;&#x91CC;&#x8BF4;&#x7684;&#x4E0D;&#x4E00;&#x81F4;&#xFF09;<br> &#x5982;rdd.reduce:</p>
 <figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span></span>(f: (<span class="type">T</span>, <span class="type">T</span>) =&gt; <span class="type">T</span>): <span class="type">T</span> = withScope {</div><div class="line">   <span class="keyword">val</span> cleanF = sc.clean(f)</div><div class="line">   <span class="comment">//reducePartition&#x88AB;&#x5E8F;&#x5217;&#x5316;&#x5230;executors&#x4E2D;&#x6267;&#x884C;</span></div><div class="line">   <span class="keyword">val</span> reducePartition: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">Option</span>[<span class="type">T</span>] = iter =&gt; {</div><div class="line">     <span class="keyword">if</span> (iter.hasNext) {</div><div class="line">       <span class="type">Some</span>(iter.reduceLeft(cleanF))</div><div class="line">     } <span class="keyword">else</span> {</div><div class="line">       <span class="type">None</span></div><div class="line">     }</div><div class="line">   }</div><div class="line">   ...</div><div class="line"> }</div></pre></td></tr></table></figure>
<p>&#x56DE;&#x5230;&#x6700;&#x521D;&#x7684;&#x95EE;&#x9898;&#xFF0C;Spark&#x4E0E;&#x5E8F;&#x5217;&#x5316;&#x6709;&#x4F55;&#x5173;&#x7CFB;&#xFF1F;<br>&#x7531;&#x4E0A;&#x6587;&#x7684;&#x5206;&#x6790;&#x53EF;&#x77E5;&#xFF0C;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;&#x88AB;&#x5185;&#x5D4C;&#x5230;RDD&#x7684;&#x5B9A;&#x4E49;&#x4E2D;(&#x901A;&#x8FC7;&#x6784;&#x9020;&#x51FD;&#x6570;), &#x8FD9;&#x4E9B;&#x903B;&#x8F91;&#x968F;RDD&#x4E00;&#x8D77;&#x88AB;&#x5206;&#x53D1;&#x5230;application&#x53EF;&#x7528;&#x7684;&#x8FDB;&#x7A0B;&#x4E0A;&#x53BB;&#x6267;&#x884C;&#xFF0C;&#x8FD9;&#x610F;&#x5473;&#x7740;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x903B;&#x8F91;&#x662F;RDD&#x4E2D;&#x4E00;&#x4E2A;&#x6709;&#x72B6;&#x6001;&#x7684;&#x6210;&#x5458;&#x53D8;&#x91CF;&#xFF0C;Spark driver&#x901A;&#x8FC7;&#x5C06;RDD&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5C06;&#x7ED3;&#x679C;&#x5C01;&#x88C5;&#x5230;&#x76F8;&#x5E94;&#x7684;Task&#x4E2D;&#xFF0C;&#x8FD9;&#x90E8;&#x5206;&#x7EC6;&#x8282;&#x53EF;&#x5728;DAGScheduler.submitMissingTasks&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></div><div class="line">    <span class="keyword">try</span> {</div><div class="line">      <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></div><div class="line">      <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></div><div class="line">      <span class="keyword">val</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = stage <span class="keyword">match</span> {</div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">          closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>).array()</div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">          closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>).array()</div><div class="line">      }</div><div class="line"></div><div class="line">      taskBinary = sc.broadcast(taskBinaryBytes)</div><div class="line">    }</div><div class="line">    </div><div class="line">  <span class="comment">//...</span></div><div class="line">     <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</div><div class="line">          partitionsToCompute.map { id =&gt;</div><div class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(id)</div><div class="line">            <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">              taskBinary, part, locs, stage.internalAccumulators)</div><div class="line">          }</div><div class="line"></div><div class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</div><div class="line">          <span class="keyword">val</span> job = stage.activeJob.get</div><div class="line">          partitionsToCompute.map { id =&gt;</div><div class="line">            <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</div><div class="line">            <span class="keyword">val</span> part = stage.rdd.partitions(p)</div><div class="line">            <span class="keyword">val</span> locs = taskIdToLocations(id)</div><div class="line">            <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptId,</div><div class="line">              taskBinary, part, locs, id, stage.internalAccumulators)</div><div class="line">     }</div></pre></td></tr></table></figure>
<p>&#x5C06;&#x6211;&#x4EEC;&#x7684;&#x903B;&#x8F91;&#x5E8F;&#x5217;&#x5316;&#x540E;&#xFF0C;&#x901A;&#x8FC7;&#x6784;&#x9020;&#x51FD;&#x6570;&#x4F20;&#x5165;&#x5230;&#x76F8;&#x5E94;&#x7684;Task&#x4E2D;&#xFF0C;TaskSetManager&#x518D;&#x5C06;task&#x5E8F;&#x5217;&#x5316;&#xFF0C;driver&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x7ED3;&#x679C;&#x53D1;&#x9001;&#x5230;executor&#xFF0C; executor&#x5148;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x5F97;&#x5230;task&#x5B9E;&#x4F8B;&#xFF0C;&#x63A5;&#x7740;&#x518D;&#x53CD;&#x5E8F;&#x5217;&#x5316;&#x5F97;&#x5230;rdd&#x548C;&#x4F9D;&#x8D56;&#x5173;&#x7CFB;(dependency)&#x3002;<br>&#x5728;<a href="https://issues.apache.org/jira/browse/SPARK-7708" target="_blank" rel="external">SPARK-7708</a>&#x63D0;&#x5230;&#xFF0C;&#x76EE;&#x524D;&#x5E76;&#x4E0D;&#x80FD;&#x652F;&#x6301;kyro&#x7684;&#x65B9;&#x5F0F;&#x6765;&#x5E8F;&#x5217;&#x5316;&#x8FD9;&#x4E9B;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#xFF0C;&#x5728;&#x672A;&#x53EF;&#x66FF;&#x4EE3;&#x7684;&#x524D;&#x63D0;&#x4E0B;&#xFF0C;&#x4F7F;&#x7528;&#x7684;&#x662F;Java&#x672C;&#x8EAB;&#x63D0;&#x4F9B;&#x7684;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x3002;&#x56E0;&#x6B64;&#xFF0C;&#x6211;&#x4EEC;&#x5728;&#x5199;&#x6211;&#x4EEC;&#x7684;&#x903B;&#x8F91;&#x65F6;&#xFF0C;&#x9700;&#x8981;&#x6CE8;&#x610F;&#x9075;&#x5FAA;Java&#x5E8F;&#x5217;&#x5316;&#x63D0;&#x4F9B;&#x7684;&#x89C4;&#x5219;&#x3002;&#x5305;&#x62EC;&#xFF0C;<strong>&#x5728;&#x6211;&#x4EEC;&#x5199;&#x7684;&#x903B;&#x8F91;&#x4E2D;&#x5305;&#x542B;&#x4F9D;&#x8D56;&#x7684;&#x7C7B;&#xFF0C;&#x5982;&#x679C;&#x6709;&#x72B6;&#x6001;&#x7684;&#x5168;&#x5C40;&#x53D8;&#x91CF;(&#x9012;&#x5F52;&#xFF0C;&#x5BF9;&#x8C61;&#x76F8;&#x5173;)&#x4E0D;&#x80FD;&#x5E8F;&#x5217;&#x5316;&#xFF0C;&#x5219;&#x4F1A;&#x51FA;&#x73B0;&#x5E8F;&#x5217;&#x5316;&#x95EE;&#x9898;&#x7B49;</strong>&#xFF0C; &#x8FD9;&#x4E2A;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<em>spark.closure.serializer</em>&#x53EF;&#x914D;&#x7F6E;&#x3002; &#x540C;&#x65F6;&#xFF0C;&#x4E86;&#x89E3;&#x5230;&#x6211;&#x4EEC;&#x5B9A;&#x4E49;&#x7684;&#x51FD;&#x6570;&#x903B;&#x8F91;f&#xFF0C;&#x4F1A;&#x5206;&#x53D1;&#x5728;&#x4E0D;&#x540C;&#x7684;JVM&#x4E0A;&#x6267;&#x884C;&#xFF0C;&#x610F;&#x5473;&#x7740;&#x53EF;&#x80FD;&#x5B58;&#x5728;&#x4E00;&#x4E9B;&#x8FD9;&#x6837;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x8FD9;&#x662F;&#x5206;&#x5E03;&#x5F0F;&#x7F16;&#x7A0B;&#x7279;&#x522B;&#x8981;&#x6CE8;&#x610F;&#x7684;&#x95EE;&#x9898;&#xFF1A;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">var</span> counter = <span class="number">0</span></div><div class="line"><span class="keyword">var</span> rdd = sc.parallelize(data)</div><div class="line"></div><div class="line"><span class="comment">// Wrong: Don&apos;t do this!!</span></div><div class="line">rdd.foreach(x =&gt; counter += x)</div><div class="line"><span class="comment">//&#x5728;&#x5206;&#x5E03;&#x5F0F;&#x73AF;&#x5883;&#x4E0B;&#xFF0C;&#x53EF;&#x80FD;&#x6BCF;&#x6B21;&#x8FD4;&#x56DE;&#x7684;&#x503C;&#x51FA;&#x73B0;&#x4E0D;&#x4E00;&#x81F4;</span></div><div class="line">println(<span class="string">&quot;Counter value: &quot;</span> + counter)</div></pre></td></tr></table></figure>
<p><a href="http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka" target="_blank" rel="external">Prior to execution, Spark computes the task&#x2019;s closure. The closure is those variables and methods which must be visible for the executor to perform its computations on the RDD (in this case foreach()). This closure is serialized and sent to each executor.<br>The variables within the closure sent to each executor are now copies and thus, when counter is referenced within the foreach function, it&#x2019;s no longer the counter on the driver node. There is still a counter in the memory of the driver node but this is no longer visible to the executors! The executors only see the copy from the serialized closure. Thus, the final value of counter will still be zero since all operations on counter were referencing the value within the serialized closure.</a><br>&#x53E6;&#x5916;&#xFF0C;&#x5728;spark&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;&#x5230;&#x4E86;&#x5E8F;&#x5217;&#x5316;&#x6765;&#x4FDD;&#x5B58;shuffle&#x7684;&#x4E2D;&#x95F4;&#x7ED3;&#x679C;,&#x51CF;&#x5C11;&#x7F51;&#x7EDC;&#x4F20;&#x8F93;;&#x6709;&#x65F6;&#x4E3A;&#x907F;&#x514D;&#x540C;&#x4E00;&#x4E2A;RDD&#x91CD;&#x590D;&#x8BA1;&#x7B97;&#xFF0C;&#x9700;&#x8981;&#x4FDD;&#x5B58;&#x67D0;&#x4E2A;RDD&#x4E0A;&#x7684;&#x6570;&#x636E;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;<a href="https://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence" target="_blank" rel="external">RDD Persist API</a>, &#x4F7F;&#x7528;&#x5E8F;&#x5217;&#x5316;&#x6765;&#x51CF;&#x5C11;&#x5185;&#x5B58;&#x4F7F;&#x7528;&#x91CF;(MEMORY_ONLY_SER)&#x6216;&#x8005;disk&#x7684;&#x5360;&#x7528;&#x7A7A;&#x95F4;(MEMORY_AND_DISK_SER)&#x3002;<a href="https://spark.apache.org/docs/latest/tuning.html" target="_blank" rel="external">&#x5BF9;&#x4E8E;&#x5927;&#x591A;&#x6570;&#x5E94;&#x7528;&#x6765;&#x8BF4;&#xFF0C;&#x5C06;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x66F4;&#x6539;&#x6210;kyro&#xFF0C;&#x5C06;&#x6570;&#x636E;&#x4EE5;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x5F62;&#x5F0F;&#x6765;&#x4FDD;&#x5B58;&#xFF0C;&#x53EF;&#x4EE5;&#x89E3;&#x51B3;&#x5927;&#x90E8;&#x5206;&#x5E94;&#x7528;&#x7684;&#x6027;&#x80FD;&#x95EE;&#x9898;&#x3002;</a>&#x53EF;&#x4EE5;&#x901A;&#x8FC7;</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//switch to using Kryo by initializing your job with a SparkConf</span></div><div class="line">conf.set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>).</div></pre></td></tr></table></figure>
<p>&#x6765;&#x914D;&#x7F6E;&#x6216;&#x4FEE;&#x6539;&#x8FD9;&#x90E8;&#x5206;Spark&#x7684;&#x5E8F;&#x5217;&#x5316;&#x673A;&#x5236;&#x3002;<br><br>&#x672C;&#x6587;&#x6240;&#x4F5C;&#x7684;&#x5206;&#x6790;&#x4E0D;&#x8FC7;&#x662F;Spark&#x4E2D;&#x7684;&#x51B0;&#x5C71;&#x4E00;&#x89D2;&#xFF0C;&#x6587;&#x4E2D;&#x4E0D;&#x5F53;&#x6216;&#x9519;&#x8BEF;&#x4E4B;&#x5904;&#xFF0C;&#x6B22;&#x8FCE;&#x6279;&#x8BC4;&#x6307;&#x6B63;&#x3002;</p>
<p><strong><em>Useful links: <br></em></strong></p>
<ul><br>  <li><a href="http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/" target="_blank" rel="external">http://jerryshao.me/architecture/2013/10/08/spark-storage-module-analysis/</a></li><br>  <li><a href="https://github.com/JerryLead/SparkInternals" target="_blank" rel="external">https://github.com/JerryLead/SparkInternals</a></li><br>  <li><a href="http://spark.apache.org/docs/latest/programming-guide.html" target="_blank" rel="external">http://spark.apache.org/docs/latest/programming-guide.html</a></li><br>  <li><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html" target="_blank" rel="external">https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html</a></li><br>  <li><a href="http://blog.madhukaraphatak.com/kryo-disk-serialization-in-spark/" target="_blank" rel="external">http://blog.madhukaraphatak.com/kryo-disk-serialization-in-spark/</a></li><br>  <li><a href="https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/" target="_blank" rel="external">https://ogirardot.wordpress.com/2015/01/09/changing-sparks-default-java-serialization-to-kryo/</a></li><br>  <li><a href="http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka" target="_blank" rel="external">http://spark.apache.org/docs/latest/programming-guide.html#understanding-closures-a-nameclosureslinka</a></li><br></ul>  

<p>Example:</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">&quot;Spark Pi&quot;</span>).setMaster(<span class="string">&quot;local&quot;</span>)</div><div class="line"><span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</div><div class="line"><span class="keyword">var</span> wcount = spark.textFile(<span class="string">&quot;file:///Users/yixin/test&quot;</span>).flatMap(line =&gt; line.split(<span class="string">&quot;\\s+&quot;</span>))</div><div class="line">      .filter(word =&gt; word.startsWith(<span class="string">&quot;f&quot;</span>)).map(word =&gt; (word, <span class="number">1</span>)).cache()</div><div class="line"></div><div class="line"><span class="keyword">var</span> patitions = wcount.mapPartitions(iter =&gt; {</div><div class="line">  <span class="keyword">var</span> buf = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]();</div><div class="line">  <span class="keyword">while</span> (iter.hasNext) {</div><div class="line">    <span class="keyword">var</span> (word, count) = iter.next()</div><div class="line">     buf += (word + <span class="string">&quot;_&quot;</span> + count)</div><div class="line">  }</div><div class="line">  buf.toList.toIterator</div><div class="line">})</div><div class="line"></div><div class="line"><span class="keyword">var</span> iter: <span class="type">Iterator</span>[<span class="type">String</span>] = patitions.compute(<span class="keyword">new</span> <span class="type">Partition</span> {</div><div class="line">  <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">index</span></span>: <span class="type">Int</span> = wcount.partitions.apply(<span class="number">0</span>).index</div><div class="line">},</div><div class="line"> <span class="keyword">new</span> <span class="type">TaskContextImpl</span>(<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,</div><div class="line">     <span class="keyword">new</span> <span class="type">TaskMemoryManager</span>(<span class="type">SparkEnv</span>.get.memoryManager, <span class="number">0</span>),</div><div class="line">          <span class="type">SparkEnv</span>.get.metricsSystem,</div><div class="line">          internalAccumulators = <span class="type">Seq</span>.empty))</div><div class="line"></div><div class="line"><span class="comment">//How to scan the records in a rdd </span></div><div class="line"><span class="keyword">while</span> (iter.hasNext) {</div><div class="line">    println(<span class="string">&quot;---------&gt;&quot;</span> + iter.next())</div><div class="line">}</div><div class="line">spark.stop()</div></pre></td></tr></table></figure></div></article><div class="tags"></div><div class="paginator"><a href="../yarn-logaggregator/" class="next"><span>Next</span><i class="iconfont icon-right"></i></a></div><section id="comments"><div id="disqus_thread"></div></section><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'https://dengzhhu653.github.io/spark-serializable/';
    this.page.identifier = 'spark-serializable/';
    this.page.title = '';
};
(function() {
var d = document, s = d.createElement('script');

s.src = '//dengzhhu653.disqus.com/embed.js';

s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();</script></section><footer><div class="copyright"><p class="power">Powered by <a href="https://hexo.io/">Hexo</a> and Theme by <a href="https://github.com/ahonn/hexo-theme-even"> Even</a></p><p class="since">&copy;2016<span class="heart"><i class="iconfont icon-heart"></i></span><span class="author">Zhihua Deng</span></p></div><label id="back2top"><i class="iconfont icon-up"></i></label></footer></div><script src="/js/zepto.min.js"></script><script src="/js/theme.js"></script></body></html>